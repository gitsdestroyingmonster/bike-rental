{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "daily-bike-share.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "lsH4_qKgiXu2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task1**\n",
        "Import data from daily-bike-share.csv and viewing first 5 rows of data. "
      ],
      "metadata": {
        "id": "BP6bOMC2humI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/daily-bike-share.csv')\n",
        "print(data.head(5))\n",
        "\n",
        "# Checking if any datapoint is null or not\n",
        "print(data.isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kSWhBM4iVdp",
        "outputId": "e2e5741c-6858-4363-e077-27358bc5ab58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   instant    dteday  season  yr  ...     atemp       hum  windspeed  rentals\n",
            "0        1  1/1/2011       1   0  ...  0.363625  0.805833   0.160446      331\n",
            "1        2  1/2/2011       1   0  ...  0.353739  0.696087   0.248539      131\n",
            "2        3  1/3/2011       1   0  ...  0.189405  0.437273   0.248309      120\n",
            "3        4  1/4/2011       1   0  ...  0.212122  0.590435   0.160296      108\n",
            "4        5  1/5/2011       1   0  ...  0.229270  0.436957   0.186900       82\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task2**\n",
        "\n",
        "Creating Histogram for features 'temp' and 'windspeed', also adding lines for mean and median of each distribution."
      ],
      "metadata": {
        "id": "UuvNH8WEis8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Histogram for 'temp'**"
      ],
      "metadata": {
        "id": "XQlFU8Wck3ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color_median = '#fc4f30'\n",
        "color_mean = '#008000'\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "temp = data['temp']\n",
        "\n",
        "plt.hist(temp, bins = 70, edgecolor = 'black')\n",
        "\n",
        "mean_temp = temp.mean()\n",
        "median_temp =temp.median()\n",
        "\n",
        "plt.axvline(median_temp, color=color_median, label='median', linewidth = 2)\n",
        "plt.axvline(mean_temp, color=color_mean, label = 'mean', linewidth = 2)\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('TEMPERATURE')\n",
        "plt.ylabel('FREQUENCY')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "V4VMEVgUi7eu",
        "outputId": "d788e09f-4c31-4ae3-e6ea-dbe337a2e638"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Histogram for 'windspeed'**"
      ],
      "metadata": {
        "id": "OxVjcEATrO8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "windspeed = data['windspeed']\n",
        "\n",
        "plt.hist(windspeed, bins = 40, edgecolor = 'black')\n",
        "\n",
        "mean_windspeed = windspeed.mean()\n",
        "median_windspeed = windspeed.median()\n",
        "\n",
        "plt.axvline(median_windspeed, color=color_median, label='median', linewidth = 1)\n",
        "plt.axvline(mean_windspeed, color=color_mean, label='mean',  linewidth = 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('WINDSPEED')\n",
        "plt.ylabel('FREQUENCY')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "Tw7D64Pwrp8q",
        "outputId": "2b84fe1b-5f51-445d-cb06-56011d8a6ca3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEQCAYAAAD2/KAsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVjU1f4H8PcEyiLQCA7Dr1gMHEXQK25I3EovplZc5eKS+680FckSIk0nzbUuIsbNBVAxr5XLVVEvmlqPKakooOaaKaEiWgZM+ENZBhGY3x8+Tk4sMwMz8x2G9+t5eB7nnDPn+5nTwKfvcs4RlZSUqEBERGRiTwkdABERtU5MQEREJAgmICIiEgQTEBERCYIJiIiIBMEEREREgmACIiIiQTABERGRICwuAeXm5godgtmw1LFweGNAg3Xiz8T1llvqWDQFx+IPHAtNph4Pi0tARETUMjABERGRIJiAiIhIEIIloNjYWIjFYo2fzp07q+tVKhViY2Ph6+sLNzc3hIaG4sqVK0KFS0REBmYt5MFlMhm+/vpr9WsrKyv1v1euXInExEQkJiZCJpNh+fLlCA8Px+nTp+Ho6ChEuEQksOrqapSXlxusP1tbW9y7d89g/bV0TRmPdu3awdq6aalE0ARkbW0NqVRap1ylUiE5ORnR0dEICwsDACQnJ0MmkyE1NRWTJk0ydahEJLDq6mqUlpZCLBZDJBIZpE8bGxvY2toapC9LoO94qFQqlJSUwNHRsUlJSNB7QDdv3oSvry/+8pe/YPLkybh58yYAID8/H4WFhQgJCVG3tbOzQ3BwMLKzswWKloiEVF5ebtDkQ80nEokgFoubfFYq2BlQnz59kJSUBJlMht9//x3x8fEYPHgwsrKyUFhYCACQSCQa75FIJPjtt9+09s1n+/9g6LH4ZO0XuHX/YYP1nk5tMG/6GwY95p/1BBAydU79lf7Am+/PrzcGfi/+0BLHwtbWFjY2Ngbvt7Ky0uB9tmRNGY/79++jqKioTrlMJmv0fYIloEGDBmm87tOnDwICArB161b07du3WX1r+9CtRW5ursHHQlFtjbPBkQ3W251PMcn4nw2eWX/FvXVQVFvXicEYY9FStdSxuHfvnsEvl1VWVvIS3BOaOh5OTk7w8PDQ+31m8xi2g4MDfH19cePGDfV9IYVCodFGoVDA1dVViPCIiMjAzCYBVVZWIjc3F1KpFF5eXpBKpUhPT9eoz8zMRL9+/QSMkojIPK1evRrdu3dXv46NjcXzzz8vYETaCXYJbv78+XjllVfg7u6uvgdUUVGBsWPHQiQSITIyEgkJCZDJZOjUqRNWrFiBdu3aYeTIkUKFTETUYrz77ruIiIgQOoxGCZaA7ty5gylTpqC4uBgdOnRAnz59cOjQIXh6egIAoqKioFQqMXv2bJSUlKB3797YvXs35wCZuWs5VxEatajBeh+Xdli1YLbpAiJqpRwcHIQOQSvBEtDGjRsbrReJRJDL5ZDL5SaKiAxBaWWLEwFTG25wPsV0wRCZgdDQUHTp0gV2dnbYsmULrKysMGvWLEyePBnz5s3Djh074OTkhPnz52PMmDEAHv0P+vz583H48GEAQL9+/RAbGwsfHx91v48n65eXl+Pvf/87OnbsqHHc2NhY7N27F5mZmQCAs2fPYunSpbhw4QIePnwIf39/LFmyBIGBger3uLm54bPPPkN6ejoOHToEiUSCDz/8EKNHjzbK2JjNPSAiIku1c+dOODg44PDhw4iOjoZcLsf48ePh4+OD77//HmPGjMHMmTNRUFCAiooKDB06FDY2Nti/fz8OHToEqVSKsLAwVFRUAAD27NmDjz/+GHK5HEePHoVMJkNSUlKjMZSWlmL06NE4ePAgDh8+jO7du2PUqFG4e/euRrvly5fjtddeQ0ZGBoYPH4533nkHt2/fNsq4MAERERmZr68v5HI5fHx88M4778DFxQXW1taIjIyEt7c35syZA5VKhezsbOzatQsqlQpJSUno1q0bOnfujM8++wzl5eX49ttvATxaGWbs2LGYNGkSOnXqhFmzZqFXr16NxtC/f3+MGTMGXbp0QefOnbF8+XLY2tri0KFDGu1Gjx6N0aNHw9vbG/PmzYO1tTVOnjxplHERdCkeoj+buSQe14sbn1V91ESxUMvQds+/0fa/XzTpvU25S1L1jzdQFa7fcmD+/v7qf4tEIkgkEo2yNm3aQCwWQ6FQ4OrVq8jPz4e7u7tGHxUVFcjLywMA5OTkYOLEiRr1ffv2xY0bNxqMQaFQ4JNPPsHx48ehUChQU1MDpVKJX375pcFYra2t4eLiUmdKjKEwAZFZuV5c3vg9JAD4/nuTxEItQ1X4JL0TwmOmmojapk0bjdcikajO2mkikQi1tbWora1F9+7d671P3r59+ybHEBkZiaKiIvzzn/+Ep6cnbGxsMGzYMFRVVWmNVaVSNfm4jWECIiIyIz169EBqaiqcnZ0hFte/xXyXLl1w5swZjbOgM2fONNpvVlYWli1bhiFDhgAAioqK1MueCYX3gIiIzMioUaPg6uqKcePGISMjAzdv3sSJEycwb948XL9+HQAwffp0bNu2DV988QWuX7+OhIQE/PDDD4326+Pjgx07duDq1as4e/YsJk+ejLZt25riIzWIZ0BkUtrmCeXevA0EmC4eInNjb2+PAwcOYNGiRXjzzTdx//59uLm54cUXX1SfEQ0fPhw3b97E0qVLoVQq8eqrr+Ltt9/G1q1bG+x3zZo1iI6OxoABA+Dm5oa5c+eiuLjYVB+rXkxAZFLa5gk5XZtnwmiIjG///v11yh7PzXnSzz//rP63q6ur1seqY2JiEBMTo1H25LzJP8+j7N69u3pe0WOP5x09VlBQUOee2KVLlxqNozl4CY6IiATBBERERIJgAiIiIkEwARERkSCYgIiISBBMQEREJAg+hk0atK3Fxnk6RGQoTECkQdtabJynQ0SGwktwREQkCCYgIiISBC/BEelJ230yH5d2WLVgtgkjImqZmICI9KR1z6LzKaYLhqgF4yU4IiIjCg0NRUxMDObNm4eOHTvCx8cHycnJePDgAWbNmgVPT09069YN//nPf9TvuXPnDiZPngwvLy94eXnh9ddfV2/FAAB5eXkYO3YsOnfujGeeeQYvvfQSvvnmG43jdu/eHfHx8YiOjoaHhwf8/PywatUqk31uXTABEREZ2c6dO+Hg4IDDhw8jOjoacrkc48ePh4+PD77//nuMGTMGM2fOREFBASoqKjB06FDY2Nhg//79OHToEKRSKcLCwlBRUQEAKCsrw6BBg7Bnzx5kZGRg2LBhmDhxosaK2gCQlJQEPz8/HD16FFFRUViwYAFOnTolxBDUiwmIiMjIfH19IZfL4ePjg3feeQcuLi6wtrZGZGQkvL29MWfOHKhUKmRnZ2PXrl1QqVRISkpCt27d0LlzZ3z22WcoLy/Ht99+C+DR2c3kyZPh7+8Pb29vzJo1Cz169EBaWprGcUNCQjBt2jR4e3sjIiIC3t7eOHr0qBBDUC/eA6JWhw8RWJbYzFjEZceZ7Hhz+s2B/Hm59oZP8Pf3V/9bJBJBIpFolLVp0wZisRgKhQJXr15Ffn4+3N3dNfqoqKhAXl4eAKC8vBxxcXH49ttvUVBQgOrqalRWVmr0+efjAoCbmxsUCoVesRsTExC1OnyIwLLIn5frnRAeq6ysrLMBmzG0adNG47VIJIK1tXWdstraWtTW1qJ79+7YuHFjnX7at28PAPjoo4/w3XffYenSpfDx8YG9vT2mT5+OqqoqrcdVqVSG+EgGwQRERGRGevTogdTUVDg7O6u34P6zrKwsjBkzBmFhYQAeJdK8vDz4+PiYMtRm4z0gIiIzMmrUKLi6umLcuHHIyMjAzZs3ceLECcybN0/9JJyPjw++/vprnD9/HpcvX8a0adPw4MEDgSPXHxMQEZEZsbe3x4EDB9CxY0e8+eabCAwMRGRkJEpKStRnRJ988gkkEglee+01jBo1Cn379sXzzz8vcOT64yU4IiIj2r9/f52yzMzMOmVPPkLt6uqKpKSkBvv09PSs88Tbu+++q/H60qVLOsUiJJ4BERGRIJiAiIhIEGaTgBISEiAWizF79h/zL1QqFWJjY+Hr6ws3NzeEhobiypUrAkZJRESGYhYJ6PTp09i0aVOdSVMrV65EYmIi4uLicOTIEUgkEoSHh6O0tFSgSImIyFAET0D37t3D1KlTsWbNGo1n3lUqFZKTkxEdHY2wsDD4+fkhOTkZZWVlSE1NFTBiIiIyBMET0OME89JLL2mU5+fno7CwECEhIeoyOzs7BAcHIzs729RhEpEZMKdZ/PRIc/6bCPoY9hdffIEbN25g/fr1deoKCwsBABKJRKNcIpHgt99+a7Tf3NxcwwXZwuk7FsoKZaP1NTW1gtbrQlmhrPdzPy7T9hmvXv4RIVPnNFif/1sBEKD/8c2JucfXkLKyMjg7O0MkEhmsz8rKSoP1ZQn0GQ+VSoW7d++ioqICRUVFdeplMlmj7xcsAeXm5mLJkiX45ptv6qxX1FzaPnRrkZubq/dY2NnbNVpvZdX4SbOx63VhZ29X53M/ORbaPuNDGwecDZ7ZYL1T6jy9j29OmvK9MBfV1dUoL294IVl93b9/H05OTgbrr6VrynhIpdI669rpSrAEdOrUKRQXFyMoKEhdVlNTg5MnT2Ljxo3IysoCACgUCnh4eKjbKBQKuLq6mjxeIhKetbU1nn76aYP1V1RUpPH3pbUz9XgIloBCQ0PRs2dPjbIZM2bAx8cHMTEx6NSpE6RSKdLT09GrVy8Aj04NMzMzsWTJEiFCJiIiAxIsAYnF4jorvdrb26N9+/bw8/MDAERGRiIhIQEymQydOnXCihUr0K5dO4wcOVKIkImIyIDMei24qKgoKJVKzJ49GyUlJejduzd2794NR0dHoUMjIqJmMqsE9OeF8kQiEeRyOeTypm02RURE5kvweUBERNQ6MQEREZEgdEpAq1evRm1t8ycIEhERPaZTAlqwYAFCQkJw/vx5Y8dDRESthE4JaPPmzfj999/x8ssvY968eaioqDB2XEREZOF0SkChoaE4deoUIiIisG7dOgQFBeHQoUPGjo2IiCyYzo9h29vb45NPPsGYMWPw3nvvYfTo0Rg2bFid1QyAR49Pz5zZ8FpaREREes8D6t69O1auXImhQ4ciLS0NaWlpddowARERkTZ6JaCqqiosX74cq1evhouLCzZt2lTvGRAREZE2Oiego0ePIiYmBnl5eZg0aRIWLlzIZcyJiKjJdEpAERER2LlzJ7p06YKDBw+iX79+xo6LjGTmknhcL254P5Xcm7cb3WyNiMhQdEpAaWlpkMvliI6ONvjmcWRa14vLcSJgaoP1Ttca32yNiMhQdEpAJ06cgI+Pj7FjISKiVkTnteCkUik++uijRtt89NFHcHNzQ35+frMDIyIiy6ZTAlq3bh0kEonWBDR//nxIJBKsW7fOIMEREZHl0ikBpaenY/jw4Wjbtm2j7WxsbDB8+HB89913BgmOiIgsl04J6Pbt25DJZDp12KlTJ9y+fbtZQRERkeXTKQG1bdsWlZWVOnX44MEDWFub1UarRERkhnRKQN7e3sjMzNSpw5MnT8Lb27tZQRERkeXTKQENHToUe/fu1ZqEsrKysHfvXgwbNswgwRERkeXSKQFNnz4dXl5eGDlyJBISEvDrr79q1N+5cwcJCQkYOXIkPD09ERERYZRgiYjIcuh0s6Zdu3bYs2cPJkyYgKVLl+Ljjz+Gk5MTHBwcUFZWhvv370OlUqFbt2746quv4ODgYOy4iYiohdP5aQFPT098//33SEtLw8GDB5GTk4PS0lJ4eXmhS5cuePXVVzFs2DBYWVkZM14iIrIQej2u9tRTTyE8PBzh4eHGioeIiFoJnZfiISIiMiSdzoDi4uL07njOnDl6v4eIiFoPnRLQsmXLdOpMJBKp/80EREK5lnMVoVGLNMqUFUrY2dsB4J5HROZCpwR0/fp1rW2ysrIQFxeHixcvwtXVtdmBETWV0sqWex4RtQA6JSBnZ+cG606fPo1ly5YhPT0dLi4uWLJkCaZMmWKwAImIyDI1edG2M2fOIDY2Vp14Fi1ahClTpsDe3t6Q8RERkYXS+ym4M2fOYOTIkRg8eDAuXLiARYsW4cKFC5g5c6ZeySclJQXBwcHw8PCAh4cHBg0ahG+//VZdr1KpEBsbC19fX7i5uSE0NBRXrlzRN1wiIjJTOiegH374AaNGjcKgQYNw/vx5LFy4EBcvXtQ78Tz2zDPPYPHixTh69CjS09Px0ksvYfz48fjxxx8BACtXrkRiYiLi4uJw5MgRSCQShIeHo7S0VO9jERGR+dHpEtyoUaNw+PBh9aW2qVOnNvtSW2hoqMbrjz76CJ9//jlOnz4Nf39/JCcnIzo6GmFhYQCA5ORkyGQypKamYtKkSc06NhERCU+nBPTdd99BJBLBxsYGW7duxdatWxttLxKJkJWVpXMQNTU1+O9//4vy8nIEBgYiPz8fhYWFCAkJUbexs7NDcHAwsrOzmYCIiCyATgkoODhYY46PoVy+fBmDBw9GZWUl2rVrh82bN8Pf3x/Z2dkAAIlEotFeIpHgt99+M3gcRERkejoloP379xvl4DKZDMePH8f9+/eRlpaGyMhIfP31183uNzc31wDRWYY/j4WyQtlo+5qaWrOu14XQMSorlGb/HTT3+EyJY6HJkOMhk8karRd07+y2bduqd08NCAjA2bNnkZSUhFmzZgEAFAoFPDw81O0VCoVOk1y1fejWIjc3t85YPF4NoCFWVo0/lyJ0vS6EjtHO3s6sv4P1fS9aK46FJlOPh06/7Zs2bUJeXp76dW1tLa5du4bKyso6bS9cuIAFCxY0KZja2lpUVVXBy8sLUqkU6enp6rrKykpkZmaiX79+TeqbiIjMi04JKCYmBmfOnFG/LikpQWBgoPpezZNycnKwZs0arX0uWrQIJ0+eRH5+Pi5fvozFixcjIyMDo0aNgkgkQmRkJFauXIm9e/fip59+wttvv4127dph5MiRenw8IiIyVzpdglOpVDqV6aOwsBDTpk1DUVERnJyc4O/vj9TUVAwcOBAAEBUVBaVSidmzZ6OkpAS9e/fG7t274ejo2KzjEhGReRDsHlBycnKj9SKRCHK5HHK53EQRERGRKXFDOiIiEgQTEBERCULnS3BnzpyBtfWj5qWlpRCJRDhx4gTu3r2r0e706dOGjZCIiCySzglo/fr1WL9+vUZZfHx8vW2NsWoCERFZFp0S0L59+4wdBxERtTI6JaAXXnjB2HEQEVErw4cQiIhIEDrvB9SQx9s0eHh4YMiQIejfv7/BgiMiIsulUwK6evVqow8WKJVKfP3111i7di3+/ve/49///jesrKwMFiQREVkenRLQpUuXtLYpKSnB2rVrERcXh8TERMycObPZwRERkeUy2D0gsViMuXPnIjQ0FNu3bzdUt0REZKEM/hDCiy++qLF1AxERUX0MnoCqq6s5EZWIiLQyeAJKT0/nDoNERKSVwRLQtWvX8MEHH+DIkSOYMGGCobolIiILpdNTcG5ubo1eVquqqoJKpYJKpcL//u//YsqUKQYLkIiILJNOCSg8PLzRBGRrawsPDw+8/PLL6N69u8GCIyIiy6VTAtK2eykREZG+uBYcEREJQuf9gACgtrYW+/btw8GDB5GTk4OysjJ06NABHTt2RHh4OF5++WU89RRzGhERaadzAsrLy8Mbb7yBH3/8ESqVCo6OjnB0dMTly5eRlZWF7du3IyAgAJs2bYKnpycA4PDhwxg4cKDRgiciopZLp9OVkpISDB06FNevX8fcuXNx4cIF3Lp1C5cvX8atW7dw8eJFzJ07Fz///DOGDRuG8vJybNmyBWPHjjV2/ERE1ELpdAaUkJCA33//HQcPHkTPnj3r1Ht4eOCDDz7AoEGD8Nprr+GVV17B5cuXMXjwYIMHTERElkGnBHTgwAFMmDCh3uTzpJ49e2LcuHHYuHEjJk6ciM8++8wgQZLuZi6Jx/XicgCAskIJO3s7jfrcm7eBACEiIyLSpFMC+uWXX9CjRw+dOgwICIBIJMKqVauaFRg1zfXicpwImNpgvdO1eSaMhoioYTrdA7Kzs0NJSYlOHZaUlODpp59uVlBERGT5dEpAvXr1ws6dO6FSqRptV1tbi9TUVK2X6oiIiHS6BDd16lSMHTsW06ZNw7/+9S84ODjUaVNeXo733nsPly5dwrZt2wweKFFLcS3nKkKjFjVY7+PSDqsWzDZdQERmSqcE9Morr2DGjBlITEzE4cOHERoaCn9/fzg4OKCsrAyXL1/G/v378X//93+YMWMGhgwZYuy4icyW0sq20ftwOJ9iumCIzJjOE1E//vhjBAQEIC4uDps3b65TL5PJEB8fjxEjRhg0QCIiskx6LcUzcuRIjBw5Ejdu3MDVq1dRVlYGBwcH+Pr6wtvb21gxEhGRBdIrAT3m7e3d7ISTkJCAffv24dq1a2jbti369OmDhQsXws/PT91GpVJh2bJl+OKLL1BSUoLevXtjxYoV6Nq1a7OO3VI9OcenIZznQ0QthU4JaNOmTejfvz+ee+45AI+edrtx4wbc3d1ha2ur0fbChQvYtWsXlixZ0mifGRkZeOutt9CrVy+oVCr885//xD/+8Q9kZ2ejffv2AICVK1ciMTERiYmJkMlkWL58OcLDw3H69Gk4Ojo25fO2aNrm+ACc50NELYdOj2HHxMTgzJkz6tclJSUIDAxEdnZ2nbY5OTlYs2aN1j53796NCRMmwM/PD/7+/li3bh1+//13ZGVlAXh09pOcnIzo6GiEhYXBz88PycnJKCsrQ2pqqq6fj4iIzJROCai++T/a5gTpq6ysDLW1tRCLxQCA/Px8FBYWIiQkRN3Gzs4OwcHB9SY+IiJqWZp0D8gY5s6di+7duyMwMBAAUFhYCACQSCQa7SQSCX777bdG+8rNzTVOkAJTVii1tqmpqbXoel0IHaO2emWFUvDvqNDHNyccC02GHA+ZTNZovVkkoA8//BBZWVn45ptvYGVl1ez+tH3olurPC4vWx8qq8ZPall6vC6Fj1FZvZ28n6Hc0NzfXYn9H9MWx0GTq8RB8+1K5XI5du3Zh79696Nixo7pcKpUCABQKhUZ7hUIBV1dXU4ZIRERGoPMZ0JkzZ2Bt/ah5aWkpRCIRTpw4gbt372q0O336tM4HnzNnDvbs2YN9+/ahc+fOGnVeXl6QSqVIT09Hr169AACVlZXIzMzU+oQdERGZP50T0Pr167F+/XqNsvj4+HrbikQirf3NmjUL27dvx+bNmyEWi9X3fNq1awcHBweIRCJERkYiISEBMpkMnTp1wooVK9CuXTuMHDlS17BbFG3zfDjHh3TV2HdJWaFEN48OXI+OBKdTAtq3b5/BD7xhwwYAQFhYmEb5nDlzIJfLAQBRUVFQKpWYPXu2eiLq7t27LXYOEPfyIUPR9l2y43p0ZAZ0SkAvvPCCwQ+sy/5CIpEIcrlcnZCIiMhyGPwhhOrq6noXKyUiInqSwR7DViqV2LRpExITE3Hnzh1MmDDBUF0TWRRt+wUBQFH+Nbh6dWqwnnsKkSXQOQF9+eWXSE5ORl5eHsRiMcLCwrBkyRLY2Nhg7dq1WLFiBYqLi+Hv74/58+cbM2aiFk3rfkF4dL8vl3sKkYXTKQH95z//QVRUFBwcHODn54c7d+4gJSUFlZWVuHfvHtLS0tC/f39ERUXhb3/7m7FjJiIiC6BTAkpJSYFMJsPBgwfh4uKCmpoavP322/jqq68gFouxa9cujTXbiIiItNHpIYSrV69i4sSJcHFxAQBYWVkhOjoaKpUKs2bNYvIhIiK96ZSAKioq4ObmplH2eKmc1ro5HBERNY/Oj2E3tLqBIRYPJSKi1kfnp+BWrlyJ7du3q18/fPgQALB48WI4OztrtBWJRNixY4eBQiQiIkukUwJyd3fHvXv3cO/ePY1yDw8PKBSKOitW67IWHBERtW46JaBLly4ZOw4iImpldLoH9MEHH+D8+fMaZRUVFQbflpuIiFoPnRJQSkqKxjatd+/ehbu7O44dO2a0wIiIyLI1eTFSnv0QEVFzGGwxUiKiJ2nbYJELqhITEBEZhbZN8bigKumcgG7evIkffvgBAHD//n0AQG5uLhwcHOpt37t3bwOER0RElkrnBBQbG4vY2FiNsg8++KBOO5VKBZFIhLt37zY/OiIislg6JaDExERjx9EqaLsmnnvzNhBgwoCIiASkUwIaN26cseNoFbRdE3e6Ns+E0RARCavJj2ETERE1BxMQEREJgo9hE7VA13KuIjRqUYP1vJ9ILQETEFELpLSy5f1EavF4CY6IiATBBERERILgJTiiVkjbPSSu00amwARE1Appu4fEddrIFHgJjoiIBMEEREREghA0AZ04cQJjxoxB165dIRaLsWXLFo16lUqF2NhY+Pr6ws3NDaGhobhy5YpA0RIRkSEJmoDKy8vh5+eHZcuWwc7Ork79ypUrkZiYiLi4OBw5cgQSiQTh4eEoLS0VIFoiIjIkQRPQ4MGDsWDBAoSFheGppzRDUalUSE5ORnR0NMLCwuDn54fk5GSUlZUhNTVVoIiJiMhQzPYeUH5+PgoLCxESEqIus7OzQ3BwMLKzswWMjIiIDMFsE1BhYSEAQCKRaJRLJBIUFRUJERIRERmQRc4Dys3NFTqEeikrlI3W19TUNqveEH2Ye70uhI7REv47KiuUzf490vZ9N8QxDMEcYjAnhhwPmUzWaL3ZJiCpVAoAUCgU8PDwUJcrFAq4uro2+l5tH1oodvZ1H7R4kpVV4yek2uoN0Ye51+tC6Bgt4b+jnb1ds3+PtH3fDXGM5srNzRU8BnNi6vEw20twXl5ekEqlSE9PV5dVVlYiMzMT/fr1EzAyIiIyBEHPgMrKynDjxg0AQG1tLX755RdcvHgR7du3h4eHByIjI5GQkACZTIZOnTphxYoVaNeuHUaOHClk2EREZACCJqBz585h6NCh6texsbGIjY3F2LFjkZycjKioKCiVSsyePRslJSXo3bs3du/eDUdHRwGjJiIiQxA0Ab344osoKSlpsPcgRVcAABAESURBVF4kEkEul0Mul5swKiIiMgWzvQdERESWjQmIiIgEYbaPYbdEM5fE43pxeYP1uTdvAwEmDIioibhhHZkCE5ABXS8ub3STL6dr80wYDVHTccM6MgVegiMiIkEwARERkSB4CY6IBMH7TMQERESC4H0m4iU4IiISBBMQEREJggmIiIgEwQRERESCYAIiIiJBMAEREZEgmICIiEgQnAdERHrTNokUMP7iu9oW/23uRFZt/RviGK0dExAR6U3rJFIYf/FdbYv/Nnciq9b+DXCM1o6X4IiISBBMQEREJAhegiMis6TtPhM3eGz5mICIyCxpu8/EDR5bPl6CIyIiQTABERGRIHgJTg/a5gXwmjSR+dBlw7t3x/7DdAFRHUxAetA2L4DXpInMBze8M3+8BEdERIJgAiIiIkHwEhwRtUrXcq4iYvkG2Nnb1VvPe7rGxwRERK2S0soWZ4NnNljPe7rGx0twREQkCCYgIiISRIu4BLdhwwasWrUKhYWF8PX1RWxsLIKDgw1+HM7zISJDMvaeRYbwZIzKCmWde2LGjNHsE9Du3bsxd+5cfPrppwgKCsKGDRswatQoZGVlwcPDw6DH4jwfIjIkY+9ZZAhCxmj2l+ASExMxbtw4vPHGG+jSpQvi4+MhlUqxceNGoUMjIqJmEJWUlKiEDqIhVVVV+J//+R98/vnn+Mc//lgyY9asWfjpp59w4MABAaMjIqLmMOszoOLiYtTU1EAikWiUSyQSFBUVCRQVEREZglknICIislxmnYBcXFxgZWUFhUKhUa5QKODq6ipQVEREZAhmnYDatm2LgIAApKena5Snp6ejX79+AkVFRESGYPaPYc+YMQMRERHo3bs3+vXrh40bN6KgoACTJk0SOjQiImoGsz4DAoDhw4cjNjYW8fHxCA4OxsaNG1FVVYWJEyfi5MmTjb43IyMD/fv3h1QqRY8ePSzu0e0NGzbgL3/5C6RSKfr379/oeBQUFGDKlCno27cvnJ2dERkZacJIjU+fsdi7dy/Cw8Ph4+MDd3d3DBw40KKeqNRnLDIyMjB48GA899xzcHNzQ9++fbF69WoTRmtc+ozFkzIzM+Hi4oLnn3/eyBGajj5jcfz4cYjF4jo/P//8s0FjMvsEBABTpkzB4sWLIRKJsGLFCmRkZCAwMBCjRo3C7du3633PzZs38frrryMwMBDHjh1DTEwMPvjgA6SlpZk4euN4PEH3/fffx7Fjx7SOx4MHD+Ds7Izo6Gj06dPHxNEal75jceLECbz00kvYsWMHjh07hkGDBmHChAk6/3EyZ/qOhYODAyIiInDgwAFkZWVh1qxZiI2NxYYNG0wcueHpOxaPlZSUYPr06ejfv7+JIjW+po5FVlYWcnJy1D8+Pj4Gjcus5wE9aeDAgfD398eqVavUZb169UJYWBgWLlxYp/3ChQuxb98+nD17Vl327rvv4urVqzh06JBJYjYmfcfjSaNHj4azszOSk5ONHaZJNGcsHgsJCcHzzz+PTz75xFhhmoQhxmLChAmwsbHB559/bqwwTaKpYzFhwgR069YNKpUKe/fuRWZmpinCNSp9x+L48eMYOnQorl+/DhcXF6PF1SLOgKqqqnD+/HmEhIRolIeEhCA7O7ve95w6dapO+4EDB+LcuXN4+PCh0WI1haaMh6Uy1FiUlZVBLBYbOjyTMsRYXLhwAadOncJf//pXY4RoMk0diw0bNkChUGD2bGHXZzOk5nwvBgwYgC5dumDYsGE4duyYwWMz+4cQgKZNSC0qKsKAAQPqtK+urkZxcTHc3NyMFa7RcYLuHwwxFikpKbhz5w5Gjx5tjBBNpjlj4efnh99//x3V1dWYM2cOJk+ebMxQja4pY3H58mXExcXh0KFDsLKyMkWYJtGUsXBzc0NCQgJ69eqFqqoqbN++HWFhYdi/f79BF4JuEQmIyFjS0tKwYMECbNy4EZ6enkKHI5gDBw6gvLwcZ86cwcKFC+Hl5YUxY8YIHZbJPHjwAJMnT8bSpUvRsWNHocMRnEwmg0wmU78ODAzErVu3sGrVqtaXgJoyIdXV1bXe9tbW1ka9pmkKnKD7h+aMRVpaGqZPn461a9fi1VdfNWaYJtGcsXj8R9ff3x9FRUVYtmxZi05A+o5FQUEBcnJyMGPGDMyYMQMAUFtbC5VKBRcXF+zcubPOJayWwlB/L3r37o3du3cbNLYWcQ+oKRNSAwMD623fs2dPtGnTxmixmgIn6P6hqWOxZ88eREREICkpCWFhYcYO0yQM9b2ora1FVVWVocMzKX3H4plnnsHJkydx/Phx9c/kyZPh7e2N48ePIzAw0FShG5yhvheXLl2CVCo1aGwt4gwI0D4hNSIiAgCwbt06AMCkSZOQkpKCuXPnYtKkScjOzsbWrVst4vFSQP/xAICLFy8CAO7fvw+RSISLFy+ibdu28PX1Nf0HMCB9x2LXrl2IiIjA0qVLERwcjMLCQgCPflHbt28vzIcwEH3HYt26dfDy8lJfbjlx4gTWrFmDt956S5gPYED6jEWbNm3g5+en8f4OHTrAxsamTnlLpO/3IikpCZ6enujatSuqqqqwY8cO7N+/H19++aVB42oxCWj48OG4e/cu4uPjUVhYiK5du2LHjh3q6/a//PKLRvuOHTtix44d+PDDD7Fx40a4ubkhLi7OYv5vV9/xAICXXnpJ4/U333wDDw8PXLp0ySQxG4u+Y7Fx40ZUV1dDLpdDLpery//6179i//79Jo3d0PQdi5qaGixatAi3bt2CtbU1OnbsiIULF7b4hxCApv2OWCp9x+Lhw4dYsGAB7ty5A1tbW3X7wYMHGzSuFjMPiIiILEuLuAdERESWhwmIiIgEwQRERESCYAIiIiJBMAEREZEgmICIiEgQTEBERCQIJiCyGHv37oVYLMaePXvq1L366qsQi8XYu3dvnbrBgweja9euAIDQ0FD07dtXo7579+4Qi8V477336rz33LlzEIvF2LJli7psy5YtGrtISqVS+Pr6Yvjw4Vi7di1KS0vrjf/06dMYPXo0/Pz8IJVK4efnh/DwcKxfv77eeB7/PPvssxg4cCC2bdum0S40NLTeXS3FYjE6d+6sbtfQ7pePf57cSfjJPtu3bw8PDw/06dMH06ZNq7PUC5E2LWYlBCJtHm+fnJmZifDwcHV5VVUVzp07B2tra2RlZWHYsGHqusrKSpw/fx6hoaFa+9+yZQtiYmLg4eGhUzxz587Fc889h4cPH6KoqAgZGRmQy+VITEzEtm3b0K1bN3XbtLQ0vPnmm+jatSumTJmCDh064NatWzhz5gySkpIwbdo0jb79/f0xc+ZMAI8W0ty0aRMiIyOhVCo1VjFwc3PD4sWL68Rma2tbp2zq1Kn17pb757In+6yoqMCNGzewb98+7NixQ50wW/p6i2QaTEBkMSQSCXx8fJCVlaVRfu7cOVRWVuL111+vU/fDDz+gqqoKQUFBjfbt6+uLGzduICEhAf/61790imfgwIEaZ1MxMTE4evQoxowZg7Fjx+LUqVOws7MDAMTGxqJTp044cuRIneRQ354tbm5uGvsXjRkzBr169UJSUpJGAnJ0dNR5n6OgoCCMGDFCa7v6+ly0aBHmzJmDDRs2wNPTs96kR/RnvARHFiUoKAiXL1/WuMyVnZ0Nd3d3DB8+HBcvXkRFRYVGHfDH2VNDnn32WYwfPx6bN2/G7du3mxxf//79MXv2bNy+fRs7duxQl+fl5aFnz571npnosmS+VCpF586dkZ+f3+TYmsPKygpxcXHw9fVFSkoK7t27J0gc1LIwAZFFCQoKQk1NDU6fPq0uy8zMRFBQEAIDA+vUZWVlwcnJSeNyWENiYmIgEonw6aefNivGx2cPR44cUZd5enoiIyOjycnt4cOH+PXXX+Hs7KxRXlNTg+Li4jo/9d2HKisrq7dtTU2NTjFYWVlhxIgRqKioqHOmSVQfJiCyKE/eB3rs1KlT6NevH5ydnSGTydR/HFUqFbKzs9G3b1889ZT2XwUPDw9MmDABW7Zswa1bt5oc47PPPgsnJyfk5eWpy9577z3cuXMHvXr1wmuvvYalS5fi2LFjqK6urrePhw8fqhPEjz/+iOnTp6OoqKjOau83btyAj49PnZ+oqKg6fUZFRdXb9vr16zp/tscPczz52YgawntAZFE6deoEiUSiTjI5OTkoLi5Wb7wVGBiorvvpp59w7949rZffnhQTE4PNmzfj008/xcqVK5scp4ODA8rKytSvx40bBxcXFyQlJSEzMxMnT57Ep59+CqlUilWrVmHIkCEa7z927Bh8fHzUr9u0aYO33nqrzr0Xd3d3rFmzps7x67usN2vWLLzwwgt1yt3d3fX6XAA0PhtRQ5iAyOL069cPR44cQXV1NbKzs+Ho6Ah/f3913Ycffoiamhr1/R9tDyA8yd3dHRMnTsSXX36J999/v8kxlpWVoUOHDhplQ4YMwZAhQ1BZWYkff/wR+/btw9q1azFx4kRkZGRoPDrds2dPLFy4ECKRCC4uLujYsaP6j/+T7OzsMGDAAJ1i6tq1q85tG/I48dQXC9Gf8RIcWZygoCBUVFTgwoULyMzMRJ8+fWBlZQXgUQIqLS3FpUuXkJWVhbZt26J379569d/ce0G//vor7t+/D29v73rrbW1t0adPHyxevBgrVqxAVVVVnblNzs7OGDBgAPr3749u3bqZzR/8K1euAECDn43oSUxAZHGevA+UlZWlcYYjk8ng7OyMrKwsZGZmIiAgQP0otK6effZZTJw4EVu3bm3SvaDt27cDAEJCQrS2fZwcCwoK9D6OqdXU1CA1NRX29vZ6nVVS68UERBanR48esLe3x969e5GXl6fxx1AkEqFv377Ys2cPbt++3eQ/lDExMXjqqaf0Pgs6evQo4uPj4eXlhddff11d3tAqAocOHQLwKHGas5qaGsyZMwc5OTmIiIiAk5OT0CFRC8B7QGRxrK2t0bt3bxw/fhxWVlZ1LrEFBQWpb9Y3NQE9PgvasGFDg20OHz6MGzduoLq6GgqFAseOHUN6ejo8PDywbds2jTk/EyZMgIeHB1555RV4e3ujsrISp06dwp49e9CxY0eMHz++SXGWlpaqz7j+bMSIEbC2/uNPQFZWVr1P3XXp0gUBAQH19qlUKtUrIeTl5WHEiBGYN29ek2Kl1ocJiCxSUFAQjh8/Xu/9kcdPxIlEomZdKnrvvffw1Vdf4cGDB/XWL1u2DADQtm1btG/fHn5+foiNjcX48ePh6Oio0Xb16tU4ePAg9u3bh4KCAjx8+BCenp6YNm0a3n//fTz99NNNirGgoAARERH11oWGhmqMTUpKClJSUuq0e+eddzQS0JN9Ojg4QCqVom/fvkhISMDf/va3JsVJrZOopKREJXQQRETU+vAeEBERCYIJiIiIBMEEREREgmACIiIiQTABERGRIJiAiIhIEExAREQkCCYgIiISBBMQEREJggmIiIgE8f8q0dKkvgwNdAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task3 & Task4**\n",
        "Dividing data in training and testing and then Seperating features(droping some) and labels from dataset "
      ],
      "metadata": {
        "id": "zkEBMzGttP4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using OHE on all the categorical features\n",
        "categorical_cols = ['season', 'mnth', 'holiday','weekday','workingday','weathersit']\n",
        "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Splitting Dataset into testing and training (3:7)\n",
        "training_data = data.sample(frac=0.7, random_state = 25)\n",
        "testing_data = data.drop(training_data.index)\n",
        "\n",
        "# Dropping useless columns\n",
        "X_train = training_data.drop(columns=['instant', 'dteday','yr','rentals']).to_numpy()\n",
        "Y_train = training_data['rentals'].to_numpy() \n",
        "\n",
        "X_test = testing_data.drop(columns=['instant', 'dteday', 'yr', 'rentals']).to_numpy()\n",
        "Y_test = testing_data['rentals'].to_numpy()"
      ],
      "metadata": {
        "id": "6mywEeT9tZiN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task5 & Task6 & Task7**\n",
        "Build suitable Machine Learning model, Predicting on Test data, Calculating R-Squared to find accuracy.\n"
      ],
      "metadata": {
        "id": "L2ZzwUdSz3GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Did experimentation with Linear Regression(R2 Score = 0.65), Ridge Regression(R2 Score = 0.688 with best_alpha=3), Lasso Lars(R2 Score = 0.6517), \n",
        "# Bayesian Ridge Regression(R2 Score = 0.6820), and Finally using Multi-layer Perceptron Regression(R2 Score = 0.779) using nuerons_list as [28, 100, 1]\n",
        "# Using Early Stopping criteria on Neural Network to get maximum validation error\n",
        "\n",
        "nn = MLPRegressor(random_state = 1, max_iter = 50000, activation = 'logistic', solver = 'adam', shuffle = True, tol = 1e-15, verbose = True, early_stopping=True)\n",
        "nn.fit(X_train, Y_train)\n",
        "\n",
        "# Predicting on test data\n",
        "Y_pred = nn.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt5lMEWL0Clu",
        "outputId": "285d2dd8-c484-4ada-a21d-7a18c2f1474b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Validation score: 0.554913\n",
            "Iteration 4999, loss = 99447.86222322\n",
            "Validation score: 0.555059\n",
            "Iteration 5000, loss = 99416.12810616\n",
            "Validation score: 0.555198\n",
            "Iteration 5001, loss = 99384.72191228\n",
            "Validation score: 0.555333\n",
            "Iteration 5002, loss = 99349.66645548\n",
            "Validation score: 0.555458\n",
            "Iteration 5003, loss = 99317.82350649\n",
            "Validation score: 0.555590\n",
            "Iteration 5004, loss = 99283.29621132\n",
            "Validation score: 0.555732\n",
            "Iteration 5005, loss = 99251.12277290\n",
            "Validation score: 0.555873\n",
            "Iteration 5006, loss = 99216.40881162\n",
            "Validation score: 0.556010\n",
            "Iteration 5007, loss = 99185.87161560\n",
            "Validation score: 0.556130\n",
            "Iteration 5008, loss = 99149.75974210\n",
            "Validation score: 0.556252\n",
            "Iteration 5009, loss = 99119.14055746\n",
            "Validation score: 0.556369\n",
            "Iteration 5010, loss = 99086.44684954\n",
            "Validation score: 0.556512\n",
            "Iteration 5011, loss = 99053.46420621\n",
            "Validation score: 0.556661\n",
            "Iteration 5012, loss = 99021.01040645\n",
            "Validation score: 0.556799\n",
            "Iteration 5013, loss = 98993.39666949\n",
            "Validation score: 0.556934\n",
            "Iteration 5014, loss = 98960.16812321\n",
            "Validation score: 0.557075\n",
            "Iteration 5015, loss = 98930.66437185\n",
            "Validation score: 0.557216\n",
            "Iteration 5016, loss = 98899.53337620\n",
            "Validation score: 0.557373\n",
            "Iteration 5017, loss = 98867.49313363\n",
            "Validation score: 0.557527\n",
            "Iteration 5018, loss = 98836.92461268\n",
            "Validation score: 0.557676\n",
            "Iteration 5019, loss = 98806.11477769\n",
            "Validation score: 0.557832\n",
            "Iteration 5020, loss = 98772.61969353\n",
            "Validation score: 0.557975\n",
            "Iteration 5021, loss = 98740.23407154\n",
            "Validation score: 0.558111\n",
            "Iteration 5022, loss = 98709.14296347\n",
            "Validation score: 0.558238\n",
            "Iteration 5023, loss = 98676.49947360\n",
            "Validation score: 0.558360\n",
            "Iteration 5024, loss = 98645.81390931\n",
            "Validation score: 0.558503\n",
            "Iteration 5025, loss = 98612.42431816\n",
            "Validation score: 0.558658\n",
            "Iteration 5026, loss = 98577.52852694\n",
            "Validation score: 0.558826\n",
            "Iteration 5027, loss = 98550.12164094\n",
            "Validation score: 0.558986\n",
            "Iteration 5028, loss = 98517.37524136\n",
            "Validation score: 0.559143\n",
            "Iteration 5029, loss = 98485.74863512\n",
            "Validation score: 0.559288\n",
            "Iteration 5030, loss = 98454.01680943\n",
            "Validation score: 0.559433\n",
            "Iteration 5031, loss = 98421.54575566\n",
            "Validation score: 0.559586\n",
            "Iteration 5032, loss = 98389.45037646\n",
            "Validation score: 0.559736\n",
            "Iteration 5033, loss = 98357.87001677\n",
            "Validation score: 0.559876\n",
            "Iteration 5034, loss = 98323.88070742\n",
            "Validation score: 0.560013\n",
            "Iteration 5035, loss = 98290.87849901\n",
            "Validation score: 0.560154\n",
            "Iteration 5036, loss = 98259.18241308\n",
            "Validation score: 0.560269\n",
            "Iteration 5037, loss = 98228.59913719\n",
            "Validation score: 0.560385\n",
            "Iteration 5038, loss = 98193.39479755\n",
            "Validation score: 0.560517\n",
            "Iteration 5039, loss = 98161.62117810\n",
            "Validation score: 0.560650\n",
            "Iteration 5040, loss = 98128.96874479\n",
            "Validation score: 0.560773\n",
            "Iteration 5041, loss = 98098.27144157\n",
            "Validation score: 0.560900\n",
            "Iteration 5042, loss = 98065.72310443\n",
            "Validation score: 0.561021\n",
            "Iteration 5043, loss = 98034.05220841\n",
            "Validation score: 0.561143\n",
            "Iteration 5044, loss = 98002.51362247\n",
            "Validation score: 0.561251\n",
            "Iteration 5045, loss = 97968.93059039\n",
            "Validation score: 0.561365\n",
            "Iteration 5046, loss = 97936.51166115\n",
            "Validation score: 0.561478\n",
            "Iteration 5047, loss = 97907.01425680\n",
            "Validation score: 0.561590\n",
            "Iteration 5048, loss = 97876.58639811\n",
            "Validation score: 0.561713\n",
            "Iteration 5049, loss = 97845.03432222\n",
            "Validation score: 0.561842\n",
            "Iteration 5050, loss = 97813.84745568\n",
            "Validation score: 0.561974\n",
            "Iteration 5051, loss = 97782.96374296\n",
            "Validation score: 0.562117\n",
            "Iteration 5052, loss = 97750.85650801\n",
            "Validation score: 0.562277\n",
            "Iteration 5053, loss = 97720.39938008\n",
            "Validation score: 0.562441\n",
            "Iteration 5054, loss = 97688.66410901\n",
            "Validation score: 0.562595\n",
            "Iteration 5055, loss = 97652.95292635\n",
            "Validation score: 0.562721\n",
            "Iteration 5056, loss = 97617.98767341\n",
            "Validation score: 0.562833\n",
            "Iteration 5057, loss = 97590.73420058\n",
            "Validation score: 0.562935\n",
            "Iteration 5058, loss = 97552.70508248\n",
            "Validation score: 0.563056\n",
            "Iteration 5059, loss = 97520.58038291\n",
            "Validation score: 0.563187\n",
            "Iteration 5060, loss = 97487.74626621\n",
            "Validation score: 0.563319\n",
            "Iteration 5061, loss = 97455.17826024\n",
            "Validation score: 0.563465\n",
            "Iteration 5062, loss = 97425.21793871\n",
            "Validation score: 0.563608\n",
            "Iteration 5063, loss = 97389.35126439\n",
            "Validation score: 0.563760\n",
            "Iteration 5064, loss = 97360.02540224\n",
            "Validation score: 0.563903\n",
            "Iteration 5065, loss = 97329.09466373\n",
            "Validation score: 0.564035\n",
            "Iteration 5066, loss = 97297.39325235\n",
            "Validation score: 0.564167\n",
            "Iteration 5067, loss = 97267.44669243\n",
            "Validation score: 0.564297\n",
            "Iteration 5068, loss = 97237.03983716\n",
            "Validation score: 0.564413\n",
            "Iteration 5069, loss = 97207.63525890\n",
            "Validation score: 0.564528\n",
            "Iteration 5070, loss = 97177.42372692\n",
            "Validation score: 0.564662\n",
            "Iteration 5071, loss = 97146.25744647\n",
            "Validation score: 0.564795\n",
            "Iteration 5072, loss = 97115.83729736\n",
            "Validation score: 0.564927\n",
            "Iteration 5073, loss = 97082.33153923\n",
            "Validation score: 0.565072\n",
            "Iteration 5074, loss = 97052.95642941\n",
            "Validation score: 0.565225\n",
            "Iteration 5075, loss = 97020.96677322\n",
            "Validation score: 0.565381\n",
            "Iteration 5076, loss = 96989.06023051\n",
            "Validation score: 0.565534\n",
            "Iteration 5077, loss = 96957.80659561\n",
            "Validation score: 0.565688\n",
            "Iteration 5078, loss = 96926.76504219\n",
            "Validation score: 0.565834\n",
            "Iteration 5079, loss = 96894.94540236\n",
            "Validation score: 0.565989\n",
            "Iteration 5080, loss = 96862.64908447\n",
            "Validation score: 0.566132\n",
            "Iteration 5081, loss = 96832.14401499\n",
            "Validation score: 0.566276\n",
            "Iteration 5082, loss = 96802.11657453\n",
            "Validation score: 0.566417\n",
            "Iteration 5083, loss = 96772.34004650\n",
            "Validation score: 0.566554\n",
            "Iteration 5084, loss = 96742.79485595\n",
            "Validation score: 0.566686\n",
            "Iteration 5085, loss = 96713.93100829\n",
            "Validation score: 0.566819\n",
            "Iteration 5086, loss = 96685.39220263\n",
            "Validation score: 0.566952\n",
            "Iteration 5087, loss = 96659.41470383\n",
            "Validation score: 0.567092\n",
            "Iteration 5088, loss = 96629.83938701\n",
            "Validation score: 0.567202\n",
            "Iteration 5089, loss = 96599.56091019\n",
            "Validation score: 0.567324\n",
            "Iteration 5090, loss = 96571.01872316\n",
            "Validation score: 0.567446\n",
            "Iteration 5091, loss = 96541.12491202\n",
            "Validation score: 0.567565\n",
            "Iteration 5092, loss = 96511.44850812\n",
            "Validation score: 0.567683\n",
            "Iteration 5093, loss = 96481.10920797\n",
            "Validation score: 0.567804\n",
            "Iteration 5094, loss = 96450.08631565\n",
            "Validation score: 0.567929\n",
            "Iteration 5095, loss = 96417.26784754\n",
            "Validation score: 0.568046\n",
            "Iteration 5096, loss = 96388.15942735\n",
            "Validation score: 0.568182\n",
            "Iteration 5097, loss = 96355.33777604\n",
            "Validation score: 0.568327\n",
            "Iteration 5098, loss = 96327.11804878\n",
            "Validation score: 0.568477\n",
            "Iteration 5099, loss = 96297.25812917\n",
            "Validation score: 0.568621\n",
            "Iteration 5100, loss = 96267.15558498\n",
            "Validation score: 0.568752\n",
            "Iteration 5101, loss = 96236.86826912\n",
            "Validation score: 0.568885\n",
            "Iteration 5102, loss = 96207.84593036\n",
            "Validation score: 0.569023\n",
            "Iteration 5103, loss = 96177.82194622\n",
            "Validation score: 0.569149\n",
            "Iteration 5104, loss = 96146.92894720\n",
            "Validation score: 0.569277\n",
            "Iteration 5105, loss = 96117.21294394\n",
            "Validation score: 0.569414\n",
            "Iteration 5106, loss = 96088.06520759\n",
            "Validation score: 0.569549\n",
            "Iteration 5107, loss = 96057.46672767\n",
            "Validation score: 0.569673\n",
            "Iteration 5108, loss = 96026.06858278\n",
            "Validation score: 0.569798\n",
            "Iteration 5109, loss = 95996.76252532\n",
            "Validation score: 0.569910\n",
            "Iteration 5110, loss = 95965.15046789\n",
            "Validation score: 0.570019\n",
            "Iteration 5111, loss = 95934.50841264\n",
            "Validation score: 0.570138\n",
            "Iteration 5112, loss = 95901.47393540\n",
            "Validation score: 0.570264\n",
            "Iteration 5113, loss = 95869.90596905\n",
            "Validation score: 0.570387\n",
            "Iteration 5114, loss = 95840.58645792\n",
            "Validation score: 0.570506\n",
            "Iteration 5115, loss = 95809.20591410\n",
            "Validation score: 0.570621\n",
            "Iteration 5116, loss = 95780.09131464\n",
            "Validation score: 0.570745\n",
            "Iteration 5117, loss = 95747.44180658\n",
            "Validation score: 0.570875\n",
            "Iteration 5118, loss = 95717.78427529\n",
            "Validation score: 0.571008\n",
            "Iteration 5119, loss = 95685.98458571\n",
            "Validation score: 0.571130\n",
            "Iteration 5120, loss = 95654.96204469\n",
            "Validation score: 0.571253\n",
            "Iteration 5121, loss = 95624.44737480\n",
            "Validation score: 0.571383\n",
            "Iteration 5122, loss = 95593.66326040\n",
            "Validation score: 0.571511\n",
            "Iteration 5123, loss = 95561.11041639\n",
            "Validation score: 0.571642\n",
            "Iteration 5124, loss = 95533.10074931\n",
            "Validation score: 0.571785\n",
            "Iteration 5125, loss = 95503.29323406\n",
            "Validation score: 0.571922\n",
            "Iteration 5126, loss = 95475.51748103\n",
            "Validation score: 0.572046\n",
            "Iteration 5127, loss = 95445.26847333\n",
            "Validation score: 0.572149\n",
            "Iteration 5128, loss = 95415.91522437\n",
            "Validation score: 0.572242\n",
            "Iteration 5129, loss = 95384.39964643\n",
            "Validation score: 0.572316\n",
            "Iteration 5130, loss = 95354.94994119\n",
            "Validation score: 0.572381\n",
            "Iteration 5131, loss = 95324.30570898\n",
            "Validation score: 0.572452\n",
            "Iteration 5132, loss = 95294.42579886\n",
            "Validation score: 0.572532\n",
            "Iteration 5133, loss = 95262.95790761\n",
            "Validation score: 0.572642\n",
            "Iteration 5134, loss = 95231.83281168\n",
            "Validation score: 0.572756\n",
            "Iteration 5135, loss = 95202.43278407\n",
            "Validation score: 0.572859\n",
            "Iteration 5136, loss = 95171.19125018\n",
            "Validation score: 0.572958\n",
            "Iteration 5137, loss = 95142.63986401\n",
            "Validation score: 0.573059\n",
            "Iteration 5138, loss = 95113.53656977\n",
            "Validation score: 0.573179\n",
            "Iteration 5139, loss = 95081.75429652\n",
            "Validation score: 0.573320\n",
            "Iteration 5140, loss = 95054.14164528\n",
            "Validation score: 0.573463\n",
            "Iteration 5141, loss = 95023.23231745\n",
            "Validation score: 0.573611\n",
            "Iteration 5142, loss = 94994.38392644\n",
            "Validation score: 0.573772\n",
            "Iteration 5143, loss = 94964.62626730\n",
            "Validation score: 0.573922\n",
            "Iteration 5144, loss = 94934.88878804\n",
            "Validation score: 0.574061\n",
            "Iteration 5145, loss = 94904.84450493\n",
            "Validation score: 0.574188\n",
            "Iteration 5146, loss = 94875.11230718\n",
            "Validation score: 0.574309\n",
            "Iteration 5147, loss = 94843.53108635\n",
            "Validation score: 0.574438\n",
            "Iteration 5148, loss = 94813.58066412\n",
            "Validation score: 0.574561\n",
            "Iteration 5149, loss = 94781.40104110\n",
            "Validation score: 0.574682\n",
            "Iteration 5150, loss = 94750.20265784\n",
            "Validation score: 0.574794\n",
            "Iteration 5151, loss = 94719.63825636\n",
            "Validation score: 0.574909\n",
            "Iteration 5152, loss = 94687.32992005\n",
            "Validation score: 0.575026\n",
            "Iteration 5153, loss = 94656.23724835\n",
            "Validation score: 0.575147\n",
            "Iteration 5154, loss = 94626.30514169\n",
            "Validation score: 0.575276\n",
            "Iteration 5155, loss = 94594.35566024\n",
            "Validation score: 0.575412\n",
            "Iteration 5156, loss = 94566.17377628\n",
            "Validation score: 0.575537\n",
            "Iteration 5157, loss = 94533.35157118\n",
            "Validation score: 0.575644\n",
            "Iteration 5158, loss = 94507.49083812\n",
            "Validation score: 0.575757\n",
            "Iteration 5159, loss = 94477.69410534\n",
            "Validation score: 0.575870\n",
            "Iteration 5160, loss = 94447.33189407\n",
            "Validation score: 0.575969\n",
            "Iteration 5161, loss = 94418.96444397\n",
            "Validation score: 0.576081\n",
            "Iteration 5162, loss = 94385.37389748\n",
            "Validation score: 0.576207\n",
            "Iteration 5163, loss = 94355.92414801\n",
            "Validation score: 0.576353\n",
            "Iteration 5164, loss = 94324.17293622\n",
            "Validation score: 0.576496\n",
            "Iteration 5165, loss = 94292.97785790\n",
            "Validation score: 0.576637\n",
            "Iteration 5166, loss = 94262.42223593\n",
            "Validation score: 0.576783\n",
            "Iteration 5167, loss = 94230.97435312\n",
            "Validation score: 0.576928\n",
            "Iteration 5168, loss = 94199.02457880\n",
            "Validation score: 0.577073\n",
            "Iteration 5169, loss = 94166.16425883\n",
            "Validation score: 0.577215\n",
            "Iteration 5170, loss = 94132.69553031\n",
            "Validation score: 0.577358\n",
            "Iteration 5171, loss = 94102.24886660\n",
            "Validation score: 0.577496\n",
            "Iteration 5172, loss = 94071.03305509\n",
            "Validation score: 0.577619\n",
            "Iteration 5173, loss = 94041.14129183\n",
            "Validation score: 0.577719\n",
            "Iteration 5174, loss = 94007.93010859\n",
            "Validation score: 0.577829\n",
            "Iteration 5175, loss = 93978.10110382\n",
            "Validation score: 0.577935\n",
            "Iteration 5176, loss = 93945.07157235\n",
            "Validation score: 0.578050\n",
            "Iteration 5177, loss = 93916.32010804\n",
            "Validation score: 0.578169\n",
            "Iteration 5178, loss = 93887.24271962\n",
            "Validation score: 0.578288\n",
            "Iteration 5179, loss = 93856.10187551\n",
            "Validation score: 0.578419\n",
            "Iteration 5180, loss = 93827.06265188\n",
            "Validation score: 0.578551\n",
            "Iteration 5181, loss = 93797.32544840\n",
            "Validation score: 0.578669\n",
            "Iteration 5182, loss = 93768.30068012\n",
            "Validation score: 0.578777\n",
            "Iteration 5183, loss = 93738.99101527\n",
            "Validation score: 0.578881\n",
            "Iteration 5184, loss = 93705.54544878\n",
            "Validation score: 0.578988\n",
            "Iteration 5185, loss = 93674.83923552\n",
            "Validation score: 0.579085\n",
            "Iteration 5186, loss = 93646.26331364\n",
            "Validation score: 0.579185\n",
            "Iteration 5187, loss = 93614.64430145\n",
            "Validation score: 0.579309\n",
            "Iteration 5188, loss = 93582.25504785\n",
            "Validation score: 0.579451\n",
            "Iteration 5189, loss = 93553.36150716\n",
            "Validation score: 0.579581\n",
            "Iteration 5190, loss = 93523.56729192\n",
            "Validation score: 0.579695\n",
            "Iteration 5191, loss = 93492.64095802\n",
            "Validation score: 0.579789\n",
            "Iteration 5192, loss = 93462.73016962\n",
            "Validation score: 0.579898\n",
            "Iteration 5193, loss = 93432.41739465\n",
            "Validation score: 0.580017\n",
            "Iteration 5194, loss = 93403.34689645\n",
            "Validation score: 0.580143\n",
            "Iteration 5195, loss = 93372.48518287\n",
            "Validation score: 0.580276\n",
            "Iteration 5196, loss = 93342.23613341\n",
            "Validation score: 0.580398\n",
            "Iteration 5197, loss = 93312.03546227\n",
            "Validation score: 0.580522\n",
            "Iteration 5198, loss = 93282.68796124\n",
            "Validation score: 0.580648\n",
            "Iteration 5199, loss = 93253.59211461\n",
            "Validation score: 0.580783\n",
            "Iteration 5200, loss = 93223.76295778\n",
            "Validation score: 0.580920\n",
            "Iteration 5201, loss = 93194.93542605\n",
            "Validation score: 0.581043\n",
            "Iteration 5202, loss = 93164.12228539\n",
            "Validation score: 0.581169\n",
            "Iteration 5203, loss = 93136.40865766\n",
            "Validation score: 0.581294\n",
            "Iteration 5204, loss = 93107.03402230\n",
            "Validation score: 0.581428\n",
            "Iteration 5205, loss = 93076.81584129\n",
            "Validation score: 0.581548\n",
            "Iteration 5206, loss = 93048.93901411\n",
            "Validation score: 0.581666\n",
            "Iteration 5207, loss = 93018.21482843\n",
            "Validation score: 0.581795\n",
            "Iteration 5208, loss = 92989.35426184\n",
            "Validation score: 0.581924\n",
            "Iteration 5209, loss = 92959.83543097\n",
            "Validation score: 0.582035\n",
            "Iteration 5210, loss = 92930.41028015\n",
            "Validation score: 0.582153\n",
            "Iteration 5211, loss = 92900.46718677\n",
            "Validation score: 0.582255\n",
            "Iteration 5212, loss = 92872.23864650\n",
            "Validation score: 0.582358\n",
            "Iteration 5213, loss = 92841.88107637\n",
            "Validation score: 0.582477\n",
            "Iteration 5214, loss = 92813.66210859\n",
            "Validation score: 0.582593\n",
            "Iteration 5215, loss = 92784.72260744\n",
            "Validation score: 0.582700\n",
            "Iteration 5216, loss = 92755.69566168\n",
            "Validation score: 0.582807\n",
            "Iteration 5217, loss = 92727.28344586\n",
            "Validation score: 0.582921\n",
            "Iteration 5218, loss = 92698.14460788\n",
            "Validation score: 0.583045\n",
            "Iteration 5219, loss = 92671.25300259\n",
            "Validation score: 0.583171\n",
            "Iteration 5220, loss = 92641.82978957\n",
            "Validation score: 0.583285\n",
            "Iteration 5221, loss = 92612.52291624\n",
            "Validation score: 0.583396\n",
            "Iteration 5222, loss = 92582.56377546\n",
            "Validation score: 0.583515\n",
            "Iteration 5223, loss = 92552.76948596\n",
            "Validation score: 0.583636\n",
            "Iteration 5224, loss = 92523.54793998\n",
            "Validation score: 0.583754\n",
            "Iteration 5225, loss = 92498.03336252\n",
            "Validation score: 0.583850\n",
            "Iteration 5226, loss = 92464.18819800\n",
            "Validation score: 0.583967\n",
            "Iteration 5227, loss = 92433.82413050\n",
            "Validation score: 0.584104\n",
            "Iteration 5228, loss = 92404.28298675\n",
            "Validation score: 0.584238\n",
            "Iteration 5229, loss = 92372.95309263\n",
            "Validation score: 0.584359\n",
            "Iteration 5230, loss = 92344.64217043\n",
            "Validation score: 0.584484\n",
            "Iteration 5231, loss = 92312.62134662\n",
            "Validation score: 0.584582\n",
            "Iteration 5232, loss = 92285.26445166\n",
            "Validation score: 0.584703\n",
            "Iteration 5233, loss = 92252.62609722\n",
            "Validation score: 0.584842\n",
            "Iteration 5234, loss = 92222.38943970\n",
            "Validation score: 0.584992\n",
            "Iteration 5235, loss = 92191.79720336\n",
            "Validation score: 0.585160\n",
            "Iteration 5236, loss = 92166.15307234\n",
            "Validation score: 0.585325\n",
            "Iteration 5237, loss = 92134.95834458\n",
            "Validation score: 0.585465\n",
            "Iteration 5238, loss = 92101.02929145\n",
            "Validation score: 0.585594\n",
            "Iteration 5239, loss = 92073.45265403\n",
            "Validation score: 0.585727\n",
            "Iteration 5240, loss = 92042.19046825\n",
            "Validation score: 0.585853\n",
            "Iteration 5241, loss = 92014.09955507\n",
            "Validation score: 0.585975\n",
            "Iteration 5242, loss = 91981.44268510\n",
            "Validation score: 0.586075\n",
            "Iteration 5243, loss = 91950.78544576\n",
            "Validation score: 0.586172\n",
            "Iteration 5244, loss = 91924.17432587\n",
            "Validation score: 0.586293\n",
            "Iteration 5245, loss = 91891.71703213\n",
            "Validation score: 0.586441\n",
            "Iteration 5246, loss = 91862.19624047\n",
            "Validation score: 0.586588\n",
            "Iteration 5247, loss = 91831.04451464\n",
            "Validation score: 0.586714\n",
            "Iteration 5248, loss = 91801.98374488\n",
            "Validation score: 0.586832\n",
            "Iteration 5249, loss = 91770.04533909\n",
            "Validation score: 0.586951\n",
            "Iteration 5250, loss = 91743.59341217\n",
            "Validation score: 0.587064\n",
            "Iteration 5251, loss = 91710.58295396\n",
            "Validation score: 0.587186\n",
            "Iteration 5252, loss = 91681.80963539\n",
            "Validation score: 0.587304\n",
            "Iteration 5253, loss = 91652.28758879\n",
            "Validation score: 0.587431\n",
            "Iteration 5254, loss = 91623.55637917\n",
            "Validation score: 0.587554\n",
            "Iteration 5255, loss = 91593.39852649\n",
            "Validation score: 0.587671\n",
            "Iteration 5256, loss = 91565.33666008\n",
            "Validation score: 0.587797\n",
            "Iteration 5257, loss = 91535.46500773\n",
            "Validation score: 0.587902\n",
            "Iteration 5258, loss = 91503.60386889\n",
            "Validation score: 0.588007\n",
            "Iteration 5259, loss = 91475.21103733\n",
            "Validation score: 0.588119\n",
            "Iteration 5260, loss = 91444.92873474\n",
            "Validation score: 0.588243\n",
            "Iteration 5261, loss = 91416.39692163\n",
            "Validation score: 0.588372\n",
            "Iteration 5262, loss = 91383.99994312\n",
            "Validation score: 0.588497\n",
            "Iteration 5263, loss = 91354.84296446\n",
            "Validation score: 0.588628\n",
            "Iteration 5264, loss = 91325.12952226\n",
            "Validation score: 0.588748\n",
            "Iteration 5265, loss = 91293.68303059\n",
            "Validation score: 0.588861\n",
            "Iteration 5266, loss = 91266.33644950\n",
            "Validation score: 0.588975\n",
            "Iteration 5267, loss = 91234.68571713\n",
            "Validation score: 0.589078\n",
            "Iteration 5268, loss = 91205.66169114\n",
            "Validation score: 0.589184\n",
            "Iteration 5269, loss = 91176.57180277\n",
            "Validation score: 0.589299\n",
            "Iteration 5270, loss = 91149.82277479\n",
            "Validation score: 0.589420\n",
            "Iteration 5271, loss = 91120.59563937\n",
            "Validation score: 0.589536\n",
            "Iteration 5272, loss = 91091.76728797\n",
            "Validation score: 0.589653\n",
            "Iteration 5273, loss = 91063.84247878\n",
            "Validation score: 0.589783\n",
            "Iteration 5274, loss = 91036.05986252\n",
            "Validation score: 0.589921\n",
            "Iteration 5275, loss = 91006.02267800\n",
            "Validation score: 0.590053\n",
            "Iteration 5276, loss = 90976.83614472\n",
            "Validation score: 0.590189\n",
            "Iteration 5277, loss = 90947.08487776\n",
            "Validation score: 0.590329\n",
            "Iteration 5278, loss = 90917.02072728\n",
            "Validation score: 0.590457\n",
            "Iteration 5279, loss = 90886.98471570\n",
            "Validation score: 0.590564\n",
            "Iteration 5280, loss = 90858.44358055\n",
            "Validation score: 0.590667\n",
            "Iteration 5281, loss = 90829.59129334\n",
            "Validation score: 0.590770\n",
            "Iteration 5282, loss = 90803.17197231\n",
            "Validation score: 0.590888\n",
            "Iteration 5283, loss = 90773.73399078\n",
            "Validation score: 0.591010\n",
            "Iteration 5284, loss = 90747.95043994\n",
            "Validation score: 0.591134\n",
            "Iteration 5285, loss = 90719.53527435\n",
            "Validation score: 0.591248\n",
            "Iteration 5286, loss = 90691.02539694\n",
            "Validation score: 0.591358\n",
            "Iteration 5287, loss = 90663.87970421\n",
            "Validation score: 0.591471\n",
            "Iteration 5288, loss = 90636.69017935\n",
            "Validation score: 0.591584\n",
            "Iteration 5289, loss = 90609.85577293\n",
            "Validation score: 0.591711\n",
            "Iteration 5290, loss = 90581.37999701\n",
            "Validation score: 0.591842\n",
            "Iteration 5291, loss = 90555.41168655\n",
            "Validation score: 0.591978\n",
            "Iteration 5292, loss = 90526.17733189\n",
            "Validation score: 0.592105\n",
            "Iteration 5293, loss = 90495.66288056\n",
            "Validation score: 0.592228\n",
            "Iteration 5294, loss = 90467.86818684\n",
            "Validation score: 0.592353\n",
            "Iteration 5295, loss = 90439.66446308\n",
            "Validation score: 0.592476\n",
            "Iteration 5296, loss = 90409.82751143\n",
            "Validation score: 0.592602\n",
            "Iteration 5297, loss = 90380.77324633\n",
            "Validation score: 0.592727\n",
            "Iteration 5298, loss = 90352.51805485\n",
            "Validation score: 0.592854\n",
            "Iteration 5299, loss = 90323.86842920\n",
            "Validation score: 0.592985\n",
            "Iteration 5300, loss = 90295.65426150\n",
            "Validation score: 0.593097\n",
            "Iteration 5301, loss = 90264.98530997\n",
            "Validation score: 0.593210\n",
            "Iteration 5302, loss = 90238.43286841\n",
            "Validation score: 0.593325\n",
            "Iteration 5303, loss = 90208.40759018\n",
            "Validation score: 0.593419\n",
            "Iteration 5304, loss = 90180.45509196\n",
            "Validation score: 0.593505\n",
            "Iteration 5305, loss = 90151.87263083\n",
            "Validation score: 0.593580\n",
            "Iteration 5306, loss = 90124.94797827\n",
            "Validation score: 0.593653\n",
            "Iteration 5307, loss = 90098.35804041\n",
            "Validation score: 0.593718\n",
            "Iteration 5308, loss = 90072.28320964\n",
            "Validation score: 0.593821\n",
            "Iteration 5309, loss = 90046.11796094\n",
            "Validation score: 0.593934\n",
            "Iteration 5310, loss = 90017.19546603\n",
            "Validation score: 0.594055\n",
            "Iteration 5311, loss = 89989.45467764\n",
            "Validation score: 0.594192\n",
            "Iteration 5312, loss = 89962.02809024\n",
            "Validation score: 0.594326\n",
            "Iteration 5313, loss = 89932.62024204\n",
            "Validation score: 0.594465\n",
            "Iteration 5314, loss = 89905.47254441\n",
            "Validation score: 0.594596\n",
            "Iteration 5315, loss = 89877.00865351\n",
            "Validation score: 0.594716\n",
            "Iteration 5316, loss = 89846.74819524\n",
            "Validation score: 0.594846\n",
            "Iteration 5317, loss = 89820.35934527\n",
            "Validation score: 0.594974\n",
            "Iteration 5318, loss = 89791.68997310\n",
            "Validation score: 0.595105\n",
            "Iteration 5319, loss = 89763.22583394\n",
            "Validation score: 0.595242\n",
            "Iteration 5320, loss = 89735.14307336\n",
            "Validation score: 0.595389\n",
            "Iteration 5321, loss = 89707.09551654\n",
            "Validation score: 0.595522\n",
            "Iteration 5322, loss = 89679.05375790\n",
            "Validation score: 0.595646\n",
            "Iteration 5323, loss = 89649.63937078\n",
            "Validation score: 0.595747\n",
            "Iteration 5324, loss = 89624.11422365\n",
            "Validation score: 0.595859\n",
            "Iteration 5325, loss = 89594.05061764\n",
            "Validation score: 0.595968\n",
            "Iteration 5326, loss = 89568.79713830\n",
            "Validation score: 0.596087\n",
            "Iteration 5327, loss = 89541.27431621\n",
            "Validation score: 0.596210\n",
            "Iteration 5328, loss = 89515.89908277\n",
            "Validation score: 0.596331\n",
            "Iteration 5329, loss = 89489.92929733\n",
            "Validation score: 0.596446\n",
            "Iteration 5330, loss = 89460.63885459\n",
            "Validation score: 0.596528\n",
            "Iteration 5331, loss = 89430.49362444\n",
            "Validation score: 0.596618\n",
            "Iteration 5332, loss = 89403.85989009\n",
            "Validation score: 0.596715\n",
            "Iteration 5333, loss = 89374.26097571\n",
            "Validation score: 0.596801\n",
            "Iteration 5334, loss = 89346.04593318\n",
            "Validation score: 0.596888\n",
            "Iteration 5335, loss = 89316.65864785\n",
            "Validation score: 0.596977\n",
            "Iteration 5336, loss = 89285.82691808\n",
            "Validation score: 0.597082\n",
            "Iteration 5337, loss = 89257.96859332\n",
            "Validation score: 0.597192\n",
            "Iteration 5338, loss = 89233.05423726\n",
            "Validation score: 0.597292\n",
            "Iteration 5339, loss = 89199.06267103\n",
            "Validation score: 0.597406\n",
            "Iteration 5340, loss = 89171.50054880\n",
            "Validation score: 0.597531\n",
            "Iteration 5341, loss = 89143.36238126\n",
            "Validation score: 0.597666\n",
            "Iteration 5342, loss = 89114.25028817\n",
            "Validation score: 0.597802\n",
            "Iteration 5343, loss = 89086.47496000\n",
            "Validation score: 0.597934\n",
            "Iteration 5344, loss = 89058.06933227\n",
            "Validation score: 0.598052\n",
            "Iteration 5345, loss = 89029.33504073\n",
            "Validation score: 0.598165\n",
            "Iteration 5346, loss = 89001.72490158\n",
            "Validation score: 0.598281\n",
            "Iteration 5347, loss = 88971.51552019\n",
            "Validation score: 0.598389\n",
            "Iteration 5348, loss = 88943.38523960\n",
            "Validation score: 0.598496\n",
            "Iteration 5349, loss = 88918.32813663\n",
            "Validation score: 0.598596\n",
            "Iteration 5350, loss = 88887.26120571\n",
            "Validation score: 0.598695\n",
            "Iteration 5351, loss = 88857.44867096\n",
            "Validation score: 0.598805\n",
            "Iteration 5352, loss = 88829.52805172\n",
            "Validation score: 0.598921\n",
            "Iteration 5353, loss = 88801.84746722\n",
            "Validation score: 0.599030\n",
            "Iteration 5354, loss = 88775.20580807\n",
            "Validation score: 0.599146\n",
            "Iteration 5355, loss = 88748.86736761\n",
            "Validation score: 0.599253\n",
            "Iteration 5356, loss = 88722.27385300\n",
            "Validation score: 0.599356\n",
            "Iteration 5357, loss = 88694.44098105\n",
            "Validation score: 0.599465\n",
            "Iteration 5358, loss = 88665.69098564\n",
            "Validation score: 0.599583\n",
            "Iteration 5359, loss = 88638.04765361\n",
            "Validation score: 0.599700\n",
            "Iteration 5360, loss = 88609.84753282\n",
            "Validation score: 0.599826\n",
            "Iteration 5361, loss = 88579.82760757\n",
            "Validation score: 0.599927\n",
            "Iteration 5362, loss = 88551.23396149\n",
            "Validation score: 0.600028\n",
            "Iteration 5363, loss = 88523.31998038\n",
            "Validation score: 0.600132\n",
            "Iteration 5364, loss = 88494.29212972\n",
            "Validation score: 0.600250\n",
            "Iteration 5365, loss = 88464.23792831\n",
            "Validation score: 0.600360\n",
            "Iteration 5366, loss = 88437.39862673\n",
            "Validation score: 0.600477\n",
            "Iteration 5367, loss = 88409.55398424\n",
            "Validation score: 0.600596\n",
            "Iteration 5368, loss = 88380.84812651\n",
            "Validation score: 0.600699\n",
            "Iteration 5369, loss = 88352.39272605\n",
            "Validation score: 0.600800\n",
            "Iteration 5370, loss = 88325.71583642\n",
            "Validation score: 0.600922\n",
            "Iteration 5371, loss = 88295.81675577\n",
            "Validation score: 0.601042\n",
            "Iteration 5372, loss = 88268.67213410\n",
            "Validation score: 0.601169\n",
            "Iteration 5373, loss = 88241.23081311\n",
            "Validation score: 0.601292\n",
            "Iteration 5374, loss = 88214.22357309\n",
            "Validation score: 0.601405\n",
            "Iteration 5375, loss = 88185.58843651\n",
            "Validation score: 0.601512\n",
            "Iteration 5376, loss = 88158.31432436\n",
            "Validation score: 0.601628\n",
            "Iteration 5377, loss = 88131.91971111\n",
            "Validation score: 0.601741\n",
            "Iteration 5378, loss = 88104.79866188\n",
            "Validation score: 0.601857\n",
            "Iteration 5379, loss = 88075.29389063\n",
            "Validation score: 0.601964\n",
            "Iteration 5380, loss = 88046.45552538\n",
            "Validation score: 0.602061\n",
            "Iteration 5381, loss = 88017.23678377\n",
            "Validation score: 0.602164\n",
            "Iteration 5382, loss = 87988.70689853\n",
            "Validation score: 0.602259\n",
            "Iteration 5383, loss = 87959.65504750\n",
            "Validation score: 0.602373\n",
            "Iteration 5384, loss = 87931.64175799\n",
            "Validation score: 0.602493\n",
            "Iteration 5385, loss = 87902.24246728\n",
            "Validation score: 0.602611\n",
            "Iteration 5386, loss = 87874.50804118\n",
            "Validation score: 0.602717\n",
            "Iteration 5387, loss = 87847.63084983\n",
            "Validation score: 0.602807\n",
            "Iteration 5388, loss = 87820.62149057\n",
            "Validation score: 0.602897\n",
            "Iteration 5389, loss = 87792.09395071\n",
            "Validation score: 0.602983\n",
            "Iteration 5390, loss = 87768.90449752\n",
            "Validation score: 0.603073\n",
            "Iteration 5391, loss = 87742.26967081\n",
            "Validation score: 0.603185\n",
            "Iteration 5392, loss = 87715.43934660\n",
            "Validation score: 0.603292\n",
            "Iteration 5393, loss = 87691.05052963\n",
            "Validation score: 0.603391\n",
            "Iteration 5394, loss = 87665.63069381\n",
            "Validation score: 0.603504\n",
            "Iteration 5395, loss = 87640.26187472\n",
            "Validation score: 0.603608\n",
            "Iteration 5396, loss = 87613.26608428\n",
            "Validation score: 0.603698\n",
            "Iteration 5397, loss = 87588.29624196\n",
            "Validation score: 0.603798\n",
            "Iteration 5398, loss = 87562.27565067\n",
            "Validation score: 0.603911\n",
            "Iteration 5399, loss = 87536.01223122\n",
            "Validation score: 0.604042\n",
            "Iteration 5400, loss = 87509.33079065\n",
            "Validation score: 0.604156\n",
            "Iteration 5401, loss = 87481.86190903\n",
            "Validation score: 0.604274\n",
            "Iteration 5402, loss = 87455.22354950\n",
            "Validation score: 0.604394\n",
            "Iteration 5403, loss = 87429.44497709\n",
            "Validation score: 0.604521\n",
            "Iteration 5404, loss = 87402.32445012\n",
            "Validation score: 0.604650\n",
            "Iteration 5405, loss = 87373.86678673\n",
            "Validation score: 0.604788\n",
            "Iteration 5406, loss = 87348.51511988\n",
            "Validation score: 0.604922\n",
            "Iteration 5407, loss = 87318.81034763\n",
            "Validation score: 0.605059\n",
            "Iteration 5408, loss = 87293.68756722\n",
            "Validation score: 0.605196\n",
            "Iteration 5409, loss = 87266.33804006\n",
            "Validation score: 0.605322\n",
            "Iteration 5410, loss = 87239.02228462\n",
            "Validation score: 0.605445\n",
            "Iteration 5411, loss = 87212.49530207\n",
            "Validation score: 0.605565\n",
            "Iteration 5412, loss = 87185.47429500\n",
            "Validation score: 0.605694\n",
            "Iteration 5413, loss = 87160.14746899\n",
            "Validation score: 0.605820\n",
            "Iteration 5414, loss = 87130.94449680\n",
            "Validation score: 0.605939\n",
            "Iteration 5415, loss = 87102.80407633\n",
            "Validation score: 0.606048\n",
            "Iteration 5416, loss = 87075.98284687\n",
            "Validation score: 0.606147\n",
            "Iteration 5417, loss = 87047.38187018\n",
            "Validation score: 0.606261\n",
            "Iteration 5418, loss = 87019.47981183\n",
            "Validation score: 0.606369\n",
            "Iteration 5419, loss = 86994.00481541\n",
            "Validation score: 0.606471\n",
            "Iteration 5420, loss = 86965.73455738\n",
            "Validation score: 0.606575\n",
            "Iteration 5421, loss = 86939.64134967\n",
            "Validation score: 0.606682\n",
            "Iteration 5422, loss = 86912.14933121\n",
            "Validation score: 0.606798\n",
            "Iteration 5423, loss = 86885.48551579\n",
            "Validation score: 0.606917\n",
            "Iteration 5424, loss = 86857.88489020\n",
            "Validation score: 0.607043\n",
            "Iteration 5425, loss = 86831.30165155\n",
            "Validation score: 0.607166\n",
            "Iteration 5426, loss = 86804.92917278\n",
            "Validation score: 0.607279\n",
            "Iteration 5427, loss = 86778.72520585\n",
            "Validation score: 0.607378\n",
            "Iteration 5428, loss = 86749.43279143\n",
            "Validation score: 0.607480\n",
            "Iteration 5429, loss = 86722.14105046\n",
            "Validation score: 0.607594\n",
            "Iteration 5430, loss = 86693.54409419\n",
            "Validation score: 0.607714\n",
            "Iteration 5431, loss = 86665.85445216\n",
            "Validation score: 0.607827\n",
            "Iteration 5432, loss = 86635.52014688\n",
            "Validation score: 0.607914\n",
            "Iteration 5433, loss = 86607.17156202\n",
            "Validation score: 0.607996\n",
            "Iteration 5434, loss = 86576.00466200\n",
            "Validation score: 0.608100\n",
            "Iteration 5435, loss = 86547.47307569\n",
            "Validation score: 0.608197\n",
            "Iteration 5436, loss = 86517.86156493\n",
            "Validation score: 0.608303\n",
            "Iteration 5437, loss = 86490.79978312\n",
            "Validation score: 0.608416\n",
            "Iteration 5438, loss = 86461.45982114\n",
            "Validation score: 0.608551\n",
            "Iteration 5439, loss = 86434.17056431\n",
            "Validation score: 0.608694\n",
            "Iteration 5440, loss = 86407.03752070\n",
            "Validation score: 0.608827\n",
            "Iteration 5441, loss = 86380.29923802\n",
            "Validation score: 0.608963\n",
            "Iteration 5442, loss = 86355.26639190\n",
            "Validation score: 0.609096\n",
            "Iteration 5443, loss = 86325.74731186\n",
            "Validation score: 0.609202\n",
            "Iteration 5444, loss = 86300.46161880\n",
            "Validation score: 0.609314\n",
            "Iteration 5445, loss = 86276.05489670\n",
            "Validation score: 0.609425\n",
            "Iteration 5446, loss = 86250.94857863\n",
            "Validation score: 0.609541\n",
            "Iteration 5447, loss = 86224.84138926\n",
            "Validation score: 0.609646\n",
            "Iteration 5448, loss = 86199.16784072\n",
            "Validation score: 0.609743\n",
            "Iteration 5449, loss = 86172.76069929\n",
            "Validation score: 0.609836\n",
            "Iteration 5450, loss = 86146.91343472\n",
            "Validation score: 0.609938\n",
            "Iteration 5451, loss = 86120.23698813\n",
            "Validation score: 0.610045\n",
            "Iteration 5452, loss = 86096.34250686\n",
            "Validation score: 0.610146\n",
            "Iteration 5453, loss = 86069.72985936\n",
            "Validation score: 0.610255\n",
            "Iteration 5454, loss = 86044.38839187\n",
            "Validation score: 0.610352\n",
            "Iteration 5455, loss = 86016.60742428\n",
            "Validation score: 0.610458\n",
            "Iteration 5456, loss = 85991.67769793\n",
            "Validation score: 0.610568\n",
            "Iteration 5457, loss = 85964.65667538\n",
            "Validation score: 0.610669\n",
            "Iteration 5458, loss = 85937.33363188\n",
            "Validation score: 0.610774\n",
            "Iteration 5459, loss = 85909.67438221\n",
            "Validation score: 0.610869\n",
            "Iteration 5460, loss = 85882.29819174\n",
            "Validation score: 0.610967\n",
            "Iteration 5461, loss = 85856.22063460\n",
            "Validation score: 0.611073\n",
            "Iteration 5462, loss = 85828.56882596\n",
            "Validation score: 0.611164\n",
            "Iteration 5463, loss = 85806.29877345\n",
            "Validation score: 0.611247\n",
            "Iteration 5464, loss = 85771.41228511\n",
            "Validation score: 0.611359\n",
            "Iteration 5465, loss = 85748.00552319\n",
            "Validation score: 0.611476\n",
            "Iteration 5466, loss = 85719.75786104\n",
            "Validation score: 0.611582\n",
            "Iteration 5467, loss = 85690.98538809\n",
            "Validation score: 0.611674\n",
            "Iteration 5468, loss = 85662.30145263\n",
            "Validation score: 0.611762\n",
            "Iteration 5469, loss = 85634.83372129\n",
            "Validation score: 0.611856\n",
            "Iteration 5470, loss = 85606.31209070\n",
            "Validation score: 0.611946\n",
            "Iteration 5471, loss = 85579.74916829\n",
            "Validation score: 0.612031\n",
            "Iteration 5472, loss = 85552.82526210\n",
            "Validation score: 0.612122\n",
            "Iteration 5473, loss = 85525.23267507\n",
            "Validation score: 0.612237\n",
            "Iteration 5474, loss = 85497.32621463\n",
            "Validation score: 0.612358\n",
            "Iteration 5475, loss = 85471.91120823\n",
            "Validation score: 0.612486\n",
            "Iteration 5476, loss = 85442.04221140\n",
            "Validation score: 0.612604\n",
            "Iteration 5477, loss = 85414.14782849\n",
            "Validation score: 0.612717\n",
            "Iteration 5478, loss = 85386.69100590\n",
            "Validation score: 0.612819\n",
            "Iteration 5479, loss = 85359.89168969\n",
            "Validation score: 0.612936\n",
            "Iteration 5480, loss = 85331.50305521\n",
            "Validation score: 0.613053\n",
            "Iteration 5481, loss = 85302.05045612\n",
            "Validation score: 0.613185\n",
            "Iteration 5482, loss = 85274.81377432\n",
            "Validation score: 0.613301\n",
            "Iteration 5483, loss = 85246.27030977\n",
            "Validation score: 0.613403\n",
            "Iteration 5484, loss = 85220.03438903\n",
            "Validation score: 0.613509\n",
            "Iteration 5485, loss = 85191.58274419\n",
            "Validation score: 0.613619\n",
            "Iteration 5486, loss = 85163.66004842\n",
            "Validation score: 0.613711\n",
            "Iteration 5487, loss = 85137.69718605\n",
            "Validation score: 0.613792\n",
            "Iteration 5488, loss = 85113.12096648\n",
            "Validation score: 0.613881\n",
            "Iteration 5489, loss = 85082.79274334\n",
            "Validation score: 0.613982\n",
            "Iteration 5490, loss = 85055.06299562\n",
            "Validation score: 0.614090\n",
            "Iteration 5491, loss = 85027.95813248\n",
            "Validation score: 0.614206\n",
            "Iteration 5492, loss = 85002.10620751\n",
            "Validation score: 0.614319\n",
            "Iteration 5493, loss = 84974.45871073\n",
            "Validation score: 0.614436\n",
            "Iteration 5494, loss = 84947.91801944\n",
            "Validation score: 0.614556\n",
            "Iteration 5495, loss = 84921.40853754\n",
            "Validation score: 0.614679\n",
            "Iteration 5496, loss = 84891.31292346\n",
            "Validation score: 0.614804\n",
            "Iteration 5497, loss = 84865.48182938\n",
            "Validation score: 0.614934\n",
            "Iteration 5498, loss = 84839.59139244\n",
            "Validation score: 0.615075\n",
            "Iteration 5499, loss = 84812.68598544\n",
            "Validation score: 0.615201\n",
            "Iteration 5500, loss = 84784.46080047\n",
            "Validation score: 0.615316\n",
            "Iteration 5501, loss = 84756.65102496\n",
            "Validation score: 0.615433\n",
            "Iteration 5502, loss = 84730.46939225\n",
            "Validation score: 0.615549\n",
            "Iteration 5503, loss = 84705.64372151\n",
            "Validation score: 0.615660\n",
            "Iteration 5504, loss = 84680.80052138\n",
            "Validation score: 0.615780\n",
            "Iteration 5505, loss = 84654.86159543\n",
            "Validation score: 0.615901\n",
            "Iteration 5506, loss = 84631.10014147\n",
            "Validation score: 0.616015\n",
            "Iteration 5507, loss = 84604.92454916\n",
            "Validation score: 0.616122\n",
            "Iteration 5508, loss = 84579.43282997\n",
            "Validation score: 0.616225\n",
            "Iteration 5509, loss = 84550.88001921\n",
            "Validation score: 0.616322\n",
            "Iteration 5510, loss = 84526.46858863\n",
            "Validation score: 0.616403\n",
            "Iteration 5511, loss = 84499.02475852\n",
            "Validation score: 0.616477\n",
            "Iteration 5512, loss = 84472.86441165\n",
            "Validation score: 0.616547\n",
            "Iteration 5513, loss = 84446.18310139\n",
            "Validation score: 0.616620\n",
            "Iteration 5514, loss = 84423.79644700\n",
            "Validation score: 0.616694\n",
            "Iteration 5515, loss = 84396.53739347\n",
            "Validation score: 0.616771\n",
            "Iteration 5516, loss = 84369.84746627\n",
            "Validation score: 0.616874\n",
            "Iteration 5517, loss = 84344.72893270\n",
            "Validation score: 0.616995\n",
            "Iteration 5518, loss = 84319.34466182\n",
            "Validation score: 0.617125\n",
            "Iteration 5519, loss = 84292.98200111\n",
            "Validation score: 0.617243\n",
            "Iteration 5520, loss = 84268.44028473\n",
            "Validation score: 0.617368\n",
            "Iteration 5521, loss = 84244.37449124\n",
            "Validation score: 0.617493\n",
            "Iteration 5522, loss = 84218.37859366\n",
            "Validation score: 0.617619\n",
            "Iteration 5523, loss = 84193.25142697\n",
            "Validation score: 0.617743\n",
            "Iteration 5524, loss = 84169.15607118\n",
            "Validation score: 0.617855\n",
            "Iteration 5525, loss = 84144.07978287\n",
            "Validation score: 0.617963\n",
            "Iteration 5526, loss = 84118.11445122\n",
            "Validation score: 0.618077\n",
            "Iteration 5527, loss = 84092.65124988\n",
            "Validation score: 0.618186\n",
            "Iteration 5528, loss = 84067.08735095\n",
            "Validation score: 0.618298\n",
            "Iteration 5529, loss = 84041.22860496\n",
            "Validation score: 0.618422\n",
            "Iteration 5530, loss = 84017.27099523\n",
            "Validation score: 0.618549\n",
            "Iteration 5531, loss = 83990.29180237\n",
            "Validation score: 0.618667\n",
            "Iteration 5532, loss = 83963.70017906\n",
            "Validation score: 0.618779\n",
            "Iteration 5533, loss = 83938.86106067\n",
            "Validation score: 0.618888\n",
            "Iteration 5534, loss = 83911.79168302\n",
            "Validation score: 0.619004\n",
            "Iteration 5535, loss = 83885.61183772\n",
            "Validation score: 0.619115\n",
            "Iteration 5536, loss = 83858.00980463\n",
            "Validation score: 0.619225\n",
            "Iteration 5537, loss = 83833.08349257\n",
            "Validation score: 0.619347\n",
            "Iteration 5538, loss = 83805.29706875\n",
            "Validation score: 0.619463\n",
            "Iteration 5539, loss = 83778.58058102\n",
            "Validation score: 0.619576\n",
            "Iteration 5540, loss = 83753.44546108\n",
            "Validation score: 0.619693\n",
            "Iteration 5541, loss = 83728.46223111\n",
            "Validation score: 0.619814\n",
            "Iteration 5542, loss = 83703.02604603\n",
            "Validation score: 0.619931\n",
            "Iteration 5543, loss = 83675.63813555\n",
            "Validation score: 0.620048\n",
            "Iteration 5544, loss = 83649.36123392\n",
            "Validation score: 0.620164\n",
            "Iteration 5545, loss = 83624.08142296\n",
            "Validation score: 0.620296\n",
            "Iteration 5546, loss = 83599.51272460\n",
            "Validation score: 0.620411\n",
            "Iteration 5547, loss = 83570.79064938\n",
            "Validation score: 0.620520\n",
            "Iteration 5548, loss = 83544.60906073\n",
            "Validation score: 0.620621\n",
            "Iteration 5549, loss = 83518.64244457\n",
            "Validation score: 0.620705\n",
            "Iteration 5550, loss = 83493.34807501\n",
            "Validation score: 0.620783\n",
            "Iteration 5551, loss = 83466.32578729\n",
            "Validation score: 0.620866\n",
            "Iteration 5552, loss = 83441.52802729\n",
            "Validation score: 0.620945\n",
            "Iteration 5553, loss = 83416.15542496\n",
            "Validation score: 0.621041\n",
            "Iteration 5554, loss = 83390.35654234\n",
            "Validation score: 0.621131\n",
            "Iteration 5555, loss = 83365.92746900\n",
            "Validation score: 0.621228\n",
            "Iteration 5556, loss = 83340.13959687\n",
            "Validation score: 0.621330\n",
            "Iteration 5557, loss = 83315.37300151\n",
            "Validation score: 0.621434\n",
            "Iteration 5558, loss = 83289.33913714\n",
            "Validation score: 0.621537\n",
            "Iteration 5559, loss = 83265.61612549\n",
            "Validation score: 0.621656\n",
            "Iteration 5560, loss = 83238.29541318\n",
            "Validation score: 0.621790\n",
            "Iteration 5561, loss = 83215.59771330\n",
            "Validation score: 0.621921\n",
            "Iteration 5562, loss = 83187.05821433\n",
            "Validation score: 0.622034\n",
            "Iteration 5563, loss = 83161.06829126\n",
            "Validation score: 0.622150\n",
            "Iteration 5564, loss = 83135.04040764\n",
            "Validation score: 0.622261\n",
            "Iteration 5565, loss = 83108.07030552\n",
            "Validation score: 0.622369\n",
            "Iteration 5566, loss = 83079.17306747\n",
            "Validation score: 0.622474\n",
            "Iteration 5567, loss = 83054.01643721\n",
            "Validation score: 0.622579\n",
            "Iteration 5568, loss = 83025.22273648\n",
            "Validation score: 0.622689\n",
            "Iteration 5569, loss = 82998.57856382\n",
            "Validation score: 0.622818\n",
            "Iteration 5570, loss = 82974.08440851\n",
            "Validation score: 0.622952\n",
            "Iteration 5571, loss = 82949.94410222\n",
            "Validation score: 0.623079\n",
            "Iteration 5572, loss = 82927.07478747\n",
            "Validation score: 0.623202\n",
            "Iteration 5573, loss = 82901.95335112\n",
            "Validation score: 0.623319\n",
            "Iteration 5574, loss = 82878.80547193\n",
            "Validation score: 0.623440\n",
            "Iteration 5575, loss = 82855.08141263\n",
            "Validation score: 0.623551\n",
            "Iteration 5576, loss = 82832.08377471\n",
            "Validation score: 0.623660\n",
            "Iteration 5577, loss = 82808.95364179\n",
            "Validation score: 0.623762\n",
            "Iteration 5578, loss = 82782.06085408\n",
            "Validation score: 0.623854\n",
            "Iteration 5579, loss = 82760.55664098\n",
            "Validation score: 0.623963\n",
            "Iteration 5580, loss = 82733.09203282\n",
            "Validation score: 0.624090\n",
            "Iteration 5581, loss = 82707.19852193\n",
            "Validation score: 0.624221\n",
            "Iteration 5582, loss = 82682.41723863\n",
            "Validation score: 0.624345\n",
            "Iteration 5583, loss = 82656.05512856\n",
            "Validation score: 0.624454\n",
            "Iteration 5584, loss = 82630.10671906\n",
            "Validation score: 0.624563\n",
            "Iteration 5585, loss = 82604.52464546\n",
            "Validation score: 0.624666\n",
            "Iteration 5586, loss = 82578.74884740\n",
            "Validation score: 0.624750\n",
            "Iteration 5587, loss = 82553.61171957\n",
            "Validation score: 0.624830\n",
            "Iteration 5588, loss = 82528.21258895\n",
            "Validation score: 0.624907\n",
            "Iteration 5589, loss = 82502.86942506\n",
            "Validation score: 0.624986\n",
            "Iteration 5590, loss = 82479.87807590\n",
            "Validation score: 0.625080\n",
            "Iteration 5591, loss = 82453.58959697\n",
            "Validation score: 0.625161\n",
            "Iteration 5592, loss = 82429.52034298\n",
            "Validation score: 0.625248\n",
            "Iteration 5593, loss = 82404.02702271\n",
            "Validation score: 0.625326\n",
            "Iteration 5594, loss = 82377.49275489\n",
            "Validation score: 0.625410\n",
            "Iteration 5595, loss = 82352.93484662\n",
            "Validation score: 0.625498\n",
            "Iteration 5596, loss = 82326.97394187\n",
            "Validation score: 0.625590\n",
            "Iteration 5597, loss = 82302.20095123\n",
            "Validation score: 0.625672\n",
            "Iteration 5598, loss = 82277.47437021\n",
            "Validation score: 0.625748\n",
            "Iteration 5599, loss = 82249.11957362\n",
            "Validation score: 0.625829\n",
            "Iteration 5600, loss = 82225.72242793\n",
            "Validation score: 0.625905\n",
            "Iteration 5601, loss = 82198.20097860\n",
            "Validation score: 0.625988\n",
            "Iteration 5602, loss = 82172.69585616\n",
            "Validation score: 0.626075\n",
            "Iteration 5603, loss = 82147.98463110\n",
            "Validation score: 0.626176\n",
            "Iteration 5604, loss = 82120.44602836\n",
            "Validation score: 0.626279\n",
            "Iteration 5605, loss = 82095.81268842\n",
            "Validation score: 0.626390\n",
            "Iteration 5606, loss = 82073.58017822\n",
            "Validation score: 0.626493\n",
            "Iteration 5607, loss = 82045.63083485\n",
            "Validation score: 0.626592\n",
            "Iteration 5608, loss = 82021.55631817\n",
            "Validation score: 0.626683\n",
            "Iteration 5609, loss = 81997.04468518\n",
            "Validation score: 0.626790\n",
            "Iteration 5610, loss = 81972.08611276\n",
            "Validation score: 0.626897\n",
            "Iteration 5611, loss = 81948.39433541\n",
            "Validation score: 0.627020\n",
            "Iteration 5612, loss = 81922.49075774\n",
            "Validation score: 0.627127\n",
            "Iteration 5613, loss = 81897.12414031\n",
            "Validation score: 0.627222\n",
            "Iteration 5614, loss = 81869.27648554\n",
            "Validation score: 0.627304\n",
            "Iteration 5615, loss = 81843.45676602\n",
            "Validation score: 0.627388\n",
            "Iteration 5616, loss = 81818.32424574\n",
            "Validation score: 0.627482\n",
            "Iteration 5617, loss = 81795.19311080\n",
            "Validation score: 0.627566\n",
            "Iteration 5618, loss = 81770.36026266\n",
            "Validation score: 0.627665\n",
            "Iteration 5619, loss = 81741.35709096\n",
            "Validation score: 0.627781\n",
            "Iteration 5620, loss = 81718.58494022\n",
            "Validation score: 0.627916\n",
            "Iteration 5621, loss = 81690.60391145\n",
            "Validation score: 0.628051\n",
            "Iteration 5622, loss = 81666.82587330\n",
            "Validation score: 0.628193\n",
            "Iteration 5623, loss = 81640.82915600\n",
            "Validation score: 0.628315\n",
            "Iteration 5624, loss = 81616.00727222\n",
            "Validation score: 0.628441\n",
            "Iteration 5625, loss = 81590.60541641\n",
            "Validation score: 0.628559\n",
            "Iteration 5626, loss = 81564.40718158\n",
            "Validation score: 0.628665\n",
            "Iteration 5627, loss = 81540.08604317\n",
            "Validation score: 0.628780\n",
            "Iteration 5628, loss = 81516.58025571\n",
            "Validation score: 0.628875\n",
            "Iteration 5629, loss = 81490.36264562\n",
            "Validation score: 0.628955\n",
            "Iteration 5630, loss = 81462.88260335\n",
            "Validation score: 0.629035\n",
            "Iteration 5631, loss = 81440.00712286\n",
            "Validation score: 0.629102\n",
            "Iteration 5632, loss = 81412.32441344\n",
            "Validation score: 0.629159\n",
            "Iteration 5633, loss = 81388.64017708\n",
            "Validation score: 0.629224\n",
            "Iteration 5634, loss = 81360.09494895\n",
            "Validation score: 0.629302\n",
            "Iteration 5635, loss = 81336.40828087\n",
            "Validation score: 0.629372\n",
            "Iteration 5636, loss = 81309.56295731\n",
            "Validation score: 0.629457\n",
            "Iteration 5637, loss = 81287.13280855\n",
            "Validation score: 0.629540\n",
            "Iteration 5638, loss = 81258.89596185\n",
            "Validation score: 0.629635\n",
            "Iteration 5639, loss = 81233.36503928\n",
            "Validation score: 0.629725\n",
            "Iteration 5640, loss = 81209.53450409\n",
            "Validation score: 0.629822\n",
            "Iteration 5641, loss = 81181.28635622\n",
            "Validation score: 0.629902\n",
            "Iteration 5642, loss = 81153.80906921\n",
            "Validation score: 0.629984\n",
            "Iteration 5643, loss = 81128.94653100\n",
            "Validation score: 0.630067\n",
            "Iteration 5644, loss = 81104.99716543\n",
            "Validation score: 0.630148\n",
            "Iteration 5645, loss = 81077.83742438\n",
            "Validation score: 0.630243\n",
            "Iteration 5646, loss = 81052.28735904\n",
            "Validation score: 0.630342\n",
            "Iteration 5647, loss = 81026.06160585\n",
            "Validation score: 0.630436\n",
            "Iteration 5648, loss = 81002.28325713\n",
            "Validation score: 0.630536\n",
            "Iteration 5649, loss = 80975.71725407\n",
            "Validation score: 0.630643\n",
            "Iteration 5650, loss = 80950.23740979\n",
            "Validation score: 0.630743\n",
            "Iteration 5651, loss = 80925.75133109\n",
            "Validation score: 0.630844\n",
            "Iteration 5652, loss = 80901.02402207\n",
            "Validation score: 0.630957\n",
            "Iteration 5653, loss = 80876.34512240\n",
            "Validation score: 0.631073\n",
            "Iteration 5654, loss = 80851.53196118\n",
            "Validation score: 0.631182\n",
            "Iteration 5655, loss = 80826.48058364\n",
            "Validation score: 0.631281\n",
            "Iteration 5656, loss = 80803.86009776\n",
            "Validation score: 0.631374\n",
            "Iteration 5657, loss = 80779.11675357\n",
            "Validation score: 0.631473\n",
            "Iteration 5658, loss = 80753.16670400\n",
            "Validation score: 0.631576\n",
            "Iteration 5659, loss = 80730.12100386\n",
            "Validation score: 0.631667\n",
            "Iteration 5660, loss = 80706.17310650\n",
            "Validation score: 0.631748\n",
            "Iteration 5661, loss = 80682.10928700\n",
            "Validation score: 0.631813\n",
            "Iteration 5662, loss = 80660.06919113\n",
            "Validation score: 0.631887\n",
            "Iteration 5663, loss = 80636.54298627\n",
            "Validation score: 0.631974\n",
            "Iteration 5664, loss = 80612.39379331\n",
            "Validation score: 0.632067\n",
            "Iteration 5665, loss = 80586.88442257\n",
            "Validation score: 0.632166\n",
            "Iteration 5666, loss = 80563.82085193\n",
            "Validation score: 0.632289\n",
            "Iteration 5667, loss = 80537.73101690\n",
            "Validation score: 0.632409\n",
            "Iteration 5668, loss = 80512.60811660\n",
            "Validation score: 0.632531\n",
            "Iteration 5669, loss = 80488.19167241\n",
            "Validation score: 0.632658\n",
            "Iteration 5670, loss = 80462.30571961\n",
            "Validation score: 0.632779\n",
            "Iteration 5671, loss = 80438.48656974\n",
            "Validation score: 0.632914\n",
            "Iteration 5672, loss = 80415.03562056\n",
            "Validation score: 0.633058\n",
            "Iteration 5673, loss = 80389.36298717\n",
            "Validation score: 0.633175\n",
            "Iteration 5674, loss = 80366.53779738\n",
            "Validation score: 0.633280\n",
            "Iteration 5675, loss = 80339.85650125\n",
            "Validation score: 0.633396\n",
            "Iteration 5676, loss = 80315.93629103\n",
            "Validation score: 0.633536\n",
            "Iteration 5677, loss = 80292.43571414\n",
            "Validation score: 0.633672\n",
            "Iteration 5678, loss = 80265.31339606\n",
            "Validation score: 0.633781\n",
            "Iteration 5679, loss = 80241.90326444\n",
            "Validation score: 0.633873\n",
            "Iteration 5680, loss = 80216.30390650\n",
            "Validation score: 0.633959\n",
            "Iteration 5681, loss = 80192.84171941\n",
            "Validation score: 0.634058\n",
            "Iteration 5682, loss = 80167.52740703\n",
            "Validation score: 0.634139\n",
            "Iteration 5683, loss = 80142.05463866\n",
            "Validation score: 0.634232\n",
            "Iteration 5684, loss = 80117.98966735\n",
            "Validation score: 0.634328\n",
            "Iteration 5685, loss = 80093.38425491\n",
            "Validation score: 0.634419\n",
            "Iteration 5686, loss = 80068.29044570\n",
            "Validation score: 0.634498\n",
            "Iteration 5687, loss = 80042.92474262\n",
            "Validation score: 0.634588\n",
            "Iteration 5688, loss = 80018.69313454\n",
            "Validation score: 0.634683\n",
            "Iteration 5689, loss = 79994.46914424\n",
            "Validation score: 0.634773\n",
            "Iteration 5690, loss = 79968.28695854\n",
            "Validation score: 0.634860\n",
            "Iteration 5691, loss = 79943.90779571\n",
            "Validation score: 0.634952\n",
            "Iteration 5692, loss = 79917.21974657\n",
            "Validation score: 0.635031\n",
            "Iteration 5693, loss = 79892.49743856\n",
            "Validation score: 0.635110\n",
            "Iteration 5694, loss = 79865.29693574\n",
            "Validation score: 0.635203\n",
            "Iteration 5695, loss = 79840.89250741\n",
            "Validation score: 0.635296\n",
            "Iteration 5696, loss = 79814.51858312\n",
            "Validation score: 0.635397\n",
            "Iteration 5697, loss = 79788.83595032\n",
            "Validation score: 0.635515\n",
            "Iteration 5698, loss = 79760.72460793\n",
            "Validation score: 0.635623\n",
            "Iteration 5699, loss = 79737.37240158\n",
            "Validation score: 0.635720\n",
            "Iteration 5700, loss = 79708.92503888\n",
            "Validation score: 0.635818\n",
            "Iteration 5701, loss = 79683.86610062\n",
            "Validation score: 0.635906\n",
            "Iteration 5702, loss = 79657.88313994\n",
            "Validation score: 0.635988\n",
            "Iteration 5703, loss = 79633.23170890\n",
            "Validation score: 0.636075\n",
            "Iteration 5704, loss = 79609.47717810\n",
            "Validation score: 0.636158\n",
            "Iteration 5705, loss = 79587.81329964\n",
            "Validation score: 0.636253\n",
            "Iteration 5706, loss = 79561.74226000\n",
            "Validation score: 0.636351\n",
            "Iteration 5707, loss = 79537.17148431\n",
            "Validation score: 0.636450\n",
            "Iteration 5708, loss = 79511.76385551\n",
            "Validation score: 0.636546\n",
            "Iteration 5709, loss = 79486.21301622\n",
            "Validation score: 0.636656\n",
            "Iteration 5710, loss = 79462.11788699\n",
            "Validation score: 0.636749\n",
            "Iteration 5711, loss = 79436.26746661\n",
            "Validation score: 0.636837\n",
            "Iteration 5712, loss = 79410.24962172\n",
            "Validation score: 0.636927\n",
            "Iteration 5713, loss = 79387.69718333\n",
            "Validation score: 0.637022\n",
            "Iteration 5714, loss = 79362.21311766\n",
            "Validation score: 0.637115\n",
            "Iteration 5715, loss = 79337.08550401\n",
            "Validation score: 0.637203\n",
            "Iteration 5716, loss = 79309.22210308\n",
            "Validation score: 0.637299\n",
            "Iteration 5717, loss = 79285.02615432\n",
            "Validation score: 0.637384\n",
            "Iteration 5718, loss = 79261.35801654\n",
            "Validation score: 0.637449\n",
            "Iteration 5719, loss = 79234.85738478\n",
            "Validation score: 0.637516\n",
            "Iteration 5720, loss = 79211.28727269\n",
            "Validation score: 0.637607\n",
            "Iteration 5721, loss = 79187.99881546\n",
            "Validation score: 0.637707\n",
            "Iteration 5722, loss = 79164.05797062\n",
            "Validation score: 0.637812\n",
            "Iteration 5723, loss = 79137.91077719\n",
            "Validation score: 0.637942\n",
            "Iteration 5724, loss = 79116.42674525\n",
            "Validation score: 0.638096\n",
            "Iteration 5725, loss = 79089.31017991\n",
            "Validation score: 0.638241\n",
            "Iteration 5726, loss = 79065.21644279\n",
            "Validation score: 0.638388\n",
            "Iteration 5727, loss = 79041.82244522\n",
            "Validation score: 0.638526\n",
            "Iteration 5728, loss = 79016.93995982\n",
            "Validation score: 0.638658\n",
            "Iteration 5729, loss = 78996.33642852\n",
            "Validation score: 0.638787\n",
            "Iteration 5730, loss = 78971.37717668\n",
            "Validation score: 0.638893\n",
            "Iteration 5731, loss = 78947.32940341\n",
            "Validation score: 0.638986\n",
            "Iteration 5732, loss = 78924.92758813\n",
            "Validation score: 0.639090\n",
            "Iteration 5733, loss = 78899.81109478\n",
            "Validation score: 0.639218\n",
            "Iteration 5734, loss = 78877.13985053\n",
            "Validation score: 0.639357\n",
            "Iteration 5735, loss = 78853.48857435\n",
            "Validation score: 0.639480\n",
            "Iteration 5736, loss = 78828.51385630\n",
            "Validation score: 0.639604\n",
            "Iteration 5737, loss = 78805.58684193\n",
            "Validation score: 0.639736\n",
            "Iteration 5738, loss = 78780.85057342\n",
            "Validation score: 0.639861\n",
            "Iteration 5739, loss = 78756.96082798\n",
            "Validation score: 0.639986\n",
            "Iteration 5740, loss = 78732.98068059\n",
            "Validation score: 0.640092\n",
            "Iteration 5741, loss = 78708.65981544\n",
            "Validation score: 0.640189\n",
            "Iteration 5742, loss = 78684.83763137\n",
            "Validation score: 0.640277\n",
            "Iteration 5743, loss = 78663.78464652\n",
            "Validation score: 0.640380\n",
            "Iteration 5744, loss = 78637.05114917\n",
            "Validation score: 0.640500\n",
            "Iteration 5745, loss = 78613.62507999\n",
            "Validation score: 0.640612\n",
            "Iteration 5746, loss = 78591.48395097\n",
            "Validation score: 0.640729\n",
            "Iteration 5747, loss = 78563.86859308\n",
            "Validation score: 0.640834\n",
            "Iteration 5748, loss = 78539.17470776\n",
            "Validation score: 0.640925\n",
            "Iteration 5749, loss = 78517.14877580\n",
            "Validation score: 0.641000\n",
            "Iteration 5750, loss = 78490.74294412\n",
            "Validation score: 0.641071\n",
            "Iteration 5751, loss = 78466.52238755\n",
            "Validation score: 0.641153\n",
            "Iteration 5752, loss = 78440.78716812\n",
            "Validation score: 0.641252\n",
            "Iteration 5753, loss = 78416.20779209\n",
            "Validation score: 0.641366\n",
            "Iteration 5754, loss = 78392.54061844\n",
            "Validation score: 0.641482\n",
            "Iteration 5755, loss = 78367.15708314\n",
            "Validation score: 0.641593\n",
            "Iteration 5756, loss = 78343.95344089\n",
            "Validation score: 0.641706\n",
            "Iteration 5757, loss = 78319.38325203\n",
            "Validation score: 0.641814\n",
            "Iteration 5758, loss = 78294.13320560\n",
            "Validation score: 0.641917\n",
            "Iteration 5759, loss = 78273.36575921\n",
            "Validation score: 0.642028\n",
            "Iteration 5760, loss = 78246.10493326\n",
            "Validation score: 0.642135\n",
            "Iteration 5761, loss = 78223.00416914\n",
            "Validation score: 0.642235\n",
            "Iteration 5762, loss = 78197.82907943\n",
            "Validation score: 0.642330\n",
            "Iteration 5763, loss = 78175.94836628\n",
            "Validation score: 0.642422\n",
            "Iteration 5764, loss = 78152.22653600\n",
            "Validation score: 0.642522\n",
            "Iteration 5765, loss = 78129.20123618\n",
            "Validation score: 0.642617\n",
            "Iteration 5766, loss = 78106.28866542\n",
            "Validation score: 0.642685\n",
            "Iteration 5767, loss = 78081.36961848\n",
            "Validation score: 0.642760\n",
            "Iteration 5768, loss = 78059.62180232\n",
            "Validation score: 0.642837\n",
            "Iteration 5769, loss = 78035.97098898\n",
            "Validation score: 0.642925\n",
            "Iteration 5770, loss = 78012.68195340\n",
            "Validation score: 0.643029\n",
            "Iteration 5771, loss = 77989.20732960\n",
            "Validation score: 0.643125\n",
            "Iteration 5772, loss = 77967.77812163\n",
            "Validation score: 0.643215\n",
            "Iteration 5773, loss = 77941.57179964\n",
            "Validation score: 0.643312\n",
            "Iteration 5774, loss = 77918.13606851\n",
            "Validation score: 0.643405\n",
            "Iteration 5775, loss = 77895.06889392\n",
            "Validation score: 0.643484\n",
            "Iteration 5776, loss = 77873.06466700\n",
            "Validation score: 0.643572\n",
            "Iteration 5777, loss = 77847.72152975\n",
            "Validation score: 0.643662\n",
            "Iteration 5778, loss = 77823.97754131\n",
            "Validation score: 0.643745\n",
            "Iteration 5779, loss = 77800.19496171\n",
            "Validation score: 0.643822\n",
            "Iteration 5780, loss = 77775.47859051\n",
            "Validation score: 0.643903\n",
            "Iteration 5781, loss = 77751.63577309\n",
            "Validation score: 0.643985\n",
            "Iteration 5782, loss = 77729.48305550\n",
            "Validation score: 0.644064\n",
            "Iteration 5783, loss = 77707.03153838\n",
            "Validation score: 0.644144\n",
            "Iteration 5784, loss = 77683.52987192\n",
            "Validation score: 0.644219\n",
            "Iteration 5785, loss = 77659.47706520\n",
            "Validation score: 0.644301\n",
            "Iteration 5786, loss = 77636.56984355\n",
            "Validation score: 0.644370\n",
            "Iteration 5787, loss = 77612.59717233\n",
            "Validation score: 0.644433\n",
            "Iteration 5788, loss = 77594.14042309\n",
            "Validation score: 0.644488\n",
            "Iteration 5789, loss = 77570.69024147\n",
            "Validation score: 0.644571\n",
            "Iteration 5790, loss = 77548.20021622\n",
            "Validation score: 0.644655\n",
            "Iteration 5791, loss = 77523.88897049\n",
            "Validation score: 0.644756\n",
            "Iteration 5792, loss = 77498.69143139\n",
            "Validation score: 0.644867\n",
            "Iteration 5793, loss = 77473.71640695\n",
            "Validation score: 0.644979\n",
            "Iteration 5794, loss = 77450.55751700\n",
            "Validation score: 0.645110\n",
            "Iteration 5795, loss = 77428.42574341\n",
            "Validation score: 0.645244\n",
            "Iteration 5796, loss = 77403.58406501\n",
            "Validation score: 0.645343\n",
            "Iteration 5797, loss = 77379.17855891\n",
            "Validation score: 0.645436\n",
            "Iteration 5798, loss = 77354.87762750\n",
            "Validation score: 0.645538\n",
            "Iteration 5799, loss = 77331.54858846\n",
            "Validation score: 0.645623\n",
            "Iteration 5800, loss = 77308.38532087\n",
            "Validation score: 0.645707\n",
            "Iteration 5801, loss = 77286.40212085\n",
            "Validation score: 0.645786\n",
            "Iteration 5802, loss = 77263.32479536\n",
            "Validation score: 0.645870\n",
            "Iteration 5803, loss = 77240.79687335\n",
            "Validation score: 0.645958\n",
            "Iteration 5804, loss = 77217.85816659\n",
            "Validation score: 0.646055\n",
            "Iteration 5805, loss = 77196.73132074\n",
            "Validation score: 0.646141\n",
            "Iteration 5806, loss = 77174.71058901\n",
            "Validation score: 0.646226\n",
            "Iteration 5807, loss = 77151.99353837\n",
            "Validation score: 0.646330\n",
            "Iteration 5808, loss = 77129.89371959\n",
            "Validation score: 0.646446\n",
            "Iteration 5809, loss = 77107.24485645\n",
            "Validation score: 0.646563\n",
            "Iteration 5810, loss = 77083.04214311\n",
            "Validation score: 0.646692\n",
            "Iteration 5811, loss = 77061.43569324\n",
            "Validation score: 0.646813\n",
            "Iteration 5812, loss = 77037.38469568\n",
            "Validation score: 0.646924\n",
            "Iteration 5813, loss = 77014.31722867\n",
            "Validation score: 0.647031\n",
            "Iteration 5814, loss = 76991.70174308\n",
            "Validation score: 0.647151\n",
            "Iteration 5815, loss = 76969.72503845\n",
            "Validation score: 0.647272\n",
            "Iteration 5816, loss = 76945.39542864\n",
            "Validation score: 0.647407\n",
            "Iteration 5817, loss = 76923.26845164\n",
            "Validation score: 0.647533\n",
            "Iteration 5818, loss = 76900.34284738\n",
            "Validation score: 0.647646\n",
            "Iteration 5819, loss = 76877.05292547\n",
            "Validation score: 0.647750\n",
            "Iteration 5820, loss = 76857.02141369\n",
            "Validation score: 0.647839\n",
            "Iteration 5821, loss = 76826.79357065\n",
            "Validation score: 0.647923\n",
            "Iteration 5822, loss = 76806.58428469\n",
            "Validation score: 0.648001\n",
            "Iteration 5823, loss = 76782.24862130\n",
            "Validation score: 0.648077\n",
            "Iteration 5824, loss = 76758.10378543\n",
            "Validation score: 0.648143\n",
            "Iteration 5825, loss = 76736.68330331\n",
            "Validation score: 0.648212\n",
            "Iteration 5826, loss = 76713.33007860\n",
            "Validation score: 0.648301\n",
            "Iteration 5827, loss = 76689.99733245\n",
            "Validation score: 0.648382\n",
            "Iteration 5828, loss = 76667.21166315\n",
            "Validation score: 0.648472\n",
            "Iteration 5829, loss = 76644.89630838\n",
            "Validation score: 0.648573\n",
            "Iteration 5830, loss = 76621.08331498\n",
            "Validation score: 0.648675\n",
            "Iteration 5831, loss = 76599.51882630\n",
            "Validation score: 0.648779\n",
            "Iteration 5832, loss = 76575.55456524\n",
            "Validation score: 0.648896\n",
            "Iteration 5833, loss = 76551.01549513\n",
            "Validation score: 0.648986\n",
            "Iteration 5834, loss = 76527.20911733\n",
            "Validation score: 0.649074\n",
            "Iteration 5835, loss = 76503.12998700\n",
            "Validation score: 0.649184\n",
            "Iteration 5836, loss = 76480.86179187\n",
            "Validation score: 0.649288\n",
            "Iteration 5837, loss = 76456.79420773\n",
            "Validation score: 0.649377\n",
            "Iteration 5838, loss = 76433.94788921\n",
            "Validation score: 0.649476\n",
            "Iteration 5839, loss = 76408.24198182\n",
            "Validation score: 0.649570\n",
            "Iteration 5840, loss = 76385.17205123\n",
            "Validation score: 0.649682\n",
            "Iteration 5841, loss = 76362.08478874\n",
            "Validation score: 0.649797\n",
            "Iteration 5842, loss = 76339.81810681\n",
            "Validation score: 0.649904\n",
            "Iteration 5843, loss = 76314.87083102\n",
            "Validation score: 0.650023\n",
            "Iteration 5844, loss = 76296.07195932\n",
            "Validation score: 0.650146\n",
            "Iteration 5845, loss = 76271.49782666\n",
            "Validation score: 0.650247\n",
            "Iteration 5846, loss = 76246.86001740\n",
            "Validation score: 0.650343\n",
            "Iteration 5847, loss = 76224.40080913\n",
            "Validation score: 0.650434\n",
            "Iteration 5848, loss = 76201.58555973\n",
            "Validation score: 0.650516\n",
            "Iteration 5849, loss = 76177.52834483\n",
            "Validation score: 0.650594\n",
            "Iteration 5850, loss = 76156.31161225\n",
            "Validation score: 0.650673\n",
            "Iteration 5851, loss = 76132.76734837\n",
            "Validation score: 0.650761\n",
            "Iteration 5852, loss = 76109.08653669\n",
            "Validation score: 0.650853\n",
            "Iteration 5853, loss = 76084.69086161\n",
            "Validation score: 0.650947\n",
            "Iteration 5854, loss = 76062.78889880\n",
            "Validation score: 0.651055\n",
            "Iteration 5855, loss = 76039.20548767\n",
            "Validation score: 0.651159\n",
            "Iteration 5856, loss = 76016.38551332\n",
            "Validation score: 0.651255\n",
            "Iteration 5857, loss = 75991.88675189\n",
            "Validation score: 0.651361\n",
            "Iteration 5858, loss = 75971.80607252\n",
            "Validation score: 0.651460\n",
            "Iteration 5859, loss = 75946.99244844\n",
            "Validation score: 0.651564\n",
            "Iteration 5860, loss = 75925.52238676\n",
            "Validation score: 0.651669\n",
            "Iteration 5861, loss = 75901.74347576\n",
            "Validation score: 0.651778\n",
            "Iteration 5862, loss = 75878.70608667\n",
            "Validation score: 0.651875\n",
            "Iteration 5863, loss = 75854.58232443\n",
            "Validation score: 0.651986\n",
            "Iteration 5864, loss = 75831.92373523\n",
            "Validation score: 0.652100\n",
            "Iteration 5865, loss = 75810.36401758\n",
            "Validation score: 0.652228\n",
            "Iteration 5866, loss = 75787.64616482\n",
            "Validation score: 0.652348\n",
            "Iteration 5867, loss = 75764.82178894\n",
            "Validation score: 0.652489\n",
            "Iteration 5868, loss = 75742.04693579\n",
            "Validation score: 0.652634\n",
            "Iteration 5869, loss = 75720.01648447\n",
            "Validation score: 0.652770\n",
            "Iteration 5870, loss = 75698.43373817\n",
            "Validation score: 0.652905\n",
            "Iteration 5871, loss = 75678.16285139\n",
            "Validation score: 0.653026\n",
            "Iteration 5872, loss = 75654.33677270\n",
            "Validation score: 0.653140\n",
            "Iteration 5873, loss = 75633.92519389\n",
            "Validation score: 0.653260\n",
            "Iteration 5874, loss = 75613.68194683\n",
            "Validation score: 0.653360\n",
            "Iteration 5875, loss = 75589.38568333\n",
            "Validation score: 0.653442\n",
            "Iteration 5876, loss = 75569.23477145\n",
            "Validation score: 0.653529\n",
            "Iteration 5877, loss = 75546.57312580\n",
            "Validation score: 0.653622\n",
            "Iteration 5878, loss = 75526.21370402\n",
            "Validation score: 0.653685\n",
            "Iteration 5879, loss = 75502.72431105\n",
            "Validation score: 0.653761\n",
            "Iteration 5880, loss = 75480.08266149\n",
            "Validation score: 0.653829\n",
            "Iteration 5881, loss = 75457.74566358\n",
            "Validation score: 0.653882\n",
            "Iteration 5882, loss = 75440.26608814\n",
            "Validation score: 0.653934\n",
            "Iteration 5883, loss = 75413.60645447\n",
            "Validation score: 0.654003\n",
            "Iteration 5884, loss = 75390.93477049\n",
            "Validation score: 0.654082\n",
            "Iteration 5885, loss = 75369.57723662\n",
            "Validation score: 0.654151\n",
            "Iteration 5886, loss = 75347.21700067\n",
            "Validation score: 0.654237\n",
            "Iteration 5887, loss = 75328.07859459\n",
            "Validation score: 0.654313\n",
            "Iteration 5888, loss = 75302.75414282\n",
            "Validation score: 0.654400\n",
            "Iteration 5889, loss = 75280.42818584\n",
            "Validation score: 0.654489\n",
            "Iteration 5890, loss = 75257.49005925\n",
            "Validation score: 0.654575\n",
            "Iteration 5891, loss = 75234.48290575\n",
            "Validation score: 0.654655\n",
            "Iteration 5892, loss = 75211.38934715\n",
            "Validation score: 0.654752\n",
            "Iteration 5893, loss = 75188.20240525\n",
            "Validation score: 0.654848\n",
            "Iteration 5894, loss = 75167.53660165\n",
            "Validation score: 0.654933\n",
            "Iteration 5895, loss = 75143.62927262\n",
            "Validation score: 0.655029\n",
            "Iteration 5896, loss = 75123.70452745\n",
            "Validation score: 0.655128\n",
            "Iteration 5897, loss = 75101.97313191\n",
            "Validation score: 0.655224\n",
            "Iteration 5898, loss = 75080.36447684\n",
            "Validation score: 0.655329\n",
            "Iteration 5899, loss = 75060.01603095\n",
            "Validation score: 0.655438\n",
            "Iteration 5900, loss = 75040.45603896\n",
            "Validation score: 0.655554\n",
            "Iteration 5901, loss = 75017.03960752\n",
            "Validation score: 0.655650\n",
            "Iteration 5902, loss = 74995.26593051\n",
            "Validation score: 0.655747\n",
            "Iteration 5903, loss = 74972.59418359\n",
            "Validation score: 0.655854\n",
            "Iteration 5904, loss = 74953.25539925\n",
            "Validation score: 0.655962\n",
            "Iteration 5905, loss = 74930.33812300\n",
            "Validation score: 0.656056\n",
            "Iteration 5906, loss = 74909.30138184\n",
            "Validation score: 0.656149\n",
            "Iteration 5907, loss = 74888.00136255\n",
            "Validation score: 0.656260\n",
            "Iteration 5908, loss = 74864.30693356\n",
            "Validation score: 0.656370\n",
            "Iteration 5909, loss = 74844.47217869\n",
            "Validation score: 0.656483\n",
            "Iteration 5910, loss = 74819.89861695\n",
            "Validation score: 0.656588\n",
            "Iteration 5911, loss = 74799.40085267\n",
            "Validation score: 0.656696\n",
            "Iteration 5912, loss = 74776.60374471\n",
            "Validation score: 0.656795\n",
            "Iteration 5913, loss = 74753.23190794\n",
            "Validation score: 0.656883\n",
            "Iteration 5914, loss = 74731.68530892\n",
            "Validation score: 0.656968\n",
            "Iteration 5915, loss = 74711.44103984\n",
            "Validation score: 0.657050\n",
            "Iteration 5916, loss = 74688.20463406\n",
            "Validation score: 0.657119\n",
            "Iteration 5917, loss = 74666.64252039\n",
            "Validation score: 0.657198\n",
            "Iteration 5918, loss = 74645.20979177\n",
            "Validation score: 0.657265\n",
            "Iteration 5919, loss = 74623.89820923\n",
            "Validation score: 0.657349\n",
            "Iteration 5920, loss = 74602.53563055\n",
            "Validation score: 0.657449\n",
            "Iteration 5921, loss = 74579.25722687\n",
            "Validation score: 0.657533\n",
            "Iteration 5922, loss = 74557.52555682\n",
            "Validation score: 0.657617\n",
            "Iteration 5923, loss = 74537.35379024\n",
            "Validation score: 0.657717\n",
            "Iteration 5924, loss = 74513.96467107\n",
            "Validation score: 0.657792\n",
            "Iteration 5925, loss = 74491.85096005\n",
            "Validation score: 0.657872\n",
            "Iteration 5926, loss = 74467.54909295\n",
            "Validation score: 0.657962\n",
            "Iteration 5927, loss = 74445.38686977\n",
            "Validation score: 0.658059\n",
            "Iteration 5928, loss = 74422.39371048\n",
            "Validation score: 0.658140\n",
            "Iteration 5929, loss = 74398.71840133\n",
            "Validation score: 0.658210\n",
            "Iteration 5930, loss = 74374.16767246\n",
            "Validation score: 0.658288\n",
            "Iteration 5931, loss = 74353.50185906\n",
            "Validation score: 0.658349\n",
            "Iteration 5932, loss = 74329.10324951\n",
            "Validation score: 0.658427\n",
            "Iteration 5933, loss = 74306.07763056\n",
            "Validation score: 0.658486\n",
            "Iteration 5934, loss = 74282.52716290\n",
            "Validation score: 0.658547\n",
            "Iteration 5935, loss = 74262.29453824\n",
            "Validation score: 0.658620\n",
            "Iteration 5936, loss = 74241.94624958\n",
            "Validation score: 0.658690\n",
            "Iteration 5937, loss = 74218.62855484\n",
            "Validation score: 0.658773\n",
            "Iteration 5938, loss = 74198.87088102\n",
            "Validation score: 0.658854\n",
            "Iteration 5939, loss = 74176.85047473\n",
            "Validation score: 0.658930\n",
            "Iteration 5940, loss = 74156.08284116\n",
            "Validation score: 0.659017\n",
            "Iteration 5941, loss = 74133.98592739\n",
            "Validation score: 0.659095\n",
            "Iteration 5942, loss = 74113.40551078\n",
            "Validation score: 0.659158\n",
            "Iteration 5943, loss = 74091.13582307\n",
            "Validation score: 0.659257\n",
            "Iteration 5944, loss = 74069.59647660\n",
            "Validation score: 0.659364\n",
            "Iteration 5945, loss = 74047.38037845\n",
            "Validation score: 0.659457\n",
            "Iteration 5946, loss = 74024.73284712\n",
            "Validation score: 0.659545\n",
            "Iteration 5947, loss = 74004.81344070\n",
            "Validation score: 0.659655\n",
            "Iteration 5948, loss = 73981.53989784\n",
            "Validation score: 0.659751\n",
            "Iteration 5949, loss = 73960.14635486\n",
            "Validation score: 0.659848\n",
            "Iteration 5950, loss = 73937.99117148\n",
            "Validation score: 0.659942\n",
            "Iteration 5951, loss = 73917.57784327\n",
            "Validation score: 0.660045\n",
            "Iteration 5952, loss = 73896.66110668\n",
            "Validation score: 0.660164\n",
            "Iteration 5953, loss = 73873.15588905\n",
            "Validation score: 0.660271\n",
            "Iteration 5954, loss = 73853.52629946\n",
            "Validation score: 0.660369\n",
            "Iteration 5955, loss = 73831.63369736\n",
            "Validation score: 0.660461\n",
            "Iteration 5956, loss = 73808.91925934\n",
            "Validation score: 0.660558\n",
            "Iteration 5957, loss = 73787.90950520\n",
            "Validation score: 0.660665\n",
            "Iteration 5958, loss = 73766.74679367\n",
            "Validation score: 0.660773\n",
            "Iteration 5959, loss = 73745.01625688\n",
            "Validation score: 0.660859\n",
            "Iteration 5960, loss = 73722.89353181\n",
            "Validation score: 0.660942\n",
            "Iteration 5961, loss = 73699.89169771\n",
            "Validation score: 0.661013\n",
            "Iteration 5962, loss = 73678.62795334\n",
            "Validation score: 0.661092\n",
            "Iteration 5963, loss = 73657.34377249\n",
            "Validation score: 0.661183\n",
            "Iteration 5964, loss = 73635.43432169\n",
            "Validation score: 0.661272\n",
            "Iteration 5965, loss = 73613.87817339\n",
            "Validation score: 0.661380\n",
            "Iteration 5966, loss = 73593.56411805\n",
            "Validation score: 0.661484\n",
            "Iteration 5967, loss = 73571.54249902\n",
            "Validation score: 0.661574\n",
            "Iteration 5968, loss = 73550.96403757\n",
            "Validation score: 0.661658\n",
            "Iteration 5969, loss = 73529.99308703\n",
            "Validation score: 0.661746\n",
            "Iteration 5970, loss = 73508.21454045\n",
            "Validation score: 0.661858\n",
            "Iteration 5971, loss = 73490.55780857\n",
            "Validation score: 0.661974\n",
            "Iteration 5972, loss = 73467.20990322\n",
            "Validation score: 0.662079\n",
            "Iteration 5973, loss = 73446.46369028\n",
            "Validation score: 0.662180\n",
            "Iteration 5974, loss = 73427.03770433\n",
            "Validation score: 0.662287\n",
            "Iteration 5975, loss = 73406.61644910\n",
            "Validation score: 0.662386\n",
            "Iteration 5976, loss = 73387.82460637\n",
            "Validation score: 0.662472\n",
            "Iteration 5977, loss = 73366.28708891\n",
            "Validation score: 0.662566\n",
            "Iteration 5978, loss = 73345.91060929\n",
            "Validation score: 0.662659\n",
            "Iteration 5979, loss = 73323.83419434\n",
            "Validation score: 0.662755\n",
            "Iteration 5980, loss = 73303.38313517\n",
            "Validation score: 0.662862\n",
            "Iteration 5981, loss = 73278.99533794\n",
            "Validation score: 0.662957\n",
            "Iteration 5982, loss = 73258.45279093\n",
            "Validation score: 0.663047\n",
            "Iteration 5983, loss = 73234.94549780\n",
            "Validation score: 0.663146\n",
            "Iteration 5984, loss = 73213.00565909\n",
            "Validation score: 0.663255\n",
            "Iteration 5985, loss = 73191.10185066\n",
            "Validation score: 0.663364\n",
            "Iteration 5986, loss = 73171.22534925\n",
            "Validation score: 0.663478\n",
            "Iteration 5987, loss = 73148.66619348\n",
            "Validation score: 0.663568\n",
            "Iteration 5988, loss = 73126.60612121\n",
            "Validation score: 0.663633\n",
            "Iteration 5989, loss = 73106.09470059\n",
            "Validation score: 0.663687\n",
            "Iteration 5990, loss = 73085.46396442\n",
            "Validation score: 0.663756\n",
            "Iteration 5991, loss = 73061.11360162\n",
            "Validation score: 0.663834\n",
            "Iteration 5992, loss = 73042.38912927\n",
            "Validation score: 0.663923\n",
            "Iteration 5993, loss = 73020.23935355\n",
            "Validation score: 0.664010\n",
            "Iteration 5994, loss = 72999.07178787\n",
            "Validation score: 0.664088\n",
            "Iteration 5995, loss = 72979.62980258\n",
            "Validation score: 0.664154\n",
            "Iteration 5996, loss = 72958.84178376\n",
            "Validation score: 0.664203\n",
            "Iteration 5997, loss = 72938.21533742\n",
            "Validation score: 0.664258\n",
            "Iteration 5998, loss = 72915.56748821\n",
            "Validation score: 0.664325\n",
            "Iteration 5999, loss = 72891.80479136\n",
            "Validation score: 0.664402\n",
            "Iteration 6000, loss = 72871.55968124\n",
            "Validation score: 0.664473\n",
            "Iteration 6001, loss = 72850.32217376\n",
            "Validation score: 0.664536\n",
            "Iteration 6002, loss = 72825.80745549\n",
            "Validation score: 0.664583\n",
            "Iteration 6003, loss = 72807.97610344\n",
            "Validation score: 0.664637\n",
            "Iteration 6004, loss = 72785.92735870\n",
            "Validation score: 0.664709\n",
            "Iteration 6005, loss = 72763.56675677\n",
            "Validation score: 0.664793\n",
            "Iteration 6006, loss = 72743.75187604\n",
            "Validation score: 0.664870\n",
            "Iteration 6007, loss = 72721.14828781\n",
            "Validation score: 0.664953\n",
            "Iteration 6008, loss = 72700.83076123\n",
            "Validation score: 0.665034\n",
            "Iteration 6009, loss = 72678.72068293\n",
            "Validation score: 0.665139\n",
            "Iteration 6010, loss = 72658.45522016\n",
            "Validation score: 0.665241\n",
            "Iteration 6011, loss = 72636.23008722\n",
            "Validation score: 0.665344\n",
            "Iteration 6012, loss = 72615.58654119\n",
            "Validation score: 0.665438\n",
            "Iteration 6013, loss = 72595.02147045\n",
            "Validation score: 0.665550\n",
            "Iteration 6014, loss = 72572.79186979\n",
            "Validation score: 0.665661\n",
            "Iteration 6015, loss = 72553.46899703\n",
            "Validation score: 0.665773\n",
            "Iteration 6016, loss = 72534.07862380\n",
            "Validation score: 0.665870\n",
            "Iteration 6017, loss = 72514.91068411\n",
            "Validation score: 0.665976\n",
            "Iteration 6018, loss = 72495.70080721\n",
            "Validation score: 0.666058\n",
            "Iteration 6019, loss = 72478.09661451\n",
            "Validation score: 0.666173\n",
            "Iteration 6020, loss = 72454.34996411\n",
            "Validation score: 0.666270\n",
            "Iteration 6021, loss = 72434.36416800\n",
            "Validation score: 0.666356\n",
            "Iteration 6022, loss = 72415.16240492\n",
            "Validation score: 0.666436\n",
            "Iteration 6023, loss = 72393.20596192\n",
            "Validation score: 0.666522\n",
            "Iteration 6024, loss = 72372.06889545\n",
            "Validation score: 0.666621\n",
            "Iteration 6025, loss = 72353.34538504\n",
            "Validation score: 0.666727\n",
            "Iteration 6026, loss = 72330.97966118\n",
            "Validation score: 0.666823\n",
            "Iteration 6027, loss = 72309.11607156\n",
            "Validation score: 0.666932\n",
            "Iteration 6028, loss = 72289.13468702\n",
            "Validation score: 0.667045\n",
            "Iteration 6029, loss = 72268.19308873\n",
            "Validation score: 0.667161\n",
            "Iteration 6030, loss = 72247.23880646\n",
            "Validation score: 0.667280\n",
            "Iteration 6031, loss = 72227.40158791\n",
            "Validation score: 0.667396\n",
            "Iteration 6032, loss = 72207.09251438\n",
            "Validation score: 0.667493\n",
            "Iteration 6033, loss = 72185.37991450\n",
            "Validation score: 0.667572\n",
            "Iteration 6034, loss = 72166.55883852\n",
            "Validation score: 0.667644\n",
            "Iteration 6035, loss = 72145.84882683\n",
            "Validation score: 0.667722\n",
            "Iteration 6036, loss = 72126.32318891\n",
            "Validation score: 0.667803\n",
            "Iteration 6037, loss = 72105.49324963\n",
            "Validation score: 0.667875\n",
            "Iteration 6038, loss = 72085.53952611\n",
            "Validation score: 0.667931\n",
            "Iteration 6039, loss = 72064.38721722\n",
            "Validation score: 0.667987\n",
            "Iteration 6040, loss = 72044.00784164\n",
            "Validation score: 0.668048\n",
            "Iteration 6041, loss = 72022.64789399\n",
            "Validation score: 0.668117\n",
            "Iteration 6042, loss = 72002.48521757\n",
            "Validation score: 0.668192\n",
            "Iteration 6043, loss = 71982.96253919\n",
            "Validation score: 0.668276\n",
            "Iteration 6044, loss = 71962.01785931\n",
            "Validation score: 0.668373\n",
            "Iteration 6045, loss = 71941.46818375\n",
            "Validation score: 0.668472\n",
            "Iteration 6046, loss = 71921.19179390\n",
            "Validation score: 0.668554\n",
            "Iteration 6047, loss = 71897.69332585\n",
            "Validation score: 0.668641\n",
            "Iteration 6048, loss = 71876.14899639\n",
            "Validation score: 0.668744\n",
            "Iteration 6049, loss = 71854.07320223\n",
            "Validation score: 0.668843\n",
            "Iteration 6050, loss = 71831.38172811\n",
            "Validation score: 0.668947\n",
            "Iteration 6051, loss = 71812.40184075\n",
            "Validation score: 0.669047\n",
            "Iteration 6052, loss = 71791.48103341\n",
            "Validation score: 0.669164\n",
            "Iteration 6053, loss = 71771.06860441\n",
            "Validation score: 0.669266\n",
            "Iteration 6054, loss = 71752.37964568\n",
            "Validation score: 0.669359\n",
            "Iteration 6055, loss = 71729.89679984\n",
            "Validation score: 0.669458\n",
            "Iteration 6056, loss = 71709.23813611\n",
            "Validation score: 0.669545\n",
            "Iteration 6057, loss = 71689.54413751\n",
            "Validation score: 0.669615\n",
            "Iteration 6058, loss = 71668.70715046\n",
            "Validation score: 0.669679\n",
            "Iteration 6059, loss = 71647.76874538\n",
            "Validation score: 0.669734\n",
            "Iteration 6060, loss = 71627.94495189\n",
            "Validation score: 0.669803\n",
            "Iteration 6061, loss = 71608.08640392\n",
            "Validation score: 0.669869\n",
            "Iteration 6062, loss = 71589.82742861\n",
            "Validation score: 0.669947\n",
            "Iteration 6063, loss = 71569.44161204\n",
            "Validation score: 0.670011\n",
            "Iteration 6064, loss = 71549.75158102\n",
            "Validation score: 0.670061\n",
            "Iteration 6065, loss = 71533.48195280\n",
            "Validation score: 0.670117\n",
            "Iteration 6066, loss = 71510.32139798\n",
            "Validation score: 0.670180\n",
            "Iteration 6067, loss = 71491.43362273\n",
            "Validation score: 0.670250\n",
            "Iteration 6068, loss = 71474.44027197\n",
            "Validation score: 0.670310\n",
            "Iteration 6069, loss = 71451.09111245\n",
            "Validation score: 0.670391\n",
            "Iteration 6070, loss = 71432.72551765\n",
            "Validation score: 0.670489\n",
            "Iteration 6071, loss = 71413.56358207\n",
            "Validation score: 0.670601\n",
            "Iteration 6072, loss = 71395.05584242\n",
            "Validation score: 0.670704\n",
            "Iteration 6073, loss = 71374.72978210\n",
            "Validation score: 0.670792\n",
            "Iteration 6074, loss = 71354.30683103\n",
            "Validation score: 0.670874\n",
            "Iteration 6075, loss = 71332.84010794\n",
            "Validation score: 0.670968\n",
            "Iteration 6076, loss = 71312.02967519\n",
            "Validation score: 0.671064\n",
            "Iteration 6077, loss = 71292.00702671\n",
            "Validation score: 0.671164\n",
            "Iteration 6078, loss = 71269.83171173\n",
            "Validation score: 0.671250\n",
            "Iteration 6079, loss = 71249.28756130\n",
            "Validation score: 0.671329\n",
            "Iteration 6080, loss = 71228.45511526\n",
            "Validation score: 0.671414\n",
            "Iteration 6081, loss = 71208.31070328\n",
            "Validation score: 0.671518\n",
            "Iteration 6082, loss = 71185.66566019\n",
            "Validation score: 0.671602\n",
            "Iteration 6083, loss = 71166.33302946\n",
            "Validation score: 0.671684\n",
            "Iteration 6084, loss = 71146.29903647\n",
            "Validation score: 0.671779\n",
            "Iteration 6085, loss = 71124.87561646\n",
            "Validation score: 0.671868\n",
            "Iteration 6086, loss = 71103.91484629\n",
            "Validation score: 0.671965\n",
            "Iteration 6087, loss = 71085.48276618\n",
            "Validation score: 0.672065\n",
            "Iteration 6088, loss = 71064.97682507\n",
            "Validation score: 0.672152\n",
            "Iteration 6089, loss = 71047.12030403\n",
            "Validation score: 0.672240\n",
            "Iteration 6090, loss = 71025.77202412\n",
            "Validation score: 0.672327\n",
            "Iteration 6091, loss = 71006.45872426\n",
            "Validation score: 0.672424\n",
            "Iteration 6092, loss = 70988.29990796\n",
            "Validation score: 0.672534\n",
            "Iteration 6093, loss = 70967.53830791\n",
            "Validation score: 0.672626\n",
            "Iteration 6094, loss = 70948.98210157\n",
            "Validation score: 0.672705\n",
            "Iteration 6095, loss = 70929.44656204\n",
            "Validation score: 0.672792\n",
            "Iteration 6096, loss = 70908.84799122\n",
            "Validation score: 0.672874\n",
            "Iteration 6097, loss = 70890.51724330\n",
            "Validation score: 0.672943\n",
            "Iteration 6098, loss = 70871.15429017\n",
            "Validation score: 0.673021\n",
            "Iteration 6099, loss = 70850.03785831\n",
            "Validation score: 0.673111\n",
            "Iteration 6100, loss = 70831.00214400\n",
            "Validation score: 0.673189\n",
            "Iteration 6101, loss = 70810.45527501\n",
            "Validation score: 0.673245\n",
            "Iteration 6102, loss = 70791.62132799\n",
            "Validation score: 0.673311\n",
            "Iteration 6103, loss = 70771.02556593\n",
            "Validation score: 0.673385\n",
            "Iteration 6104, loss = 70750.64003949\n",
            "Validation score: 0.673477\n",
            "Iteration 6105, loss = 70728.99990094\n",
            "Validation score: 0.673597\n",
            "Iteration 6106, loss = 70709.56329142\n",
            "Validation score: 0.673712\n",
            "Iteration 6107, loss = 70690.34240688\n",
            "Validation score: 0.673815\n",
            "Iteration 6108, loss = 70668.90826981\n",
            "Validation score: 0.673900\n",
            "Iteration 6109, loss = 70650.38039829\n",
            "Validation score: 0.673979\n",
            "Iteration 6110, loss = 70627.28013868\n",
            "Validation score: 0.674040\n",
            "Iteration 6111, loss = 70605.91754788\n",
            "Validation score: 0.674111\n",
            "Iteration 6112, loss = 70586.91763104\n",
            "Validation score: 0.674191\n",
            "Iteration 6113, loss = 70564.41629453\n",
            "Validation score: 0.674294\n",
            "Iteration 6114, loss = 70542.13330544\n",
            "Validation score: 0.674398\n",
            "Iteration 6115, loss = 70522.21048723\n",
            "Validation score: 0.674492\n",
            "Iteration 6116, loss = 70502.00111792\n",
            "Validation score: 0.674596\n",
            "Iteration 6117, loss = 70482.74984765\n",
            "Validation score: 0.674688\n",
            "Iteration 6118, loss = 70460.81159698\n",
            "Validation score: 0.674775\n",
            "Iteration 6119, loss = 70443.40789564\n",
            "Validation score: 0.674872\n",
            "Iteration 6120, loss = 70420.57648211\n",
            "Validation score: 0.674964\n",
            "Iteration 6121, loss = 70401.12856678\n",
            "Validation score: 0.675075\n",
            "Iteration 6122, loss = 70381.66773425\n",
            "Validation score: 0.675180\n",
            "Iteration 6123, loss = 70362.41803569\n",
            "Validation score: 0.675267\n",
            "Iteration 6124, loss = 70342.53410680\n",
            "Validation score: 0.675343\n",
            "Iteration 6125, loss = 70322.85200517\n",
            "Validation score: 0.675406\n",
            "Iteration 6126, loss = 70301.90867185\n",
            "Validation score: 0.675496\n",
            "Iteration 6127, loss = 70282.03338177\n",
            "Validation score: 0.675593\n",
            "Iteration 6128, loss = 70262.31220194\n",
            "Validation score: 0.675679\n",
            "Iteration 6129, loss = 70242.64252543\n",
            "Validation score: 0.675775\n",
            "Iteration 6130, loss = 70223.74817797\n",
            "Validation score: 0.675869\n",
            "Iteration 6131, loss = 70202.67452753\n",
            "Validation score: 0.675943\n",
            "Iteration 6132, loss = 70184.07144526\n",
            "Validation score: 0.676032\n",
            "Iteration 6133, loss = 70163.35655589\n",
            "Validation score: 0.676126\n",
            "Iteration 6134, loss = 70143.59643754\n",
            "Validation score: 0.676223\n",
            "Iteration 6135, loss = 70124.01477246\n",
            "Validation score: 0.676312\n",
            "Iteration 6136, loss = 70102.65858852\n",
            "Validation score: 0.676400\n",
            "Iteration 6137, loss = 70082.24790231\n",
            "Validation score: 0.676503\n",
            "Iteration 6138, loss = 70061.23128561\n",
            "Validation score: 0.676610\n",
            "Iteration 6139, loss = 70042.00147157\n",
            "Validation score: 0.676721\n",
            "Iteration 6140, loss = 70020.78447629\n",
            "Validation score: 0.676822\n",
            "Iteration 6141, loss = 69999.93732970\n",
            "Validation score: 0.676926\n",
            "Iteration 6142, loss = 69980.26206989\n",
            "Validation score: 0.677023\n",
            "Iteration 6143, loss = 69960.46252349\n",
            "Validation score: 0.677110\n",
            "Iteration 6144, loss = 69941.85222651\n",
            "Validation score: 0.677183\n",
            "Iteration 6145, loss = 69923.29192322\n",
            "Validation score: 0.677251\n",
            "Iteration 6146, loss = 69901.62304863\n",
            "Validation score: 0.677328\n",
            "Iteration 6147, loss = 69883.20411722\n",
            "Validation score: 0.677406\n",
            "Iteration 6148, loss = 69863.49329892\n",
            "Validation score: 0.677495\n",
            "Iteration 6149, loss = 69846.51668632\n",
            "Validation score: 0.677580\n",
            "Iteration 6150, loss = 69827.31761720\n",
            "Validation score: 0.677659\n",
            "Iteration 6151, loss = 69808.11864476\n",
            "Validation score: 0.677720\n",
            "Iteration 6152, loss = 69787.64120254\n",
            "Validation score: 0.677785\n",
            "Iteration 6153, loss = 69767.36067605\n",
            "Validation score: 0.677852\n",
            "Iteration 6154, loss = 69749.29889875\n",
            "Validation score: 0.677923\n",
            "Iteration 6155, loss = 69729.80446973\n",
            "Validation score: 0.677993\n",
            "Iteration 6156, loss = 69710.87472871\n",
            "Validation score: 0.678069\n",
            "Iteration 6157, loss = 69690.75535798\n",
            "Validation score: 0.678149\n",
            "Iteration 6158, loss = 69669.98833065\n",
            "Validation score: 0.678224\n",
            "Iteration 6159, loss = 69651.81395609\n",
            "Validation score: 0.678300\n",
            "Iteration 6160, loss = 69631.57288270\n",
            "Validation score: 0.678369\n",
            "Iteration 6161, loss = 69610.79424787\n",
            "Validation score: 0.678410\n",
            "Iteration 6162, loss = 69590.45339108\n",
            "Validation score: 0.678465\n",
            "Iteration 6163, loss = 69571.59200667\n",
            "Validation score: 0.678519\n",
            "Iteration 6164, loss = 69550.95533059\n",
            "Validation score: 0.678581\n",
            "Iteration 6165, loss = 69531.99378031\n",
            "Validation score: 0.678645\n",
            "Iteration 6166, loss = 69512.52921779\n",
            "Validation score: 0.678713\n",
            "Iteration 6167, loss = 69493.42639268\n",
            "Validation score: 0.678790\n",
            "Iteration 6168, loss = 69474.63034959\n",
            "Validation score: 0.678868\n",
            "Iteration 6169, loss = 69454.50405304\n",
            "Validation score: 0.678948\n",
            "Iteration 6170, loss = 69437.28364375\n",
            "Validation score: 0.679039\n",
            "Iteration 6171, loss = 69417.34888474\n",
            "Validation score: 0.679135\n",
            "Iteration 6172, loss = 69398.81989062\n",
            "Validation score: 0.679220\n",
            "Iteration 6173, loss = 69380.36966104\n",
            "Validation score: 0.679296\n",
            "Iteration 6174, loss = 69361.02082676\n",
            "Validation score: 0.679366\n",
            "Iteration 6175, loss = 69343.97451907\n",
            "Validation score: 0.679445\n",
            "Iteration 6176, loss = 69323.24772850\n",
            "Validation score: 0.679492\n",
            "Iteration 6177, loss = 69304.63617123\n",
            "Validation score: 0.679529\n",
            "Iteration 6178, loss = 69286.53434798\n",
            "Validation score: 0.679570\n",
            "Iteration 6179, loss = 69266.85573926\n",
            "Validation score: 0.679620\n",
            "Iteration 6180, loss = 69249.81685593\n",
            "Validation score: 0.679674\n",
            "Iteration 6181, loss = 69229.11661576\n",
            "Validation score: 0.679755\n",
            "Iteration 6182, loss = 69211.50322876\n",
            "Validation score: 0.679847\n",
            "Iteration 6183, loss = 69191.27585256\n",
            "Validation score: 0.679925\n",
            "Iteration 6184, loss = 69173.90943886\n",
            "Validation score: 0.680001\n",
            "Iteration 6185, loss = 69153.31433907\n",
            "Validation score: 0.680071\n",
            "Iteration 6186, loss = 69134.65898995\n",
            "Validation score: 0.680155\n",
            "Iteration 6187, loss = 69114.98472476\n",
            "Validation score: 0.680239\n",
            "Iteration 6188, loss = 69094.39002992\n",
            "Validation score: 0.680328\n",
            "Iteration 6189, loss = 69076.71288251\n",
            "Validation score: 0.680417\n",
            "Iteration 6190, loss = 69057.57535830\n",
            "Validation score: 0.680490\n",
            "Iteration 6191, loss = 69037.40617311\n",
            "Validation score: 0.680572\n",
            "Iteration 6192, loss = 69020.37958913\n",
            "Validation score: 0.680643\n",
            "Iteration 6193, loss = 69001.84698949\n",
            "Validation score: 0.680717\n",
            "Iteration 6194, loss = 68984.47400906\n",
            "Validation score: 0.680788\n",
            "Iteration 6195, loss = 68964.81318124\n",
            "Validation score: 0.680872\n",
            "Iteration 6196, loss = 68945.09555085\n",
            "Validation score: 0.680962\n",
            "Iteration 6197, loss = 68926.30032675\n",
            "Validation score: 0.681067\n",
            "Iteration 6198, loss = 68907.14555817\n",
            "Validation score: 0.681168\n",
            "Iteration 6199, loss = 68886.02485450\n",
            "Validation score: 0.681250\n",
            "Iteration 6200, loss = 68868.00414524\n",
            "Validation score: 0.681351\n",
            "Iteration 6201, loss = 68848.20969800\n",
            "Validation score: 0.681429\n",
            "Iteration 6202, loss = 68827.78656558\n",
            "Validation score: 0.681519\n",
            "Iteration 6203, loss = 68806.42018033\n",
            "Validation score: 0.681604\n",
            "Iteration 6204, loss = 68786.60052051\n",
            "Validation score: 0.681712\n",
            "Iteration 6205, loss = 68768.76032020\n",
            "Validation score: 0.681826\n",
            "Iteration 6206, loss = 68749.44428382\n",
            "Validation score: 0.681921\n",
            "Iteration 6207, loss = 68727.24456323\n",
            "Validation score: 0.681993\n",
            "Iteration 6208, loss = 68709.11594959\n",
            "Validation score: 0.682066\n",
            "Iteration 6209, loss = 68696.75264292\n",
            "Validation score: 0.682129\n",
            "Iteration 6210, loss = 68671.26462144\n",
            "Validation score: 0.682217\n",
            "Iteration 6211, loss = 68652.31526483\n",
            "Validation score: 0.682316\n",
            "Iteration 6212, loss = 68631.61666172\n",
            "Validation score: 0.682407\n",
            "Iteration 6213, loss = 68613.59621003\n",
            "Validation score: 0.682489\n",
            "Iteration 6214, loss = 68592.15615769\n",
            "Validation score: 0.682583\n",
            "Iteration 6215, loss = 68575.47373829\n",
            "Validation score: 0.682682\n",
            "Iteration 6216, loss = 68552.52130830\n",
            "Validation score: 0.682757\n",
            "Iteration 6217, loss = 68533.39181846\n",
            "Validation score: 0.682846\n",
            "Iteration 6218, loss = 68514.72564213\n",
            "Validation score: 0.682947\n",
            "Iteration 6219, loss = 68496.20687327\n",
            "Validation score: 0.683048\n",
            "Iteration 6220, loss = 68477.18907036\n",
            "Validation score: 0.683131\n",
            "Iteration 6221, loss = 68461.17351788\n",
            "Validation score: 0.683215\n",
            "Iteration 6222, loss = 68442.84238102\n",
            "Validation score: 0.683286\n",
            "Iteration 6223, loss = 68423.81334377\n",
            "Validation score: 0.683387\n",
            "Iteration 6224, loss = 68406.62664732\n",
            "Validation score: 0.683494\n",
            "Iteration 6225, loss = 68386.37981747\n",
            "Validation score: 0.683580\n",
            "Iteration 6226, loss = 68368.58443520\n",
            "Validation score: 0.683666\n",
            "Iteration 6227, loss = 68348.75073067\n",
            "Validation score: 0.683740\n",
            "Iteration 6228, loss = 68333.23302099\n",
            "Validation score: 0.683799\n",
            "Iteration 6229, loss = 68312.20986012\n",
            "Validation score: 0.683880\n",
            "Iteration 6230, loss = 68293.95888343\n",
            "Validation score: 0.683953\n",
            "Iteration 6231, loss = 68277.08706972\n",
            "Validation score: 0.684018\n",
            "Iteration 6232, loss = 68255.77329930\n",
            "Validation score: 0.684105\n",
            "Iteration 6233, loss = 68237.69727679\n",
            "Validation score: 0.684188\n",
            "Iteration 6234, loss = 68219.29803191\n",
            "Validation score: 0.684252\n",
            "Iteration 6235, loss = 68204.06643544\n",
            "Validation score: 0.684319\n",
            "Iteration 6236, loss = 68181.54537974\n",
            "Validation score: 0.684402\n",
            "Iteration 6237, loss = 68161.90380549\n",
            "Validation score: 0.684471\n",
            "Iteration 6238, loss = 68143.29022097\n",
            "Validation score: 0.684548\n",
            "Iteration 6239, loss = 68125.04057770\n",
            "Validation score: 0.684616\n",
            "Iteration 6240, loss = 68106.94114400\n",
            "Validation score: 0.684699\n",
            "Iteration 6241, loss = 68088.25877467\n",
            "Validation score: 0.684766\n",
            "Iteration 6242, loss = 68065.09998181\n",
            "Validation score: 0.684818\n",
            "Iteration 6243, loss = 68050.56888778\n",
            "Validation score: 0.684869\n",
            "Iteration 6244, loss = 68030.81825073\n",
            "Validation score: 0.684938\n",
            "Iteration 6245, loss = 68010.03309680\n",
            "Validation score: 0.685006\n",
            "Iteration 6246, loss = 67991.37634660\n",
            "Validation score: 0.685079\n",
            "Iteration 6247, loss = 67972.39210637\n",
            "Validation score: 0.685154\n",
            "Iteration 6248, loss = 67954.30068475\n",
            "Validation score: 0.685244\n",
            "Iteration 6249, loss = 67937.60560542\n",
            "Validation score: 0.685349\n",
            "Iteration 6250, loss = 67915.18507769\n",
            "Validation score: 0.685439\n",
            "Iteration 6251, loss = 67897.25445609\n",
            "Validation score: 0.685523\n",
            "Iteration 6252, loss = 67878.55981466\n",
            "Validation score: 0.685600\n",
            "Iteration 6253, loss = 67859.53994476\n",
            "Validation score: 0.685662\n",
            "Iteration 6254, loss = 67840.27993703\n",
            "Validation score: 0.685719\n",
            "Iteration 6255, loss = 67822.50984042\n",
            "Validation score: 0.685785\n",
            "Iteration 6256, loss = 67803.36845075\n",
            "Validation score: 0.685881\n",
            "Iteration 6257, loss = 67783.20773996\n",
            "Validation score: 0.685973\n",
            "Iteration 6258, loss = 67763.72415097\n",
            "Validation score: 0.686064\n",
            "Iteration 6259, loss = 67746.09567713\n",
            "Validation score: 0.686165\n",
            "Iteration 6260, loss = 67728.34600865\n",
            "Validation score: 0.686279\n",
            "Iteration 6261, loss = 67708.68212062\n",
            "Validation score: 0.686380\n",
            "Iteration 6262, loss = 67690.36115176\n",
            "Validation score: 0.686466\n",
            "Iteration 6263, loss = 67673.07139015\n",
            "Validation score: 0.686557\n",
            "Iteration 6264, loss = 67654.85444376\n",
            "Validation score: 0.686656\n",
            "Iteration 6265, loss = 67634.78749952\n",
            "Validation score: 0.686733\n",
            "Iteration 6266, loss = 67616.55403145\n",
            "Validation score: 0.686828\n",
            "Iteration 6267, loss = 67599.58461767\n",
            "Validation score: 0.686933\n",
            "Iteration 6268, loss = 67579.41367160\n",
            "Validation score: 0.687018\n",
            "Iteration 6269, loss = 67557.62062142\n",
            "Validation score: 0.687092\n",
            "Iteration 6270, loss = 67540.27322039\n",
            "Validation score: 0.687184\n",
            "Iteration 6271, loss = 67520.58706182\n",
            "Validation score: 0.687270\n",
            "Iteration 6272, loss = 67501.02829579\n",
            "Validation score: 0.687355\n",
            "Iteration 6273, loss = 67483.20640543\n",
            "Validation score: 0.687448\n",
            "Iteration 6274, loss = 67464.29312709\n",
            "Validation score: 0.687532\n",
            "Iteration 6275, loss = 67446.76444920\n",
            "Validation score: 0.687608\n",
            "Iteration 6276, loss = 67426.25455176\n",
            "Validation score: 0.687683\n",
            "Iteration 6277, loss = 67408.29122178\n",
            "Validation score: 0.687751\n",
            "Iteration 6278, loss = 67389.53765761\n",
            "Validation score: 0.687813\n",
            "Iteration 6279, loss = 67368.67361064\n",
            "Validation score: 0.687870\n",
            "Iteration 6280, loss = 67350.54603988\n",
            "Validation score: 0.687910\n",
            "Iteration 6281, loss = 67333.05376871\n",
            "Validation score: 0.687951\n",
            "Iteration 6282, loss = 67315.33269988\n",
            "Validation score: 0.688009\n",
            "Iteration 6283, loss = 67293.76858685\n",
            "Validation score: 0.688090\n",
            "Iteration 6284, loss = 67274.23158056\n",
            "Validation score: 0.688178\n",
            "Iteration 6285, loss = 67255.40908903\n",
            "Validation score: 0.688279\n",
            "Iteration 6286, loss = 67236.94687323\n",
            "Validation score: 0.688388\n",
            "Iteration 6287, loss = 67218.52320873\n",
            "Validation score: 0.688469\n",
            "Iteration 6288, loss = 67198.72900675\n",
            "Validation score: 0.688546\n",
            "Iteration 6289, loss = 67181.61818510\n",
            "Validation score: 0.688619\n",
            "Iteration 6290, loss = 67161.64732772\n",
            "Validation score: 0.688693\n",
            "Iteration 6291, loss = 67143.97392435\n",
            "Validation score: 0.688773\n",
            "Iteration 6292, loss = 67124.77806685\n",
            "Validation score: 0.688863\n",
            "Iteration 6293, loss = 67108.10522114\n",
            "Validation score: 0.688961\n",
            "Iteration 6294, loss = 67088.60309197\n",
            "Validation score: 0.689051\n",
            "Iteration 6295, loss = 67070.21956938\n",
            "Validation score: 0.689144\n",
            "Iteration 6296, loss = 67051.74135803\n",
            "Validation score: 0.689224\n",
            "Iteration 6297, loss = 67031.84415971\n",
            "Validation score: 0.689298\n",
            "Iteration 6298, loss = 67014.85072049\n",
            "Validation score: 0.689380\n",
            "Iteration 6299, loss = 66995.07172178\n",
            "Validation score: 0.689450\n",
            "Iteration 6300, loss = 66975.42347490\n",
            "Validation score: 0.689499\n",
            "Iteration 6301, loss = 66956.71414201\n",
            "Validation score: 0.689539\n",
            "Iteration 6302, loss = 66945.32236745\n",
            "Validation score: 0.689579\n",
            "Iteration 6303, loss = 66923.47725831\n",
            "Validation score: 0.689649\n",
            "Iteration 6304, loss = 66906.80669814\n",
            "Validation score: 0.689722\n",
            "Iteration 6305, loss = 66888.70152681\n",
            "Validation score: 0.689798\n",
            "Iteration 6306, loss = 66870.91176505\n",
            "Validation score: 0.689877\n",
            "Iteration 6307, loss = 66852.12892241\n",
            "Validation score: 0.689963\n",
            "Iteration 6308, loss = 66838.12020046\n",
            "Validation score: 0.690048\n",
            "Iteration 6309, loss = 66817.37207411\n",
            "Validation score: 0.690128\n",
            "Iteration 6310, loss = 66799.70998848\n",
            "Validation score: 0.690185\n",
            "Iteration 6311, loss = 66782.50141333\n",
            "Validation score: 0.690239\n",
            "Iteration 6312, loss = 66765.04131687\n",
            "Validation score: 0.690301\n",
            "Iteration 6313, loss = 66746.75029547\n",
            "Validation score: 0.690379\n",
            "Iteration 6314, loss = 66726.75041858\n",
            "Validation score: 0.690473\n",
            "Iteration 6315, loss = 66709.43844432\n",
            "Validation score: 0.690579\n",
            "Iteration 6316, loss = 66690.75994328\n",
            "Validation score: 0.690672\n",
            "Iteration 6317, loss = 66670.38271179\n",
            "Validation score: 0.690768\n",
            "Iteration 6318, loss = 66653.02696901\n",
            "Validation score: 0.690855\n",
            "Iteration 6319, loss = 66632.59610083\n",
            "Validation score: 0.690956\n",
            "Iteration 6320, loss = 66614.55443525\n",
            "Validation score: 0.691063\n",
            "Iteration 6321, loss = 66596.27173787\n",
            "Validation score: 0.691151\n",
            "Iteration 6322, loss = 66576.38826417\n",
            "Validation score: 0.691250\n",
            "Iteration 6323, loss = 66559.84689512\n",
            "Validation score: 0.691337\n",
            "Iteration 6324, loss = 66539.42549916\n",
            "Validation score: 0.691416\n",
            "Iteration 6325, loss = 66521.74618566\n",
            "Validation score: 0.691514\n",
            "Iteration 6326, loss = 66501.98028119\n",
            "Validation score: 0.691605\n",
            "Iteration 6327, loss = 66482.56842478\n",
            "Validation score: 0.691689\n",
            "Iteration 6328, loss = 66463.71723655\n",
            "Validation score: 0.691762\n",
            "Iteration 6329, loss = 66444.70399213\n",
            "Validation score: 0.691838\n",
            "Iteration 6330, loss = 66425.83749371\n",
            "Validation score: 0.691926\n",
            "Iteration 6331, loss = 66408.45946587\n",
            "Validation score: 0.692010\n",
            "Iteration 6332, loss = 66389.16404213\n",
            "Validation score: 0.692093\n",
            "Iteration 6333, loss = 66369.52392514\n",
            "Validation score: 0.692180\n",
            "Iteration 6334, loss = 66351.55460220\n",
            "Validation score: 0.692271\n",
            "Iteration 6335, loss = 66336.22680055\n",
            "Validation score: 0.692358\n",
            "Iteration 6336, loss = 66314.84707347\n",
            "Validation score: 0.692434\n",
            "Iteration 6337, loss = 66297.02715937\n",
            "Validation score: 0.692503\n",
            "Iteration 6338, loss = 66280.39322633\n",
            "Validation score: 0.692575\n",
            "Iteration 6339, loss = 66259.32895173\n",
            "Validation score: 0.692644\n",
            "Iteration 6340, loss = 66242.85544256\n",
            "Validation score: 0.692715\n",
            "Iteration 6341, loss = 66223.51776862\n",
            "Validation score: 0.692785\n",
            "Iteration 6342, loss = 66205.83229951\n",
            "Validation score: 0.692853\n",
            "Iteration 6343, loss = 66186.61391075\n",
            "Validation score: 0.692941\n",
            "Iteration 6344, loss = 66169.10948482\n",
            "Validation score: 0.693055\n",
            "Iteration 6345, loss = 66155.31336710\n",
            "Validation score: 0.693180\n",
            "Iteration 6346, loss = 66137.31132552\n",
            "Validation score: 0.693280\n",
            "Iteration 6347, loss = 66118.03100894\n",
            "Validation score: 0.693349\n",
            "Iteration 6348, loss = 66098.93083758\n",
            "Validation score: 0.693406\n",
            "Iteration 6349, loss = 66080.52992910\n",
            "Validation score: 0.693443\n",
            "Iteration 6350, loss = 66064.44058759\n",
            "Validation score: 0.693488\n",
            "Iteration 6351, loss = 66049.19459296\n",
            "Validation score: 0.693543\n",
            "Iteration 6352, loss = 66028.64901170\n",
            "Validation score: 0.693604\n",
            "Iteration 6353, loss = 66012.38790649\n",
            "Validation score: 0.693668\n",
            "Iteration 6354, loss = 65994.15172830\n",
            "Validation score: 0.693728\n",
            "Iteration 6355, loss = 65978.26850850\n",
            "Validation score: 0.693798\n",
            "Iteration 6356, loss = 65959.61174260\n",
            "Validation score: 0.693864\n",
            "Iteration 6357, loss = 65940.50475918\n",
            "Validation score: 0.693940\n",
            "Iteration 6358, loss = 65923.74045640\n",
            "Validation score: 0.694022\n",
            "Iteration 6359, loss = 65904.92735431\n",
            "Validation score: 0.694102\n",
            "Iteration 6360, loss = 65886.56130992\n",
            "Validation score: 0.694175\n",
            "Iteration 6361, loss = 65869.71083093\n",
            "Validation score: 0.694263\n",
            "Iteration 6362, loss = 65851.29976658\n",
            "Validation score: 0.694368\n",
            "Iteration 6363, loss = 65834.24052874\n",
            "Validation score: 0.694468\n",
            "Iteration 6364, loss = 65817.56018053\n",
            "Validation score: 0.694563\n",
            "Iteration 6365, loss = 65801.06517322\n",
            "Validation score: 0.694644\n",
            "Iteration 6366, loss = 65782.20063779\n",
            "Validation score: 0.694703\n",
            "Iteration 6367, loss = 65764.65301652\n",
            "Validation score: 0.694752\n",
            "Iteration 6368, loss = 65746.42486084\n",
            "Validation score: 0.694804\n",
            "Iteration 6369, loss = 65729.15132816\n",
            "Validation score: 0.694870\n",
            "Iteration 6370, loss = 65711.53435938\n",
            "Validation score: 0.694944\n",
            "Iteration 6371, loss = 65692.29140574\n",
            "Validation score: 0.695022\n",
            "Iteration 6372, loss = 65673.62162272\n",
            "Validation score: 0.695118\n",
            "Iteration 6373, loss = 65655.29476053\n",
            "Validation score: 0.695208\n",
            "Iteration 6374, loss = 65636.49491059\n",
            "Validation score: 0.695287\n",
            "Iteration 6375, loss = 65621.43230219\n",
            "Validation score: 0.695357\n",
            "Iteration 6376, loss = 65601.72643147\n",
            "Validation score: 0.695442\n",
            "Iteration 6377, loss = 65585.02541400\n",
            "Validation score: 0.695529\n",
            "Iteration 6378, loss = 65567.35587076\n",
            "Validation score: 0.695616\n",
            "Iteration 6379, loss = 65553.24931353\n",
            "Validation score: 0.695705\n",
            "Iteration 6380, loss = 65531.55531171\n",
            "Validation score: 0.695797\n",
            "Iteration 6381, loss = 65515.15933196\n",
            "Validation score: 0.695884\n",
            "Iteration 6382, loss = 65496.52571895\n",
            "Validation score: 0.695952\n",
            "Iteration 6383, loss = 65478.95797059\n",
            "Validation score: 0.696014\n",
            "Iteration 6384, loss = 65462.75735499\n",
            "Validation score: 0.696079\n",
            "Iteration 6385, loss = 65443.82770316\n",
            "Validation score: 0.696147\n",
            "Iteration 6386, loss = 65425.54589824\n",
            "Validation score: 0.696220\n",
            "Iteration 6387, loss = 65410.37097624\n",
            "Validation score: 0.696288\n",
            "Iteration 6388, loss = 65389.54178149\n",
            "Validation score: 0.696367\n",
            "Iteration 6389, loss = 65372.45278483\n",
            "Validation score: 0.696450\n",
            "Iteration 6390, loss = 65357.51059259\n",
            "Validation score: 0.696533\n",
            "Iteration 6391, loss = 65337.32293712\n",
            "Validation score: 0.696618\n",
            "Iteration 6392, loss = 65320.98194371\n",
            "Validation score: 0.696689\n",
            "Iteration 6393, loss = 65304.10252742\n",
            "Validation score: 0.696768\n",
            "Iteration 6394, loss = 65285.09824020\n",
            "Validation score: 0.696843\n",
            "Iteration 6395, loss = 65269.94186254\n",
            "Validation score: 0.696938\n",
            "Iteration 6396, loss = 65250.03522533\n",
            "Validation score: 0.697031\n",
            "Iteration 6397, loss = 65231.93057071\n",
            "Validation score: 0.697124\n",
            "Iteration 6398, loss = 65212.95086069\n",
            "Validation score: 0.697209\n",
            "Iteration 6399, loss = 65194.50457933\n",
            "Validation score: 0.697294\n",
            "Iteration 6400, loss = 65175.43471708\n",
            "Validation score: 0.697387\n",
            "Iteration 6401, loss = 65157.22987930\n",
            "Validation score: 0.697478\n",
            "Iteration 6402, loss = 65138.36852175\n",
            "Validation score: 0.697562\n",
            "Iteration 6403, loss = 65119.64865766\n",
            "Validation score: 0.697628\n",
            "Iteration 6404, loss = 65103.63662486\n",
            "Validation score: 0.697705\n",
            "Iteration 6405, loss = 65086.34227320\n",
            "Validation score: 0.697788\n",
            "Iteration 6406, loss = 65070.08150010\n",
            "Validation score: 0.697880\n",
            "Iteration 6407, loss = 65050.15015217\n",
            "Validation score: 0.697991\n",
            "Iteration 6408, loss = 65035.46186867\n",
            "Validation score: 0.698106\n",
            "Iteration 6409, loss = 65017.91981216\n",
            "Validation score: 0.698185\n",
            "Iteration 6410, loss = 65000.87389071\n",
            "Validation score: 0.698241\n",
            "Iteration 6411, loss = 64982.90453476\n",
            "Validation score: 0.698278\n",
            "Iteration 6412, loss = 64965.58549052\n",
            "Validation score: 0.698326\n",
            "Iteration 6413, loss = 64949.50749596\n",
            "Validation score: 0.698366\n",
            "Iteration 6414, loss = 64932.22345078\n",
            "Validation score: 0.698427\n",
            "Iteration 6415, loss = 64914.89029305\n",
            "Validation score: 0.698503\n",
            "Iteration 6416, loss = 64899.17559926\n",
            "Validation score: 0.698587\n",
            "Iteration 6417, loss = 64882.12964288\n",
            "Validation score: 0.698662\n",
            "Iteration 6418, loss = 64865.40319351\n",
            "Validation score: 0.698716\n",
            "Iteration 6419, loss = 64849.27078231\n",
            "Validation score: 0.698767\n",
            "Iteration 6420, loss = 64831.47845630\n",
            "Validation score: 0.698837\n",
            "Iteration 6421, loss = 64813.33991918\n",
            "Validation score: 0.698905\n",
            "Iteration 6422, loss = 64797.67329014\n",
            "Validation score: 0.698958\n",
            "Iteration 6423, loss = 64779.52166097\n",
            "Validation score: 0.699016\n",
            "Iteration 6424, loss = 64760.19884153\n",
            "Validation score: 0.699094\n",
            "Iteration 6425, loss = 64743.12415515\n",
            "Validation score: 0.699159\n",
            "Iteration 6426, loss = 64722.31510098\n",
            "Validation score: 0.699249\n",
            "Iteration 6427, loss = 64704.83999599\n",
            "Validation score: 0.699340\n",
            "Iteration 6428, loss = 64690.70631877\n",
            "Validation score: 0.699427\n",
            "Iteration 6429, loss = 64674.20174997\n",
            "Validation score: 0.699503\n",
            "Iteration 6430, loss = 64656.44432988\n",
            "Validation score: 0.699583\n",
            "Iteration 6431, loss = 64640.31938854\n",
            "Validation score: 0.699672\n",
            "Iteration 6432, loss = 64623.95020534\n",
            "Validation score: 0.699758\n",
            "Iteration 6433, loss = 64608.59897037\n",
            "Validation score: 0.699840\n",
            "Iteration 6434, loss = 64590.69838273\n",
            "Validation score: 0.699894\n",
            "Iteration 6435, loss = 64574.40269990\n",
            "Validation score: 0.699944\n",
            "Iteration 6436, loss = 64559.58525406\n",
            "Validation score: 0.700005\n",
            "Iteration 6437, loss = 64543.24489817\n",
            "Validation score: 0.700087\n",
            "Iteration 6438, loss = 64524.10756691\n",
            "Validation score: 0.700157\n",
            "Iteration 6439, loss = 64510.41207806\n",
            "Validation score: 0.700226\n",
            "Iteration 6440, loss = 64491.05338324\n",
            "Validation score: 0.700295\n",
            "Iteration 6441, loss = 64475.64502609\n",
            "Validation score: 0.700367\n",
            "Iteration 6442, loss = 64456.74098621\n",
            "Validation score: 0.700449\n",
            "Iteration 6443, loss = 64440.92618904\n",
            "Validation score: 0.700533\n",
            "Iteration 6444, loss = 64422.60821650\n",
            "Validation score: 0.700621\n",
            "Iteration 6445, loss = 64408.63290603\n",
            "Validation score: 0.700707\n",
            "Iteration 6446, loss = 64389.79874720\n",
            "Validation score: 0.700784\n",
            "Iteration 6447, loss = 64372.52415166\n",
            "Validation score: 0.700871\n",
            "Iteration 6448, loss = 64356.37363361\n",
            "Validation score: 0.700960\n",
            "Iteration 6449, loss = 64339.83933274\n",
            "Validation score: 0.701024\n",
            "Iteration 6450, loss = 64320.96744462\n",
            "Validation score: 0.701071\n",
            "Iteration 6451, loss = 64305.91987007\n",
            "Validation score: 0.701132\n",
            "Iteration 6452, loss = 64288.51204155\n",
            "Validation score: 0.701188\n",
            "Iteration 6453, loss = 64273.26656696\n",
            "Validation score: 0.701245\n",
            "Iteration 6454, loss = 64258.14059238\n",
            "Validation score: 0.701297\n",
            "Iteration 6455, loss = 64238.77319122\n",
            "Validation score: 0.701344\n",
            "Iteration 6456, loss = 64223.91499470\n",
            "Validation score: 0.701382\n",
            "Iteration 6457, loss = 64207.61133844\n",
            "Validation score: 0.701439\n",
            "Iteration 6458, loss = 64190.19561516\n",
            "Validation score: 0.701515\n",
            "Iteration 6459, loss = 64173.35872653\n",
            "Validation score: 0.701600\n",
            "Iteration 6460, loss = 64155.37595278\n",
            "Validation score: 0.701701\n",
            "Iteration 6461, loss = 64137.90679907\n",
            "Validation score: 0.701816\n",
            "Iteration 6462, loss = 64120.16122516\n",
            "Validation score: 0.701923\n",
            "Iteration 6463, loss = 64102.02262985\n",
            "Validation score: 0.702020\n",
            "Iteration 6464, loss = 64084.69423404\n",
            "Validation score: 0.702109\n",
            "Iteration 6465, loss = 64067.97324772\n",
            "Validation score: 0.702190\n",
            "Iteration 6466, loss = 64052.47313567\n",
            "Validation score: 0.702273\n",
            "Iteration 6467, loss = 64033.86050932\n",
            "Validation score: 0.702340\n",
            "Iteration 6468, loss = 64017.27127289\n",
            "Validation score: 0.702408\n",
            "Iteration 6469, loss = 64000.90063847\n",
            "Validation score: 0.702484\n",
            "Iteration 6470, loss = 63982.31376102\n",
            "Validation score: 0.702552\n",
            "Iteration 6471, loss = 63966.10382084\n",
            "Validation score: 0.702635\n",
            "Iteration 6472, loss = 63950.49290742\n",
            "Validation score: 0.702727\n",
            "Iteration 6473, loss = 63929.80709521\n",
            "Validation score: 0.702799\n",
            "Iteration 6474, loss = 63911.79786978\n",
            "Validation score: 0.702864\n",
            "Iteration 6475, loss = 63896.14929578\n",
            "Validation score: 0.702945\n",
            "Iteration 6476, loss = 63878.94114897\n",
            "Validation score: 0.703036\n",
            "Iteration 6477, loss = 63859.64993111\n",
            "Validation score: 0.703121\n",
            "Iteration 6478, loss = 63841.85725267\n",
            "Validation score: 0.703200\n",
            "Iteration 6479, loss = 63824.50012778\n",
            "Validation score: 0.703277\n",
            "Iteration 6480, loss = 63807.33809786\n",
            "Validation score: 0.703349\n",
            "Iteration 6481, loss = 63792.55966211\n",
            "Validation score: 0.703428\n",
            "Iteration 6482, loss = 63773.58149129\n",
            "Validation score: 0.703482\n",
            "Iteration 6483, loss = 63757.74289834\n",
            "Validation score: 0.703532\n",
            "Iteration 6484, loss = 63738.25901330\n",
            "Validation score: 0.703579\n",
            "Iteration 6485, loss = 63722.50748937\n",
            "Validation score: 0.703634\n",
            "Iteration 6486, loss = 63704.26195211\n",
            "Validation score: 0.703682\n",
            "Iteration 6487, loss = 63689.13261473\n",
            "Validation score: 0.703730\n",
            "Iteration 6488, loss = 63672.56135361\n",
            "Validation score: 0.703782\n",
            "Iteration 6489, loss = 63657.21662228\n",
            "Validation score: 0.703816\n",
            "Iteration 6490, loss = 63639.50672029\n",
            "Validation score: 0.703861\n",
            "Iteration 6491, loss = 63625.12393269\n",
            "Validation score: 0.703916\n",
            "Iteration 6492, loss = 63609.28860098\n",
            "Validation score: 0.703988\n",
            "Iteration 6493, loss = 63592.27077353\n",
            "Validation score: 0.704052\n",
            "Iteration 6494, loss = 63576.88722730\n",
            "Validation score: 0.704114\n",
            "Iteration 6495, loss = 63562.66601766\n",
            "Validation score: 0.704172\n",
            "Iteration 6496, loss = 63548.51972448\n",
            "Validation score: 0.704231\n",
            "Iteration 6497, loss = 63530.47631418\n",
            "Validation score: 0.704305\n",
            "Iteration 6498, loss = 63513.25137314\n",
            "Validation score: 0.704373\n",
            "Iteration 6499, loss = 63497.31677478\n",
            "Validation score: 0.704446\n",
            "Iteration 6500, loss = 63481.81555312\n",
            "Validation score: 0.704526\n",
            "Iteration 6501, loss = 63463.81457643\n",
            "Validation score: 0.704599\n",
            "Iteration 6502, loss = 63446.70142900\n",
            "Validation score: 0.704675\n",
            "Iteration 6503, loss = 63429.33957103\n",
            "Validation score: 0.704742\n",
            "Iteration 6504, loss = 63413.26910999\n",
            "Validation score: 0.704816\n",
            "Iteration 6505, loss = 63398.17810574\n",
            "Validation score: 0.704895\n",
            "Iteration 6506, loss = 63381.08008977\n",
            "Validation score: 0.704973\n",
            "Iteration 6507, loss = 63365.17348101\n",
            "Validation score: 0.705048\n",
            "Iteration 6508, loss = 63350.92375037\n",
            "Validation score: 0.705117\n",
            "Iteration 6509, loss = 63331.62887702\n",
            "Validation score: 0.705191\n",
            "Iteration 6510, loss = 63317.72739344\n",
            "Validation score: 0.705276\n",
            "Iteration 6511, loss = 63299.76879816\n",
            "Validation score: 0.705364\n",
            "Iteration 6512, loss = 63287.25227409\n",
            "Validation score: 0.705425\n",
            "Iteration 6513, loss = 63265.99788161\n",
            "Validation score: 0.705490\n",
            "Iteration 6514, loss = 63248.62525245\n",
            "Validation score: 0.705553\n",
            "Iteration 6515, loss = 63233.50401477\n",
            "Validation score: 0.705631\n",
            "Iteration 6516, loss = 63214.61089985\n",
            "Validation score: 0.705721\n",
            "Iteration 6517, loss = 63201.19207388\n",
            "Validation score: 0.705819\n",
            "Iteration 6518, loss = 63182.36250267\n",
            "Validation score: 0.705896\n",
            "Iteration 6519, loss = 63166.29342967\n",
            "Validation score: 0.705982\n",
            "Iteration 6520, loss = 63151.91732171\n",
            "Validation score: 0.706053\n",
            "Iteration 6521, loss = 63134.91971307\n",
            "Validation score: 0.706128\n",
            "Iteration 6522, loss = 63119.93692166\n",
            "Validation score: 0.706212\n",
            "Iteration 6523, loss = 63105.21475702\n",
            "Validation score: 0.706275\n",
            "Iteration 6524, loss = 63089.96783810\n",
            "Validation score: 0.706334\n",
            "Iteration 6525, loss = 63074.14935309\n",
            "Validation score: 0.706418\n",
            "Iteration 6526, loss = 63058.23625410\n",
            "Validation score: 0.706502\n",
            "Iteration 6527, loss = 63042.25894574\n",
            "Validation score: 0.706587\n",
            "Iteration 6528, loss = 63026.08085656\n",
            "Validation score: 0.706670\n",
            "Iteration 6529, loss = 63010.80423710\n",
            "Validation score: 0.706764\n",
            "Iteration 6530, loss = 62995.13149545\n",
            "Validation score: 0.706844\n",
            "Iteration 6531, loss = 62978.65599150\n",
            "Validation score: 0.706911\n",
            "Iteration 6532, loss = 62963.72515612\n",
            "Validation score: 0.706985\n",
            "Iteration 6533, loss = 62948.10498710\n",
            "Validation score: 0.707059\n",
            "Iteration 6534, loss = 62933.54907403\n",
            "Validation score: 0.707117\n",
            "Iteration 6535, loss = 62919.18780053\n",
            "Validation score: 0.707182\n",
            "Iteration 6536, loss = 62902.35262259\n",
            "Validation score: 0.707264\n",
            "Iteration 6537, loss = 62887.08080115\n",
            "Validation score: 0.707340\n",
            "Iteration 6538, loss = 62870.96194765\n",
            "Validation score: 0.707414\n",
            "Iteration 6539, loss = 62854.80512448\n",
            "Validation score: 0.707489\n",
            "Iteration 6540, loss = 62840.92793986\n",
            "Validation score: 0.707567\n",
            "Iteration 6541, loss = 62827.39891983\n",
            "Validation score: 0.707663\n",
            "Iteration 6542, loss = 62811.20015717\n",
            "Validation score: 0.707739\n",
            "Iteration 6543, loss = 62793.28963669\n",
            "Validation score: 0.707820\n",
            "Iteration 6544, loss = 62775.65215190\n",
            "Validation score: 0.707913\n",
            "Iteration 6545, loss = 62757.66072662\n",
            "Validation score: 0.708000\n",
            "Iteration 6546, loss = 62741.85000841\n",
            "Validation score: 0.708089\n",
            "Iteration 6547, loss = 62730.07009254\n",
            "Validation score: 0.708185\n",
            "Iteration 6548, loss = 62710.48892094\n",
            "Validation score: 0.708273\n",
            "Iteration 6549, loss = 62696.18154766\n",
            "Validation score: 0.708358\n",
            "Iteration 6550, loss = 62677.49586359\n",
            "Validation score: 0.708414\n",
            "Iteration 6551, loss = 62662.49949340\n",
            "Validation score: 0.708462\n",
            "Iteration 6552, loss = 62645.44919362\n",
            "Validation score: 0.708517\n",
            "Iteration 6553, loss = 62627.89417683\n",
            "Validation score: 0.708578\n",
            "Iteration 6554, loss = 62613.37309341\n",
            "Validation score: 0.708642\n",
            "Iteration 6555, loss = 62597.31320891\n",
            "Validation score: 0.708698\n",
            "Iteration 6556, loss = 62581.86365412\n",
            "Validation score: 0.708746\n",
            "Iteration 6557, loss = 62566.16285140\n",
            "Validation score: 0.708818\n",
            "Iteration 6558, loss = 62549.31505599\n",
            "Validation score: 0.708897\n",
            "Iteration 6559, loss = 62535.19814672\n",
            "Validation score: 0.708972\n",
            "Iteration 6560, loss = 62516.89950943\n",
            "Validation score: 0.709033\n",
            "Iteration 6561, loss = 62501.50447173\n",
            "Validation score: 0.709101\n",
            "Iteration 6562, loss = 62486.16342431\n",
            "Validation score: 0.709180\n",
            "Iteration 6563, loss = 62469.90678584\n",
            "Validation score: 0.709253\n",
            "Iteration 6564, loss = 62452.42650413\n",
            "Validation score: 0.709326\n",
            "Iteration 6565, loss = 62435.13587773\n",
            "Validation score: 0.709412\n",
            "Iteration 6566, loss = 62424.32474048\n",
            "Validation score: 0.709487\n",
            "Iteration 6567, loss = 62406.02275650\n",
            "Validation score: 0.709554\n",
            "Iteration 6568, loss = 62388.63122872\n",
            "Validation score: 0.709622\n",
            "Iteration 6569, loss = 62369.81082712\n",
            "Validation score: 0.709688\n",
            "Iteration 6570, loss = 62355.47666058\n",
            "Validation score: 0.709759\n",
            "Iteration 6571, loss = 62339.40625515\n",
            "Validation score: 0.709827\n",
            "Iteration 6572, loss = 62323.07371672\n",
            "Validation score: 0.709905\n",
            "Iteration 6573, loss = 62305.72184730\n",
            "Validation score: 0.709977\n",
            "Iteration 6574, loss = 62291.46807171\n",
            "Validation score: 0.710048\n",
            "Iteration 6575, loss = 62276.02457855\n",
            "Validation score: 0.710101\n",
            "Iteration 6576, loss = 62262.02202335\n",
            "Validation score: 0.710157\n",
            "Iteration 6577, loss = 62246.31648485\n",
            "Validation score: 0.710225\n",
            "Iteration 6578, loss = 62232.61320648\n",
            "Validation score: 0.710291\n",
            "Iteration 6579, loss = 62217.50711763\n",
            "Validation score: 0.710355\n",
            "Iteration 6580, loss = 62202.51202254\n",
            "Validation score: 0.710410\n",
            "Iteration 6581, loss = 62187.96393302\n",
            "Validation score: 0.710464\n",
            "Iteration 6582, loss = 62173.19142332\n",
            "Validation score: 0.710521\n",
            "Iteration 6583, loss = 62157.58648929\n",
            "Validation score: 0.710568\n",
            "Iteration 6584, loss = 62142.77897337\n",
            "Validation score: 0.710611\n",
            "Iteration 6585, loss = 62128.33474335\n",
            "Validation score: 0.710672\n",
            "Iteration 6586, loss = 62111.75377295\n",
            "Validation score: 0.710739\n",
            "Iteration 6587, loss = 62095.59329224\n",
            "Validation score: 0.710811\n",
            "Iteration 6588, loss = 62080.92670915\n",
            "Validation score: 0.710888\n",
            "Iteration 6589, loss = 62064.24152270\n",
            "Validation score: 0.710961\n",
            "Iteration 6590, loss = 62049.52560515\n",
            "Validation score: 0.711026\n",
            "Iteration 6591, loss = 62033.20896003\n",
            "Validation score: 0.711087\n",
            "Iteration 6592, loss = 62015.78793425\n",
            "Validation score: 0.711138\n",
            "Iteration 6593, loss = 62002.85148823\n",
            "Validation score: 0.711189\n",
            "Iteration 6594, loss = 61985.47047915\n",
            "Validation score: 0.711252\n",
            "Iteration 6595, loss = 61970.36092321\n",
            "Validation score: 0.711309\n",
            "Iteration 6596, loss = 61954.15579312\n",
            "Validation score: 0.711378\n",
            "Iteration 6597, loss = 61938.53703988\n",
            "Validation score: 0.711451\n",
            "Iteration 6598, loss = 61923.11394552\n",
            "Validation score: 0.711525\n",
            "Iteration 6599, loss = 61909.10228615\n",
            "Validation score: 0.711597\n",
            "Iteration 6600, loss = 61892.06477412\n",
            "Validation score: 0.711634\n",
            "Iteration 6601, loss = 61877.24630708\n",
            "Validation score: 0.711679\n",
            "Iteration 6602, loss = 61859.46246495\n",
            "Validation score: 0.711728\n",
            "Iteration 6603, loss = 61844.17483966\n",
            "Validation score: 0.711775\n",
            "Iteration 6604, loss = 61829.77648998\n",
            "Validation score: 0.711830\n",
            "Iteration 6605, loss = 61814.69246538\n",
            "Validation score: 0.711898\n",
            "Iteration 6606, loss = 61801.10997792\n",
            "Validation score: 0.711964\n",
            "Iteration 6607, loss = 61785.09864531\n",
            "Validation score: 0.712041\n",
            "Iteration 6608, loss = 61771.04406783\n",
            "Validation score: 0.712120\n",
            "Iteration 6609, loss = 61753.61069574\n",
            "Validation score: 0.712186\n",
            "Iteration 6610, loss = 61738.52404057\n",
            "Validation score: 0.712255\n",
            "Iteration 6611, loss = 61723.24111005\n",
            "Validation score: 0.712330\n",
            "Iteration 6612, loss = 61707.98607270\n",
            "Validation score: 0.712393\n",
            "Iteration 6613, loss = 61691.58872487\n",
            "Validation score: 0.712450\n",
            "Iteration 6614, loss = 61675.41878436\n",
            "Validation score: 0.712527\n",
            "Iteration 6615, loss = 61659.95382813\n",
            "Validation score: 0.712611\n",
            "Iteration 6616, loss = 61646.00835790\n",
            "Validation score: 0.712664\n",
            "Iteration 6617, loss = 61627.11984217\n",
            "Validation score: 0.712729\n",
            "Iteration 6618, loss = 61613.04819746\n",
            "Validation score: 0.712806\n",
            "Iteration 6619, loss = 61593.81831728\n",
            "Validation score: 0.712868\n",
            "Iteration 6620, loss = 61578.74011790\n",
            "Validation score: 0.712926\n",
            "Iteration 6621, loss = 61562.67932624\n",
            "Validation score: 0.712980\n",
            "Iteration 6622, loss = 61547.39638533\n",
            "Validation score: 0.713042\n",
            "Iteration 6623, loss = 61529.76175094\n",
            "Validation score: 0.713116\n",
            "Iteration 6624, loss = 61516.93644599\n",
            "Validation score: 0.713170\n",
            "Iteration 6625, loss = 61497.59851939\n",
            "Validation score: 0.713224\n",
            "Iteration 6626, loss = 61482.89449484\n",
            "Validation score: 0.713255\n",
            "Iteration 6627, loss = 61469.26607721\n",
            "Validation score: 0.713280\n",
            "Iteration 6628, loss = 61456.76831279\n",
            "Validation score: 0.713297\n",
            "Iteration 6629, loss = 61443.13530444\n",
            "Validation score: 0.713322\n",
            "Iteration 6630, loss = 61427.89302311\n",
            "Validation score: 0.713377\n",
            "Iteration 6631, loss = 61414.65540047\n",
            "Validation score: 0.713434\n",
            "Iteration 6632, loss = 61400.86451158\n",
            "Validation score: 0.713495\n",
            "Iteration 6633, loss = 61385.05723330\n",
            "Validation score: 0.713545\n",
            "Iteration 6634, loss = 61372.29146828\n",
            "Validation score: 0.713601\n",
            "Iteration 6635, loss = 61354.72311405\n",
            "Validation score: 0.713673\n",
            "Iteration 6636, loss = 61342.45972644\n",
            "Validation score: 0.713758\n",
            "Iteration 6637, loss = 61324.77941747\n",
            "Validation score: 0.713837\n",
            "Iteration 6638, loss = 61310.54323685\n",
            "Validation score: 0.713935\n",
            "Iteration 6639, loss = 61293.49626918\n",
            "Validation score: 0.714037\n",
            "Iteration 6640, loss = 61276.12322600\n",
            "Validation score: 0.714136\n",
            "Iteration 6641, loss = 61259.79971366\n",
            "Validation score: 0.714215\n",
            "Iteration 6642, loss = 61243.48788548\n",
            "Validation score: 0.714299\n",
            "Iteration 6643, loss = 61231.08698435\n",
            "Validation score: 0.714384\n",
            "Iteration 6644, loss = 61214.23384690\n",
            "Validation score: 0.714452\n",
            "Iteration 6645, loss = 61200.10343030\n",
            "Validation score: 0.714517\n",
            "Iteration 6646, loss = 61184.63285492\n",
            "Validation score: 0.714592\n",
            "Iteration 6647, loss = 61171.24987025\n",
            "Validation score: 0.714672\n",
            "Iteration 6648, loss = 61156.31535560\n",
            "Validation score: 0.714749\n",
            "Iteration 6649, loss = 61141.26622771\n",
            "Validation score: 0.714852\n",
            "Iteration 6650, loss = 61131.32649424\n",
            "Validation score: 0.714947\n",
            "Iteration 6651, loss = 61112.56062838\n",
            "Validation score: 0.715014\n",
            "Iteration 6652, loss = 61097.22365996\n",
            "Validation score: 0.715081\n",
            "Iteration 6653, loss = 61080.80753329\n",
            "Validation score: 0.715135\n",
            "Iteration 6654, loss = 61065.41248577\n",
            "Validation score: 0.715181\n",
            "Iteration 6655, loss = 61050.03077039\n",
            "Validation score: 0.715227\n",
            "Iteration 6656, loss = 61034.43773586\n",
            "Validation score: 0.715306\n",
            "Iteration 6657, loss = 61019.05340511\n",
            "Validation score: 0.715381\n",
            "Iteration 6658, loss = 61002.04426577\n",
            "Validation score: 0.715437\n",
            "Iteration 6659, loss = 60987.08345634\n",
            "Validation score: 0.715506\n",
            "Iteration 6660, loss = 60970.81065768\n",
            "Validation score: 0.715585\n",
            "Iteration 6661, loss = 60954.78191624\n",
            "Validation score: 0.715653\n",
            "Iteration 6662, loss = 60942.08295422\n",
            "Validation score: 0.715742\n",
            "Iteration 6663, loss = 60925.32727893\n",
            "Validation score: 0.715817\n",
            "Iteration 6664, loss = 60910.33783548\n",
            "Validation score: 0.715902\n",
            "Iteration 6665, loss = 60894.91148819\n",
            "Validation score: 0.715996\n",
            "Iteration 6666, loss = 60878.20419907\n",
            "Validation score: 0.716084\n",
            "Iteration 6667, loss = 60864.24807763\n",
            "Validation score: 0.716171\n",
            "Iteration 6668, loss = 60848.47628939\n",
            "Validation score: 0.716258\n",
            "Iteration 6669, loss = 60834.99630011\n",
            "Validation score: 0.716346\n",
            "Iteration 6670, loss = 60821.06885023\n",
            "Validation score: 0.716429\n",
            "Iteration 6671, loss = 60807.39413228\n",
            "Validation score: 0.716505\n",
            "Iteration 6672, loss = 60791.55712921\n",
            "Validation score: 0.716575\n",
            "Iteration 6673, loss = 60776.27429684\n",
            "Validation score: 0.716650\n",
            "Iteration 6674, loss = 60762.08614628\n",
            "Validation score: 0.716722\n",
            "Iteration 6675, loss = 60747.42407859\n",
            "Validation score: 0.716804\n",
            "Iteration 6676, loss = 60729.68456557\n",
            "Validation score: 0.716877\n",
            "Iteration 6677, loss = 60713.63419637\n",
            "Validation score: 0.716940\n",
            "Iteration 6678, loss = 60697.82862117\n",
            "Validation score: 0.716999\n",
            "Iteration 6679, loss = 60682.50414717\n",
            "Validation score: 0.717071\n",
            "Iteration 6680, loss = 60666.56656172\n",
            "Validation score: 0.717140\n",
            "Iteration 6681, loss = 60651.44743861\n",
            "Validation score: 0.717197\n",
            "Iteration 6682, loss = 60636.31545119\n",
            "Validation score: 0.717242\n",
            "Iteration 6683, loss = 60621.13245995\n",
            "Validation score: 0.717289\n",
            "Iteration 6684, loss = 60604.02537648\n",
            "Validation score: 0.717320\n",
            "Iteration 6685, loss = 60594.92097855\n",
            "Validation score: 0.717352\n",
            "Iteration 6686, loss = 60574.94466061\n",
            "Validation score: 0.717398\n",
            "Iteration 6687, loss = 60562.75257673\n",
            "Validation score: 0.717437\n",
            "Iteration 6688, loss = 60546.35534187\n",
            "Validation score: 0.717480\n",
            "Iteration 6689, loss = 60531.40919347\n",
            "Validation score: 0.717528\n",
            "Iteration 6690, loss = 60517.09015763\n",
            "Validation score: 0.717577\n",
            "Iteration 6691, loss = 60501.64407067\n",
            "Validation score: 0.717614\n",
            "Iteration 6692, loss = 60485.70191468\n",
            "Validation score: 0.717659\n",
            "Iteration 6693, loss = 60470.89475612\n",
            "Validation score: 0.717707\n",
            "Iteration 6694, loss = 60457.76943998\n",
            "Validation score: 0.717762\n",
            "Iteration 6695, loss = 60441.30417457\n",
            "Validation score: 0.717827\n",
            "Iteration 6696, loss = 60424.88126968\n",
            "Validation score: 0.717891\n",
            "Iteration 6697, loss = 60411.05676339\n",
            "Validation score: 0.717953\n",
            "Iteration 6698, loss = 60394.60627815\n",
            "Validation score: 0.718001\n",
            "Iteration 6699, loss = 60378.40665874\n",
            "Validation score: 0.718043\n",
            "Iteration 6700, loss = 60362.32059854\n",
            "Validation score: 0.718099\n",
            "Iteration 6701, loss = 60347.91958739\n",
            "Validation score: 0.718157\n",
            "Iteration 6702, loss = 60335.02269986\n",
            "Validation score: 0.718214\n",
            "Iteration 6703, loss = 60318.34251923\n",
            "Validation score: 0.718272\n",
            "Iteration 6704, loss = 60306.19032964\n",
            "Validation score: 0.718316\n",
            "Iteration 6705, loss = 60293.80696768\n",
            "Validation score: 0.718346\n",
            "Iteration 6706, loss = 60275.72211181\n",
            "Validation score: 0.718407\n",
            "Iteration 6707, loss = 60262.44908342\n",
            "Validation score: 0.718476\n",
            "Iteration 6708, loss = 60246.81813799\n",
            "Validation score: 0.718566\n",
            "Iteration 6709, loss = 60230.91750405\n",
            "Validation score: 0.718647\n",
            "Iteration 6710, loss = 60215.66401007\n",
            "Validation score: 0.718741\n",
            "Iteration 6711, loss = 60199.18156159\n",
            "Validation score: 0.718844\n",
            "Iteration 6712, loss = 60188.00975624\n",
            "Validation score: 0.718946\n",
            "Iteration 6713, loss = 60169.36604231\n",
            "Validation score: 0.719017\n",
            "Iteration 6714, loss = 60154.78246408\n",
            "Validation score: 0.719080\n",
            "Iteration 6715, loss = 60139.55695215\n",
            "Validation score: 0.719149\n",
            "Iteration 6716, loss = 60122.49807205\n",
            "Validation score: 0.719232\n",
            "Iteration 6717, loss = 60109.78749160\n",
            "Validation score: 0.719333\n",
            "Iteration 6718, loss = 60094.52875598\n",
            "Validation score: 0.719439\n",
            "Iteration 6719, loss = 60078.48130946\n",
            "Validation score: 0.719530\n",
            "Iteration 6720, loss = 60064.30760804\n",
            "Validation score: 0.719608\n",
            "Iteration 6721, loss = 60048.16425119\n",
            "Validation score: 0.719672\n",
            "Iteration 6722, loss = 60032.39552685\n",
            "Validation score: 0.719740\n",
            "Iteration 6723, loss = 60015.48316684\n",
            "Validation score: 0.719799\n",
            "Iteration 6724, loss = 60003.32154023\n",
            "Validation score: 0.719856\n",
            "Iteration 6725, loss = 59986.06760577\n",
            "Validation score: 0.719904\n",
            "Iteration 6726, loss = 59969.37436372\n",
            "Validation score: 0.719938\n",
            "Iteration 6727, loss = 59952.60022734\n",
            "Validation score: 0.719988\n",
            "Iteration 6728, loss = 59938.80793379\n",
            "Validation score: 0.720052\n",
            "Iteration 6729, loss = 59923.98687375\n",
            "Validation score: 0.720121\n",
            "Iteration 6730, loss = 59906.62090059\n",
            "Validation score: 0.720182\n",
            "Iteration 6731, loss = 59894.16948954\n",
            "Validation score: 0.720230\n",
            "Iteration 6732, loss = 59874.90185908\n",
            "Validation score: 0.720294\n",
            "Iteration 6733, loss = 59858.91891278\n",
            "Validation score: 0.720361\n",
            "Iteration 6734, loss = 59843.32141840\n",
            "Validation score: 0.720420\n",
            "Iteration 6735, loss = 59829.74816226\n",
            "Validation score: 0.720478\n",
            "Iteration 6736, loss = 59814.75034850\n",
            "Validation score: 0.720521\n",
            "Iteration 6737, loss = 59797.92700504\n",
            "Validation score: 0.720593\n",
            "Iteration 6738, loss = 59784.86077671\n",
            "Validation score: 0.720663\n",
            "Iteration 6739, loss = 59770.13831137\n",
            "Validation score: 0.720736\n",
            "Iteration 6740, loss = 59754.39638295\n",
            "Validation score: 0.720785\n",
            "Iteration 6741, loss = 59738.23144241\n",
            "Validation score: 0.720824\n",
            "Iteration 6742, loss = 59723.73842436\n",
            "Validation score: 0.720842\n",
            "Iteration 6743, loss = 59707.60731601\n",
            "Validation score: 0.720878\n",
            "Iteration 6744, loss = 59693.37800252\n",
            "Validation score: 0.720924\n",
            "Iteration 6745, loss = 59677.57535477\n",
            "Validation score: 0.720988\n",
            "Iteration 6746, loss = 59660.46066592\n",
            "Validation score: 0.721051\n",
            "Iteration 6747, loss = 59645.94182249\n",
            "Validation score: 0.721118\n",
            "Iteration 6748, loss = 59630.25261684\n",
            "Validation score: 0.721172\n",
            "Iteration 6749, loss = 59613.53723267\n",
            "Validation score: 0.721213\n",
            "Iteration 6750, loss = 59599.81955499\n",
            "Validation score: 0.721267\n",
            "Iteration 6751, loss = 59582.66472518\n",
            "Validation score: 0.721337\n",
            "Iteration 6752, loss = 59566.74360304\n",
            "Validation score: 0.721411\n",
            "Iteration 6753, loss = 59551.54361022\n",
            "Validation score: 0.721501\n",
            "Iteration 6754, loss = 59534.14179337\n",
            "Validation score: 0.721597\n",
            "Iteration 6755, loss = 59517.46705961\n",
            "Validation score: 0.721690\n",
            "Iteration 6756, loss = 59502.63720442\n",
            "Validation score: 0.721780\n",
            "Iteration 6757, loss = 59487.25012152\n",
            "Validation score: 0.721853\n",
            "Iteration 6758, loss = 59471.02712406\n",
            "Validation score: 0.721911\n",
            "Iteration 6759, loss = 59453.26732755\n",
            "Validation score: 0.721970\n",
            "Iteration 6760, loss = 59440.46986901\n",
            "Validation score: 0.722020\n",
            "Iteration 6761, loss = 59425.62970023\n",
            "Validation score: 0.722071\n",
            "Iteration 6762, loss = 59409.27422888\n",
            "Validation score: 0.722147\n",
            "Iteration 6763, loss = 59395.00341784\n",
            "Validation score: 0.722221\n",
            "Iteration 6764, loss = 59382.24267565\n",
            "Validation score: 0.722304\n",
            "Iteration 6765, loss = 59366.44226567\n",
            "Validation score: 0.722373\n",
            "Iteration 6766, loss = 59353.80049321\n",
            "Validation score: 0.722450\n",
            "Iteration 6767, loss = 59338.98424617\n",
            "Validation score: 0.722523\n",
            "Iteration 6768, loss = 59324.29743143\n",
            "Validation score: 0.722590\n",
            "Iteration 6769, loss = 59310.00315374\n",
            "Validation score: 0.722657\n",
            "Iteration 6770, loss = 59294.95539011\n",
            "Validation score: 0.722702\n",
            "Iteration 6771, loss = 59278.70853541\n",
            "Validation score: 0.722739\n",
            "Iteration 6772, loss = 59265.55283352\n",
            "Validation score: 0.722767\n",
            "Iteration 6773, loss = 59249.50899529\n",
            "Validation score: 0.722781\n",
            "Iteration 6774, loss = 59235.64195035\n",
            "Validation score: 0.722805\n",
            "Iteration 6775, loss = 59219.64090706\n",
            "Validation score: 0.722843\n",
            "Iteration 6776, loss = 59205.24160261\n",
            "Validation score: 0.722889\n",
            "Iteration 6777, loss = 59189.73547199\n",
            "Validation score: 0.722924\n",
            "Iteration 6778, loss = 59177.81746681\n",
            "Validation score: 0.722960\n",
            "Iteration 6779, loss = 59163.82195599\n",
            "Validation score: 0.722991\n",
            "Iteration 6780, loss = 59147.84246693\n",
            "Validation score: 0.723033\n",
            "Iteration 6781, loss = 59135.44741325\n",
            "Validation score: 0.723064\n",
            "Iteration 6782, loss = 59121.18387117\n",
            "Validation score: 0.723118\n",
            "Iteration 6783, loss = 59105.78231473\n",
            "Validation score: 0.723172\n",
            "Iteration 6784, loss = 59091.44476608\n",
            "Validation score: 0.723215\n",
            "Iteration 6785, loss = 59076.78623395\n",
            "Validation score: 0.723265\n",
            "Iteration 6786, loss = 59062.61587583\n",
            "Validation score: 0.723323\n",
            "Iteration 6787, loss = 59048.88435998\n",
            "Validation score: 0.723390\n",
            "Iteration 6788, loss = 59033.36706010\n",
            "Validation score: 0.723454\n",
            "Iteration 6789, loss = 59018.71598679\n",
            "Validation score: 0.723519\n",
            "Iteration 6790, loss = 59007.64582666\n",
            "Validation score: 0.723593\n",
            "Iteration 6791, loss = 58990.30805992\n",
            "Validation score: 0.723633\n",
            "Iteration 6792, loss = 58976.40877091\n",
            "Validation score: 0.723672\n",
            "Iteration 6793, loss = 58960.03920264\n",
            "Validation score: 0.723741\n",
            "Iteration 6794, loss = 58945.10915823\n",
            "Validation score: 0.723812\n",
            "Iteration 6795, loss = 58929.12575613\n",
            "Validation score: 0.723892\n",
            "Iteration 6796, loss = 58914.97963389\n",
            "Validation score: 0.723964\n",
            "Iteration 6797, loss = 58898.45234687\n",
            "Validation score: 0.724022\n",
            "Iteration 6798, loss = 58882.73767717\n",
            "Validation score: 0.724077\n",
            "Iteration 6799, loss = 58866.24169546\n",
            "Validation score: 0.724126\n",
            "Iteration 6800, loss = 58852.23248800\n",
            "Validation score: 0.724170\n",
            "Iteration 6801, loss = 58837.74138492\n",
            "Validation score: 0.724217\n",
            "Iteration 6802, loss = 58822.59185031\n",
            "Validation score: 0.724261\n",
            "Iteration 6803, loss = 58806.94499152\n",
            "Validation score: 0.724298\n",
            "Iteration 6804, loss = 58793.73604515\n",
            "Validation score: 0.724336\n",
            "Iteration 6805, loss = 58779.40618555\n",
            "Validation score: 0.724369\n",
            "Iteration 6806, loss = 58764.33577728\n",
            "Validation score: 0.724410\n",
            "Iteration 6807, loss = 58751.93172936\n",
            "Validation score: 0.724446\n",
            "Iteration 6808, loss = 58737.23576139\n",
            "Validation score: 0.724499\n",
            "Iteration 6809, loss = 58722.93397596\n",
            "Validation score: 0.724567\n",
            "Iteration 6810, loss = 58710.67674796\n",
            "Validation score: 0.724632\n",
            "Iteration 6811, loss = 58691.82056253\n",
            "Validation score: 0.724721\n",
            "Iteration 6812, loss = 58675.05933234\n",
            "Validation score: 0.724822\n",
            "Iteration 6813, loss = 58658.18010326\n",
            "Validation score: 0.724923\n",
            "Iteration 6814, loss = 58646.75348406\n",
            "Validation score: 0.725026\n",
            "Iteration 6815, loss = 58626.64526363\n",
            "Validation score: 0.725125\n",
            "Iteration 6816, loss = 58612.37546752\n",
            "Validation score: 0.725226\n",
            "Iteration 6817, loss = 58598.20347936\n",
            "Validation score: 0.725312\n",
            "Iteration 6818, loss = 58583.12721145\n",
            "Validation score: 0.725389\n",
            "Iteration 6819, loss = 58566.61554744\n",
            "Validation score: 0.725457\n",
            "Iteration 6820, loss = 58551.79054411\n",
            "Validation score: 0.725515\n",
            "Iteration 6821, loss = 58536.00633170\n",
            "Validation score: 0.725589\n",
            "Iteration 6822, loss = 58524.14226160\n",
            "Validation score: 0.725654\n",
            "Iteration 6823, loss = 58507.11509719\n",
            "Validation score: 0.725716\n",
            "Iteration 6824, loss = 58492.21641147\n",
            "Validation score: 0.725774\n",
            "Iteration 6825, loss = 58476.99602879\n",
            "Validation score: 0.725837\n",
            "Iteration 6826, loss = 58464.92151151\n",
            "Validation score: 0.725917\n",
            "Iteration 6827, loss = 58449.55294611\n",
            "Validation score: 0.725967\n",
            "Iteration 6828, loss = 58431.26619001\n",
            "Validation score: 0.726026\n",
            "Iteration 6829, loss = 58416.68136820\n",
            "Validation score: 0.726079\n",
            "Iteration 6830, loss = 58404.76351473\n",
            "Validation score: 0.726116\n",
            "Iteration 6831, loss = 58386.16898834\n",
            "Validation score: 0.726168\n",
            "Iteration 6832, loss = 58372.88061440\n",
            "Validation score: 0.726192\n",
            "Iteration 6833, loss = 58362.15438317\n",
            "Validation score: 0.726205\n",
            "Iteration 6834, loss = 58343.73608841\n",
            "Validation score: 0.726219\n",
            "Iteration 6835, loss = 58328.29510620\n",
            "Validation score: 0.726238\n",
            "Iteration 6836, loss = 58315.23136982\n",
            "Validation score: 0.726261\n",
            "Iteration 6837, loss = 58304.16444563\n",
            "Validation score: 0.726287\n",
            "Iteration 6838, loss = 58287.66635911\n",
            "Validation score: 0.726346\n",
            "Iteration 6839, loss = 58271.30506232\n",
            "Validation score: 0.726409\n",
            "Iteration 6840, loss = 58254.44326069\n",
            "Validation score: 0.726470\n",
            "Iteration 6841, loss = 58240.50380428\n",
            "Validation score: 0.726542\n",
            "Iteration 6842, loss = 58224.66667106\n",
            "Validation score: 0.726620\n",
            "Iteration 6843, loss = 58209.73124787\n",
            "Validation score: 0.726688\n",
            "Iteration 6844, loss = 58192.96280560\n",
            "Validation score: 0.726752\n",
            "Iteration 6845, loss = 58177.41087704\n",
            "Validation score: 0.726835\n",
            "Iteration 6846, loss = 58161.95512731\n",
            "Validation score: 0.726903\n",
            "Iteration 6847, loss = 58146.53745742\n",
            "Validation score: 0.726979\n",
            "Iteration 6848, loss = 58133.61661485\n",
            "Validation score: 0.727065\n",
            "Iteration 6849, loss = 58118.32373052\n",
            "Validation score: 0.727141\n",
            "Iteration 6850, loss = 58103.21414292\n",
            "Validation score: 0.727209\n",
            "Iteration 6851, loss = 58087.56014628\n",
            "Validation score: 0.727255\n",
            "Iteration 6852, loss = 58071.97703790\n",
            "Validation score: 0.727311\n",
            "Iteration 6853, loss = 58057.72976304\n",
            "Validation score: 0.727368\n",
            "Iteration 6854, loss = 58043.36607133\n",
            "Validation score: 0.727441\n",
            "Iteration 6855, loss = 58027.98448116\n",
            "Validation score: 0.727500\n",
            "Iteration 6856, loss = 58013.55176110\n",
            "Validation score: 0.727552\n",
            "Iteration 6857, loss = 57997.86788580\n",
            "Validation score: 0.727620\n",
            "Iteration 6858, loss = 57984.65861073\n",
            "Validation score: 0.727698\n",
            "Iteration 6859, loss = 57969.31283737\n",
            "Validation score: 0.727760\n",
            "Iteration 6860, loss = 57958.07085700\n",
            "Validation score: 0.727837\n",
            "Iteration 6861, loss = 57941.49738232\n",
            "Validation score: 0.727893\n",
            "Iteration 6862, loss = 57927.23960679\n",
            "Validation score: 0.727956\n",
            "Iteration 6863, loss = 57912.95912480\n",
            "Validation score: 0.728028\n",
            "Iteration 6864, loss = 57897.93414361\n",
            "Validation score: 0.728094\n",
            "Iteration 6865, loss = 57882.41959192\n",
            "Validation score: 0.728149\n",
            "Iteration 6866, loss = 57868.94419204\n",
            "Validation score: 0.728199\n",
            "Iteration 6867, loss = 57850.24113986\n",
            "Validation score: 0.728241\n",
            "Iteration 6868, loss = 57838.45269547\n",
            "Validation score: 0.728273\n",
            "Iteration 6869, loss = 57820.46180277\n",
            "Validation score: 0.728333\n",
            "Iteration 6870, loss = 57805.40645326\n",
            "Validation score: 0.728379\n",
            "Iteration 6871, loss = 57789.85628702\n",
            "Validation score: 0.728432\n",
            "Iteration 6872, loss = 57775.40391499\n",
            "Validation score: 0.728487\n",
            "Iteration 6873, loss = 57764.97559443\n",
            "Validation score: 0.728540\n",
            "Iteration 6874, loss = 57746.03219134\n",
            "Validation score: 0.728614\n",
            "Iteration 6875, loss = 57729.82460786\n",
            "Validation score: 0.728702\n",
            "Iteration 6876, loss = 57715.10743329\n",
            "Validation score: 0.728805\n",
            "Iteration 6877, loss = 57699.71653702\n",
            "Validation score: 0.728915\n",
            "Iteration 6878, loss = 57684.36178844\n",
            "Validation score: 0.729000\n",
            "Iteration 6879, loss = 57669.69996226\n",
            "Validation score: 0.729067\n",
            "Iteration 6880, loss = 57655.86022266\n",
            "Validation score: 0.729122\n",
            "Iteration 6881, loss = 57639.69384125\n",
            "Validation score: 0.729177\n",
            "Iteration 6882, loss = 57625.77337018\n",
            "Validation score: 0.729211\n",
            "Iteration 6883, loss = 57612.77074742\n",
            "Validation score: 0.729251\n",
            "Iteration 6884, loss = 57597.65060173\n",
            "Validation score: 0.729298\n",
            "Iteration 6885, loss = 57584.93174771\n",
            "Validation score: 0.729348\n",
            "Iteration 6886, loss = 57568.99490297\n",
            "Validation score: 0.729409\n",
            "Iteration 6887, loss = 57555.13218698\n",
            "Validation score: 0.729471\n",
            "Iteration 6888, loss = 57541.92886707\n",
            "Validation score: 0.729532\n",
            "Iteration 6889, loss = 57527.45171547\n",
            "Validation score: 0.729591\n",
            "Iteration 6890, loss = 57513.04839565\n",
            "Validation score: 0.729655\n",
            "Iteration 6891, loss = 57497.37873650\n",
            "Validation score: 0.729725\n",
            "Iteration 6892, loss = 57484.26037571\n",
            "Validation score: 0.729788\n",
            "Iteration 6893, loss = 57469.32135761\n",
            "Validation score: 0.729852\n",
            "Iteration 6894, loss = 57452.60285472\n",
            "Validation score: 0.729916\n",
            "Iteration 6895, loss = 57437.86825194\n",
            "Validation score: 0.729996\n",
            "Iteration 6896, loss = 57422.24442581\n",
            "Validation score: 0.730060\n",
            "Iteration 6897, loss = 57405.68397472\n",
            "Validation score: 0.730132\n",
            "Iteration 6898, loss = 57393.55581065\n",
            "Validation score: 0.730207\n",
            "Iteration 6899, loss = 57376.25454464\n",
            "Validation score: 0.730270\n",
            "Iteration 6900, loss = 57360.98487831\n",
            "Validation score: 0.730338\n",
            "Iteration 6901, loss = 57348.09920238\n",
            "Validation score: 0.730398\n",
            "Iteration 6902, loss = 57331.67129761\n",
            "Validation score: 0.730447\n",
            "Iteration 6903, loss = 57316.23831431\n",
            "Validation score: 0.730501\n",
            "Iteration 6904, loss = 57303.38122431\n",
            "Validation score: 0.730555\n",
            "Iteration 6905, loss = 57287.52195080\n",
            "Validation score: 0.730614\n",
            "Iteration 6906, loss = 57271.61705226\n",
            "Validation score: 0.730671\n",
            "Iteration 6907, loss = 57258.41256658\n",
            "Validation score: 0.730719\n",
            "Iteration 6908, loss = 57244.97931833\n",
            "Validation score: 0.730792\n",
            "Iteration 6909, loss = 57227.63776779\n",
            "Validation score: 0.730848\n",
            "Iteration 6910, loss = 57213.30336593\n",
            "Validation score: 0.730908\n",
            "Iteration 6911, loss = 57198.90245939\n",
            "Validation score: 0.730956\n",
            "Iteration 6912, loss = 57184.92349400\n",
            "Validation score: 0.731004\n",
            "Iteration 6913, loss = 57170.39956870\n",
            "Validation score: 0.731059\n",
            "Iteration 6914, loss = 57154.96346207\n",
            "Validation score: 0.731134\n",
            "Iteration 6915, loss = 57141.70048044\n",
            "Validation score: 0.731217\n",
            "Iteration 6916, loss = 57126.85704962\n",
            "Validation score: 0.731312\n",
            "Iteration 6917, loss = 57111.53121693\n",
            "Validation score: 0.731394\n",
            "Iteration 6918, loss = 57097.82869074\n",
            "Validation score: 0.731468\n",
            "Iteration 6919, loss = 57083.07913689\n",
            "Validation score: 0.731518\n",
            "Iteration 6920, loss = 57069.61312714\n",
            "Validation score: 0.731554\n",
            "Iteration 6921, loss = 57054.07368276\n",
            "Validation score: 0.731599\n",
            "Iteration 6922, loss = 57044.30493649\n",
            "Validation score: 0.731657\n",
            "Iteration 6923, loss = 57027.46980548\n",
            "Validation score: 0.731737\n",
            "Iteration 6924, loss = 57013.13114468\n",
            "Validation score: 0.731811\n",
            "Iteration 6925, loss = 57000.17994984\n",
            "Validation score: 0.731896\n",
            "Iteration 6926, loss = 56984.18293551\n",
            "Validation score: 0.731985\n",
            "Iteration 6927, loss = 56974.25068023\n",
            "Validation score: 0.732075\n",
            "Iteration 6928, loss = 56957.55834100\n",
            "Validation score: 0.732143\n",
            "Iteration 6929, loss = 56946.61481250\n",
            "Validation score: 0.732209\n",
            "Iteration 6930, loss = 56933.02054563\n",
            "Validation score: 0.732249\n",
            "Iteration 6931, loss = 56918.86258476\n",
            "Validation score: 0.732296\n",
            "Iteration 6932, loss = 56905.02436981\n",
            "Validation score: 0.732332\n",
            "Iteration 6933, loss = 56892.67130211\n",
            "Validation score: 0.732346\n",
            "Iteration 6934, loss = 56877.57298440\n",
            "Validation score: 0.732363\n",
            "Iteration 6935, loss = 56863.81305339\n",
            "Validation score: 0.732395\n",
            "Iteration 6936, loss = 56849.01031182\n",
            "Validation score: 0.732425\n",
            "Iteration 6937, loss = 56837.42076595\n",
            "Validation score: 0.732463\n",
            "Iteration 6938, loss = 56824.24622241\n",
            "Validation score: 0.732519\n",
            "Iteration 6939, loss = 56809.30135403\n",
            "Validation score: 0.732565\n",
            "Iteration 6940, loss = 56795.65012283\n",
            "Validation score: 0.732606\n",
            "Iteration 6941, loss = 56781.78699280\n",
            "Validation score: 0.732634\n",
            "Iteration 6942, loss = 56767.80929304\n",
            "Validation score: 0.732656\n",
            "Iteration 6943, loss = 56754.12093708\n",
            "Validation score: 0.732687\n",
            "Iteration 6944, loss = 56742.19565936\n",
            "Validation score: 0.732718\n",
            "Iteration 6945, loss = 56726.49771837\n",
            "Validation score: 0.732777\n",
            "Iteration 6946, loss = 56713.49847155\n",
            "Validation score: 0.732823\n",
            "Iteration 6947, loss = 56699.88128726\n",
            "Validation score: 0.732894\n",
            "Iteration 6948, loss = 56684.43602258\n",
            "Validation score: 0.732978\n",
            "Iteration 6949, loss = 56670.84252541\n",
            "Validation score: 0.733056\n",
            "Iteration 6950, loss = 56656.75734683\n",
            "Validation score: 0.733143\n",
            "Iteration 6951, loss = 56641.63161377\n",
            "Validation score: 0.733223\n",
            "Iteration 6952, loss = 56628.35255980\n",
            "Validation score: 0.733307\n",
            "Iteration 6953, loss = 56613.55395793\n",
            "Validation score: 0.733383\n",
            "Iteration 6954, loss = 56599.06277487\n",
            "Validation score: 0.733469\n",
            "Iteration 6955, loss = 56589.58114089\n",
            "Validation score: 0.733560\n",
            "Iteration 6956, loss = 56574.92598208\n",
            "Validation score: 0.733639\n",
            "Iteration 6957, loss = 56561.62615237\n",
            "Validation score: 0.733702\n",
            "Iteration 6958, loss = 56548.46739777\n",
            "Validation score: 0.733755\n",
            "Iteration 6959, loss = 56533.62512377\n",
            "Validation score: 0.733822\n",
            "Iteration 6960, loss = 56520.75182328\n",
            "Validation score: 0.733886\n",
            "Iteration 6961, loss = 56507.92846782\n",
            "Validation score: 0.733938\n",
            "Iteration 6962, loss = 56493.82130925\n",
            "Validation score: 0.734012\n",
            "Iteration 6963, loss = 56480.30857631\n",
            "Validation score: 0.734083\n",
            "Iteration 6964, loss = 56467.02097238\n",
            "Validation score: 0.734166\n",
            "Iteration 6965, loss = 56455.33675975\n",
            "Validation score: 0.734243\n",
            "Iteration 6966, loss = 56440.72735489\n",
            "Validation score: 0.734297\n",
            "Iteration 6967, loss = 56427.51179675\n",
            "Validation score: 0.734328\n",
            "Iteration 6968, loss = 56413.81631838\n",
            "Validation score: 0.734362\n",
            "Iteration 6969, loss = 56402.73759477\n",
            "Validation score: 0.734407\n",
            "Iteration 6970, loss = 56387.96418371\n",
            "Validation score: 0.734450\n",
            "Iteration 6971, loss = 56376.71842538\n",
            "Validation score: 0.734490\n",
            "Iteration 6972, loss = 56363.12079070\n",
            "Validation score: 0.734548\n",
            "Iteration 6973, loss = 56350.93485356\n",
            "Validation score: 0.734599\n",
            "Iteration 6974, loss = 56337.96116755\n",
            "Validation score: 0.734663\n",
            "Iteration 6975, loss = 56325.15803085\n",
            "Validation score: 0.734741\n",
            "Iteration 6976, loss = 56312.53347309\n",
            "Validation score: 0.734799\n",
            "Iteration 6977, loss = 56298.69315365\n",
            "Validation score: 0.734848\n",
            "Iteration 6978, loss = 56286.10073568\n",
            "Validation score: 0.734892\n",
            "Iteration 6979, loss = 56272.94148245\n",
            "Validation score: 0.734943\n",
            "Iteration 6980, loss = 56258.71199738\n",
            "Validation score: 0.734998\n",
            "Iteration 6981, loss = 56246.72233258\n",
            "Validation score: 0.735056\n",
            "Iteration 6982, loss = 56232.97866245\n",
            "Validation score: 0.735104\n",
            "Iteration 6983, loss = 56219.85531826\n",
            "Validation score: 0.735145\n",
            "Iteration 6984, loss = 56205.76243718\n",
            "Validation score: 0.735178\n",
            "Iteration 6985, loss = 56192.65138440\n",
            "Validation score: 0.735212\n",
            "Iteration 6986, loss = 56179.80889136\n",
            "Validation score: 0.735238\n",
            "Iteration 6987, loss = 56166.12588050\n",
            "Validation score: 0.735273\n",
            "Iteration 6988, loss = 56152.80506858\n",
            "Validation score: 0.735324\n",
            "Iteration 6989, loss = 56139.55376441\n",
            "Validation score: 0.735368\n",
            "Iteration 6990, loss = 56124.92558958\n",
            "Validation score: 0.735393\n",
            "Iteration 6991, loss = 56113.35352314\n",
            "Validation score: 0.735414\n",
            "Iteration 6992, loss = 56099.05798291\n",
            "Validation score: 0.735435\n",
            "Iteration 6993, loss = 56086.77459044\n",
            "Validation score: 0.735452\n",
            "Iteration 6994, loss = 56072.07207567\n",
            "Validation score: 0.735470\n",
            "Iteration 6995, loss = 56064.10255859\n",
            "Validation score: 0.735505\n",
            "Iteration 6996, loss = 56049.11021481\n",
            "Validation score: 0.735555\n",
            "Iteration 6997, loss = 56032.99756580\n",
            "Validation score: 0.735590\n",
            "Iteration 6998, loss = 56020.72835327\n",
            "Validation score: 0.735640\n",
            "Iteration 6999, loss = 56007.44379693\n",
            "Validation score: 0.735698\n",
            "Iteration 7000, loss = 55995.27094973\n",
            "Validation score: 0.735755\n",
            "Iteration 7001, loss = 55981.91270550\n",
            "Validation score: 0.735808\n",
            "Iteration 7002, loss = 55968.71814960\n",
            "Validation score: 0.735846\n",
            "Iteration 7003, loss = 55956.61770509\n",
            "Validation score: 0.735877\n",
            "Iteration 7004, loss = 55941.74405810\n",
            "Validation score: 0.735910\n",
            "Iteration 7005, loss = 55932.61365298\n",
            "Validation score: 0.735940\n",
            "Iteration 7006, loss = 55918.31456919\n",
            "Validation score: 0.735989\n",
            "Iteration 7007, loss = 55907.21665116\n",
            "Validation score: 0.736046\n",
            "Iteration 7008, loss = 55895.44785505\n",
            "Validation score: 0.736116\n",
            "Iteration 7009, loss = 55880.49298874\n",
            "Validation score: 0.736188\n",
            "Iteration 7010, loss = 55868.83540714\n",
            "Validation score: 0.736246\n",
            "Iteration 7011, loss = 55854.76467057\n",
            "Validation score: 0.736295\n",
            "Iteration 7012, loss = 55843.01640129\n",
            "Validation score: 0.736348\n",
            "Iteration 7013, loss = 55831.29365917\n",
            "Validation score: 0.736421\n",
            "Iteration 7014, loss = 55818.12898225\n",
            "Validation score: 0.736493\n",
            "Iteration 7015, loss = 55805.36263180\n",
            "Validation score: 0.736569\n",
            "Iteration 7016, loss = 55794.56226323\n",
            "Validation score: 0.736638\n",
            "Iteration 7017, loss = 55780.08404782\n",
            "Validation score: 0.736700\n",
            "Iteration 7018, loss = 55768.51996485\n",
            "Validation score: 0.736776\n",
            "Iteration 7019, loss = 55760.14120602\n",
            "Validation score: 0.736849\n",
            "Iteration 7020, loss = 55743.79420070\n",
            "Validation score: 0.736904\n",
            "Iteration 7021, loss = 55730.28102281\n",
            "Validation score: 0.736961\n",
            "Iteration 7022, loss = 55717.13488923\n",
            "Validation score: 0.737026\n",
            "Iteration 7023, loss = 55703.69461110\n",
            "Validation score: 0.737086\n",
            "Iteration 7024, loss = 55691.80870064\n",
            "Validation score: 0.737148\n",
            "Iteration 7025, loss = 55679.31743339\n",
            "Validation score: 0.737200\n",
            "Iteration 7026, loss = 55667.26866588\n",
            "Validation score: 0.737232\n",
            "Iteration 7027, loss = 55652.51833715\n",
            "Validation score: 0.737274\n",
            "Iteration 7028, loss = 55639.44476806\n",
            "Validation score: 0.737312\n",
            "Iteration 7029, loss = 55626.07193465\n",
            "Validation score: 0.737363\n",
            "Iteration 7030, loss = 55613.85998543\n",
            "Validation score: 0.737407\n",
            "Iteration 7031, loss = 55600.81235406\n",
            "Validation score: 0.737471\n",
            "Iteration 7032, loss = 55588.52472961\n",
            "Validation score: 0.737515\n",
            "Iteration 7033, loss = 55573.78900646\n",
            "Validation score: 0.737562\n",
            "Iteration 7034, loss = 55557.10707671\n",
            "Validation score: 0.737611\n",
            "Iteration 7035, loss = 55544.48763072\n",
            "Validation score: 0.737669\n",
            "Iteration 7036, loss = 55530.62475975\n",
            "Validation score: 0.737731\n",
            "Iteration 7037, loss = 55516.88018040\n",
            "Validation score: 0.737800\n",
            "Iteration 7038, loss = 55503.81426992\n",
            "Validation score: 0.737867\n",
            "Iteration 7039, loss = 55489.38681682\n",
            "Validation score: 0.737930\n",
            "Iteration 7040, loss = 55477.35802883\n",
            "Validation score: 0.737983\n",
            "Iteration 7041, loss = 55466.10802138\n",
            "Validation score: 0.738045\n",
            "Iteration 7042, loss = 55452.15815043\n",
            "Validation score: 0.738106\n",
            "Iteration 7043, loss = 55438.88364496\n",
            "Validation score: 0.738163\n",
            "Iteration 7044, loss = 55427.87548538\n",
            "Validation score: 0.738213\n",
            "Iteration 7045, loss = 55415.42442775\n",
            "Validation score: 0.738273\n",
            "Iteration 7046, loss = 55405.91499955\n",
            "Validation score: 0.738333\n",
            "Iteration 7047, loss = 55391.21642657\n",
            "Validation score: 0.738365\n",
            "Iteration 7048, loss = 55378.84584012\n",
            "Validation score: 0.738403\n",
            "Iteration 7049, loss = 55367.26416150\n",
            "Validation score: 0.738426\n",
            "Iteration 7050, loss = 55354.19789731\n",
            "Validation score: 0.738466\n",
            "Iteration 7051, loss = 55341.55890041\n",
            "Validation score: 0.738504\n",
            "Iteration 7052, loss = 55331.15482948\n",
            "Validation score: 0.738546\n",
            "Iteration 7053, loss = 55317.51859444\n",
            "Validation score: 0.738594\n",
            "Iteration 7054, loss = 55306.25009468\n",
            "Validation score: 0.738655\n",
            "Iteration 7055, loss = 55294.25655140\n",
            "Validation score: 0.738698\n",
            "Iteration 7056, loss = 55282.35338911\n",
            "Validation score: 0.738744\n",
            "Iteration 7057, loss = 55270.93462442\n",
            "Validation score: 0.738810\n",
            "Iteration 7058, loss = 55258.33776956\n",
            "Validation score: 0.738876\n",
            "Iteration 7059, loss = 55244.86817835\n",
            "Validation score: 0.738946\n",
            "Iteration 7060, loss = 55234.16886367\n",
            "Validation score: 0.739016\n",
            "Iteration 7061, loss = 55220.95596569\n",
            "Validation score: 0.739073\n",
            "Iteration 7062, loss = 55208.96095478\n",
            "Validation score: 0.739125\n",
            "Iteration 7063, loss = 55197.04688611\n",
            "Validation score: 0.739167\n",
            "Iteration 7064, loss = 55184.84086754\n",
            "Validation score: 0.739198\n",
            "Iteration 7065, loss = 55175.98505621\n",
            "Validation score: 0.739257\n",
            "Iteration 7066, loss = 55160.65652974\n",
            "Validation score: 0.739307\n",
            "Iteration 7067, loss = 55148.58551009\n",
            "Validation score: 0.739360\n",
            "Iteration 7068, loss = 55134.74516726\n",
            "Validation score: 0.739419\n",
            "Iteration 7069, loss = 55121.97375096\n",
            "Validation score: 0.739481\n",
            "Iteration 7070, loss = 55111.47840008\n",
            "Validation score: 0.739556\n",
            "Iteration 7071, loss = 55096.29950653\n",
            "Validation score: 0.739630\n",
            "Iteration 7072, loss = 55084.25468399\n",
            "Validation score: 0.739689\n",
            "Iteration 7073, loss = 55070.34736978\n",
            "Validation score: 0.739740\n",
            "Iteration 7074, loss = 55056.25251021\n",
            "Validation score: 0.739786\n",
            "Iteration 7075, loss = 55044.44029787\n",
            "Validation score: 0.739819\n",
            "Iteration 7076, loss = 55033.36618967\n",
            "Validation score: 0.739858\n",
            "Iteration 7077, loss = 55017.54651351\n",
            "Validation score: 0.739884\n",
            "Iteration 7078, loss = 55005.14710825\n",
            "Validation score: 0.739910\n",
            "Iteration 7079, loss = 54992.19293754\n",
            "Validation score: 0.739944\n",
            "Iteration 7080, loss = 54980.43138463\n",
            "Validation score: 0.739971\n",
            "Iteration 7081, loss = 54967.23327648\n",
            "Validation score: 0.740002\n",
            "Iteration 7082, loss = 54954.00113828\n",
            "Validation score: 0.740046\n",
            "Iteration 7083, loss = 54944.37916527\n",
            "Validation score: 0.740107\n",
            "Iteration 7084, loss = 54928.71896431\n",
            "Validation score: 0.740176\n",
            "Iteration 7085, loss = 54916.04897687\n",
            "Validation score: 0.740242\n",
            "Iteration 7086, loss = 54903.90019045\n",
            "Validation score: 0.740295\n",
            "Iteration 7087, loss = 54890.72374442\n",
            "Validation score: 0.740355\n",
            "Iteration 7088, loss = 54878.39714832\n",
            "Validation score: 0.740415\n",
            "Iteration 7089, loss = 54865.85142543\n",
            "Validation score: 0.740468\n",
            "Iteration 7090, loss = 54855.84139345\n",
            "Validation score: 0.740507\n",
            "Iteration 7091, loss = 54841.78333685\n",
            "Validation score: 0.740545\n",
            "Iteration 7092, loss = 54828.72556294\n",
            "Validation score: 0.740582\n",
            "Iteration 7093, loss = 54816.91156511\n",
            "Validation score: 0.740634\n",
            "Iteration 7094, loss = 54804.48041724\n",
            "Validation score: 0.740707\n",
            "Iteration 7095, loss = 54790.68941402\n",
            "Validation score: 0.740773\n",
            "Iteration 7096, loss = 54777.20748940\n",
            "Validation score: 0.740849\n",
            "Iteration 7097, loss = 54765.11078137\n",
            "Validation score: 0.740931\n",
            "Iteration 7098, loss = 54752.34016575\n",
            "Validation score: 0.741014\n",
            "Iteration 7099, loss = 54737.93244074\n",
            "Validation score: 0.741092\n",
            "Iteration 7100, loss = 54726.11669379\n",
            "Validation score: 0.741183\n",
            "Iteration 7101, loss = 54714.89334942\n",
            "Validation score: 0.741264\n",
            "Iteration 7102, loss = 54704.97153376\n",
            "Validation score: 0.741350\n",
            "Iteration 7103, loss = 54695.87649815\n",
            "Validation score: 0.741422\n",
            "Iteration 7104, loss = 54682.53297746\n",
            "Validation score: 0.741463\n",
            "Iteration 7105, loss = 54670.86448513\n",
            "Validation score: 0.741519\n",
            "Iteration 7106, loss = 54657.97559849\n",
            "Validation score: 0.741574\n",
            "Iteration 7107, loss = 54647.54885667\n",
            "Validation score: 0.741638\n",
            "Iteration 7108, loss = 54637.27850190\n",
            "Validation score: 0.741708\n",
            "Iteration 7109, loss = 54622.42545716\n",
            "Validation score: 0.741747\n",
            "Iteration 7110, loss = 54612.47331010\n",
            "Validation score: 0.741780\n",
            "Iteration 7111, loss = 54597.94733790\n",
            "Validation score: 0.741829\n",
            "Iteration 7112, loss = 54585.58112008\n",
            "Validation score: 0.741880\n",
            "Iteration 7113, loss = 54576.40529113\n",
            "Validation score: 0.741917\n",
            "Iteration 7114, loss = 54561.14949111\n",
            "Validation score: 0.741952\n",
            "Iteration 7115, loss = 54549.54949061\n",
            "Validation score: 0.741992\n",
            "Iteration 7116, loss = 54538.33733424\n",
            "Validation score: 0.742023\n",
            "Iteration 7117, loss = 54524.36768467\n",
            "Validation score: 0.742075\n",
            "Iteration 7118, loss = 54512.05043265\n",
            "Validation score: 0.742137\n",
            "Iteration 7119, loss = 54500.04293047\n",
            "Validation score: 0.742196\n",
            "Iteration 7120, loss = 54488.39544345\n",
            "Validation score: 0.742264\n",
            "Iteration 7121, loss = 54475.66352070\n",
            "Validation score: 0.742320\n",
            "Iteration 7122, loss = 54463.75320987\n",
            "Validation score: 0.742364\n",
            "Iteration 7123, loss = 54450.54212775\n",
            "Validation score: 0.742417\n",
            "Iteration 7124, loss = 54437.30383379\n",
            "Validation score: 0.742473\n",
            "Iteration 7125, loss = 54426.37538645\n",
            "Validation score: 0.742535\n",
            "Iteration 7126, loss = 54415.26718193\n",
            "Validation score: 0.742602\n",
            "Iteration 7127, loss = 54407.23371249\n",
            "Validation score: 0.742663\n",
            "Iteration 7128, loss = 54392.27446019\n",
            "Validation score: 0.742700\n",
            "Iteration 7129, loss = 54380.87949093\n",
            "Validation score: 0.742710\n",
            "Iteration 7130, loss = 54369.93035537\n",
            "Validation score: 0.742721\n",
            "Iteration 7131, loss = 54355.52768025\n",
            "Validation score: 0.742747\n",
            "Iteration 7132, loss = 54344.40063465\n",
            "Validation score: 0.742776\n",
            "Iteration 7133, loss = 54332.74141245\n",
            "Validation score: 0.742818\n",
            "Iteration 7134, loss = 54322.95814293\n",
            "Validation score: 0.742866\n",
            "Iteration 7135, loss = 54309.88299008\n",
            "Validation score: 0.742941\n",
            "Iteration 7136, loss = 54300.93367963\n",
            "Validation score: 0.743011\n",
            "Iteration 7137, loss = 54288.33031376\n",
            "Validation score: 0.743069\n",
            "Iteration 7138, loss = 54277.58715980\n",
            "Validation score: 0.743121\n",
            "Iteration 7139, loss = 54263.42060215\n",
            "Validation score: 0.743158\n",
            "Iteration 7140, loss = 54251.67005173\n",
            "Validation score: 0.743203\n",
            "Iteration 7141, loss = 54238.63270467\n",
            "Validation score: 0.743261\n",
            "Iteration 7142, loss = 54225.98887165\n",
            "Validation score: 0.743325\n",
            "Iteration 7143, loss = 54213.08767077\n",
            "Validation score: 0.743387\n",
            "Iteration 7144, loss = 54200.89737716\n",
            "Validation score: 0.743454\n",
            "Iteration 7145, loss = 54191.10079571\n",
            "Validation score: 0.743517\n",
            "Iteration 7146, loss = 54177.79413939\n",
            "Validation score: 0.743588\n",
            "Iteration 7147, loss = 54166.66348337\n",
            "Validation score: 0.743670\n",
            "Iteration 7148, loss = 54154.49062386\n",
            "Validation score: 0.743756\n",
            "Iteration 7149, loss = 54144.00769904\n",
            "Validation score: 0.743837\n",
            "Iteration 7150, loss = 54131.10026187\n",
            "Validation score: 0.743912\n",
            "Iteration 7151, loss = 54120.50598100\n",
            "Validation score: 0.743983\n",
            "Iteration 7152, loss = 54108.49375916\n",
            "Validation score: 0.744063\n",
            "Iteration 7153, loss = 54098.88963029\n",
            "Validation score: 0.744135\n",
            "Iteration 7154, loss = 54085.38789868\n",
            "Validation score: 0.744216\n",
            "Iteration 7155, loss = 54075.31154444\n",
            "Validation score: 0.744291\n",
            "Iteration 7156, loss = 54067.83870186\n",
            "Validation score: 0.744360\n",
            "Iteration 7157, loss = 54052.38783664\n",
            "Validation score: 0.744406\n",
            "Iteration 7158, loss = 54041.76816097\n",
            "Validation score: 0.744437\n",
            "Iteration 7159, loss = 54027.59556106\n",
            "Validation score: 0.744457\n",
            "Iteration 7160, loss = 54016.05589565\n",
            "Validation score: 0.744453\n",
            "Iteration 7161, loss = 54007.64968925\n",
            "Validation score: 0.744463\n",
            "Iteration 7162, loss = 53991.08839954\n",
            "Validation score: 0.744500\n",
            "Iteration 7163, loss = 53982.01197126\n",
            "Validation score: 0.744526\n",
            "Iteration 7164, loss = 53967.75051496\n",
            "Validation score: 0.744573\n",
            "Iteration 7165, loss = 53954.07024545\n",
            "Validation score: 0.744608\n",
            "Iteration 7166, loss = 53946.98977744\n",
            "Validation score: 0.744649\n",
            "Iteration 7167, loss = 53932.36646846\n",
            "Validation score: 0.744705\n",
            "Iteration 7168, loss = 53922.60374401\n",
            "Validation score: 0.744765\n",
            "Iteration 7169, loss = 53907.28817971\n",
            "Validation score: 0.744790\n",
            "Iteration 7170, loss = 53897.95107673\n",
            "Validation score: 0.744812\n",
            "Iteration 7171, loss = 53885.00968031\n",
            "Validation score: 0.744830\n",
            "Iteration 7172, loss = 53874.79002351\n",
            "Validation score: 0.744858\n",
            "Iteration 7173, loss = 53865.06546772\n",
            "Validation score: 0.744901\n",
            "Iteration 7174, loss = 53851.19448435\n",
            "Validation score: 0.744968\n",
            "Iteration 7175, loss = 53838.63150480\n",
            "Validation score: 0.745013\n",
            "Iteration 7176, loss = 53827.82119043\n",
            "Validation score: 0.745055\n",
            "Iteration 7177, loss = 53817.33356967\n",
            "Validation score: 0.745087\n",
            "Iteration 7178, loss = 53806.79175795\n",
            "Validation score: 0.745118\n",
            "Iteration 7179, loss = 53796.57617391\n",
            "Validation score: 0.745151\n",
            "Iteration 7180, loss = 53787.61958201\n",
            "Validation score: 0.745205\n",
            "Iteration 7181, loss = 53776.03172252\n",
            "Validation score: 0.745269\n",
            "Iteration 7182, loss = 53765.52664331\n",
            "Validation score: 0.745332\n",
            "Iteration 7183, loss = 53753.69036043\n",
            "Validation score: 0.745386\n",
            "Iteration 7184, loss = 53742.46954276\n",
            "Validation score: 0.745453\n",
            "Iteration 7185, loss = 53732.45076758\n",
            "Validation score: 0.745532\n",
            "Iteration 7186, loss = 53723.45042885\n",
            "Validation score: 0.745607\n",
            "Iteration 7187, loss = 53712.01049944\n",
            "Validation score: 0.745665\n",
            "Iteration 7188, loss = 53700.94954015\n",
            "Validation score: 0.745707\n",
            "Iteration 7189, loss = 53690.32387373\n",
            "Validation score: 0.745741\n",
            "Iteration 7190, loss = 53680.79659343\n",
            "Validation score: 0.745790\n",
            "Iteration 7191, loss = 53668.25276427\n",
            "Validation score: 0.745834\n",
            "Iteration 7192, loss = 53659.03185860\n",
            "Validation score: 0.745875\n",
            "Iteration 7193, loss = 53645.65789752\n",
            "Validation score: 0.745917\n",
            "Iteration 7194, loss = 53636.04507004\n",
            "Validation score: 0.745956\n",
            "Iteration 7195, loss = 53623.30707742\n",
            "Validation score: 0.746002\n",
            "Iteration 7196, loss = 53613.76593220\n",
            "Validation score: 0.746049\n",
            "Iteration 7197, loss = 53599.73490653\n",
            "Validation score: 0.746068\n",
            "Iteration 7198, loss = 53588.64337939\n",
            "Validation score: 0.746075\n",
            "Iteration 7199, loss = 53577.40392064\n",
            "Validation score: 0.746093\n",
            "Iteration 7200, loss = 53568.42992272\n",
            "Validation score: 0.746118\n",
            "Iteration 7201, loss = 53555.96474945\n",
            "Validation score: 0.746145\n",
            "Iteration 7202, loss = 53546.22009640\n",
            "Validation score: 0.746174\n",
            "Iteration 7203, loss = 53535.80381108\n",
            "Validation score: 0.746201\n",
            "Iteration 7204, loss = 53524.72888489\n",
            "Validation score: 0.746220\n",
            "Iteration 7205, loss = 53514.81724556\n",
            "Validation score: 0.746253\n",
            "Iteration 7206, loss = 53505.22510128\n",
            "Validation score: 0.746300\n",
            "Iteration 7207, loss = 53494.42715563\n",
            "Validation score: 0.746355\n",
            "Iteration 7208, loss = 53486.88501923\n",
            "Validation score: 0.746414\n",
            "Iteration 7209, loss = 53473.57899865\n",
            "Validation score: 0.746465\n",
            "Iteration 7210, loss = 53464.07948095\n",
            "Validation score: 0.746521\n",
            "Iteration 7211, loss = 53454.32558568\n",
            "Validation score: 0.746575\n",
            "Iteration 7212, loss = 53444.13217840\n",
            "Validation score: 0.746618\n",
            "Iteration 7213, loss = 53433.36678920\n",
            "Validation score: 0.746635\n",
            "Iteration 7214, loss = 53424.87980525\n",
            "Validation score: 0.746654\n",
            "Iteration 7215, loss = 53412.69956325\n",
            "Validation score: 0.746681\n",
            "Iteration 7216, loss = 53403.37215415\n",
            "Validation score: 0.746711\n",
            "Iteration 7217, loss = 53394.29191828\n",
            "Validation score: 0.746763\n",
            "Iteration 7218, loss = 53382.93345403\n",
            "Validation score: 0.746828\n",
            "Iteration 7219, loss = 53373.76801013\n",
            "Validation score: 0.746869\n",
            "Iteration 7220, loss = 53363.64102235\n",
            "Validation score: 0.746895\n",
            "Iteration 7221, loss = 53351.23071191\n",
            "Validation score: 0.746932\n",
            "Iteration 7222, loss = 53341.98002560\n",
            "Validation score: 0.746971\n",
            "Iteration 7223, loss = 53330.44030619\n",
            "Validation score: 0.747022\n",
            "Iteration 7224, loss = 53321.49907675\n",
            "Validation score: 0.747077\n",
            "Iteration 7225, loss = 53310.21080448\n",
            "Validation score: 0.747124\n",
            "Iteration 7226, loss = 53300.63673251\n",
            "Validation score: 0.747180\n",
            "Iteration 7227, loss = 53288.88715746\n",
            "Validation score: 0.747236\n",
            "Iteration 7228, loss = 53279.90211095\n",
            "Validation score: 0.747305\n",
            "Iteration 7229, loss = 53269.24982708\n",
            "Validation score: 0.747365\n",
            "Iteration 7230, loss = 53259.18156347\n",
            "Validation score: 0.747419\n",
            "Iteration 7231, loss = 53249.24053921\n",
            "Validation score: 0.747475\n",
            "Iteration 7232, loss = 53238.47966732\n",
            "Validation score: 0.747508\n",
            "Iteration 7233, loss = 53228.10556474\n",
            "Validation score: 0.747537\n",
            "Iteration 7234, loss = 53218.93680659\n",
            "Validation score: 0.747539\n",
            "Iteration 7235, loss = 53205.45177559\n",
            "Validation score: 0.747569\n",
            "Iteration 7236, loss = 53195.06679600\n",
            "Validation score: 0.747619\n",
            "Iteration 7237, loss = 53183.21196270\n",
            "Validation score: 0.747664\n",
            "Iteration 7238, loss = 53174.16084109\n",
            "Validation score: 0.747716\n",
            "Iteration 7239, loss = 53162.52519918\n",
            "Validation score: 0.747787\n",
            "Iteration 7240, loss = 53151.74227052\n",
            "Validation score: 0.747859\n",
            "Iteration 7241, loss = 53141.60461379\n",
            "Validation score: 0.747911\n",
            "Iteration 7242, loss = 53130.24563343\n",
            "Validation score: 0.747959\n",
            "Iteration 7243, loss = 53117.68439381\n",
            "Validation score: 0.748006\n",
            "Iteration 7244, loss = 53106.98631753\n",
            "Validation score: 0.748058\n",
            "Iteration 7245, loss = 53096.22616426\n",
            "Validation score: 0.748117\n",
            "Iteration 7246, loss = 53085.78157411\n",
            "Validation score: 0.748163\n",
            "Iteration 7247, loss = 53072.66711914\n",
            "Validation score: 0.748192\n",
            "Iteration 7248, loss = 53061.71461665\n",
            "Validation score: 0.748229\n",
            "Iteration 7249, loss = 53049.78420797\n",
            "Validation score: 0.748278\n",
            "Iteration 7250, loss = 53038.70563387\n",
            "Validation score: 0.748315\n",
            "Iteration 7251, loss = 53024.65161673\n",
            "Validation score: 0.748358\n",
            "Iteration 7252, loss = 53014.95912080\n",
            "Validation score: 0.748390\n",
            "Iteration 7253, loss = 53000.06225687\n",
            "Validation score: 0.748428\n",
            "Iteration 7254, loss = 52990.90942372\n",
            "Validation score: 0.748452\n",
            "Iteration 7255, loss = 52977.57694206\n",
            "Validation score: 0.748494\n",
            "Iteration 7256, loss = 52967.00426152\n",
            "Validation score: 0.748539\n",
            "Iteration 7257, loss = 52955.69484333\n",
            "Validation score: 0.748591\n",
            "Iteration 7258, loss = 52943.61102638\n",
            "Validation score: 0.748646\n",
            "Iteration 7259, loss = 52933.08816885\n",
            "Validation score: 0.748697\n",
            "Iteration 7260, loss = 52922.47923271\n",
            "Validation score: 0.748749\n",
            "Iteration 7261, loss = 52912.09635655\n",
            "Validation score: 0.748818\n",
            "Iteration 7262, loss = 52903.39071550\n",
            "Validation score: 0.748901\n",
            "Iteration 7263, loss = 52891.96265596\n",
            "Validation score: 0.748972\n",
            "Iteration 7264, loss = 52881.08025208\n",
            "Validation score: 0.749039\n",
            "Iteration 7265, loss = 52872.56259235\n",
            "Validation score: 0.749108\n",
            "Iteration 7266, loss = 52861.96021475\n",
            "Validation score: 0.749167\n",
            "Iteration 7267, loss = 52851.33923618\n",
            "Validation score: 0.749225\n",
            "Iteration 7268, loss = 52840.50947050\n",
            "Validation score: 0.749285\n",
            "Iteration 7269, loss = 52830.76687085\n",
            "Validation score: 0.749339\n",
            "Iteration 7270, loss = 52821.02064362\n",
            "Validation score: 0.749380\n",
            "Iteration 7271, loss = 52809.75189768\n",
            "Validation score: 0.749412\n",
            "Iteration 7272, loss = 52799.39059209\n",
            "Validation score: 0.749443\n",
            "Iteration 7273, loss = 52791.18973125\n",
            "Validation score: 0.749488\n",
            "Iteration 7274, loss = 52779.24788398\n",
            "Validation score: 0.749534\n",
            "Iteration 7275, loss = 52769.05665922\n",
            "Validation score: 0.749579\n",
            "Iteration 7276, loss = 52759.58142737\n",
            "Validation score: 0.749618\n",
            "Iteration 7277, loss = 52749.77588238\n",
            "Validation score: 0.749660\n",
            "Iteration 7278, loss = 52739.78201094\n",
            "Validation score: 0.749718\n",
            "Iteration 7279, loss = 52731.99153817\n",
            "Validation score: 0.749771\n",
            "Iteration 7280, loss = 52723.02405686\n",
            "Validation score: 0.749812\n",
            "Iteration 7281, loss = 52711.46550003\n",
            "Validation score: 0.749836\n",
            "Iteration 7282, loss = 52700.46996984\n",
            "Validation score: 0.749859\n",
            "Iteration 7283, loss = 52693.20111623\n",
            "Validation score: 0.749870\n",
            "Iteration 7284, loss = 52684.05851789\n",
            "Validation score: 0.749899\n",
            "Iteration 7285, loss = 52670.54578084\n",
            "Validation score: 0.749948\n",
            "Iteration 7286, loss = 52662.11693020\n",
            "Validation score: 0.749992\n",
            "Iteration 7287, loss = 52650.77063323\n",
            "Validation score: 0.750038\n",
            "Iteration 7288, loss = 52641.71943164\n",
            "Validation score: 0.750100\n",
            "Iteration 7289, loss = 52629.76715249\n",
            "Validation score: 0.750155\n",
            "Iteration 7290, loss = 52619.69257547\n",
            "Validation score: 0.750219\n",
            "Iteration 7291, loss = 52609.68441810\n",
            "Validation score: 0.750280\n",
            "Iteration 7292, loss = 52601.49914561\n",
            "Validation score: 0.750337\n",
            "Iteration 7293, loss = 52594.85745217\n",
            "Validation score: 0.750393\n",
            "Iteration 7294, loss = 52585.83884592\n",
            "Validation score: 0.750443\n",
            "Iteration 7295, loss = 52575.24552343\n",
            "Validation score: 0.750491\n",
            "Iteration 7296, loss = 52568.54910903\n",
            "Validation score: 0.750541\n",
            "Iteration 7297, loss = 52558.46718898\n",
            "Validation score: 0.750575\n",
            "Iteration 7298, loss = 52550.13029578\n",
            "Validation score: 0.750606\n",
            "Iteration 7299, loss = 52539.04772808\n",
            "Validation score: 0.750640\n",
            "Iteration 7300, loss = 52531.32312591\n",
            "Validation score: 0.750680\n",
            "Iteration 7301, loss = 52522.00143330\n",
            "Validation score: 0.750720\n",
            "Iteration 7302, loss = 52510.90977416\n",
            "Validation score: 0.750767\n",
            "Iteration 7303, loss = 52502.67373450\n",
            "Validation score: 0.750812\n",
            "Iteration 7304, loss = 52489.80165403\n",
            "Validation score: 0.750849\n",
            "Iteration 7305, loss = 52482.65442511\n",
            "Validation score: 0.750881\n",
            "Iteration 7306, loss = 52469.18393828\n",
            "Validation score: 0.750931\n",
            "Iteration 7307, loss = 52458.47138211\n",
            "Validation score: 0.750969\n",
            "Iteration 7308, loss = 52449.00935251\n",
            "Validation score: 0.750986\n",
            "Iteration 7309, loss = 52438.82399552\n",
            "Validation score: 0.751003\n",
            "Iteration 7310, loss = 52428.60187175\n",
            "Validation score: 0.751021\n",
            "Iteration 7311, loss = 52422.44898814\n",
            "Validation score: 0.751028\n",
            "Iteration 7312, loss = 52409.91696361\n",
            "Validation score: 0.751056\n",
            "Iteration 7313, loss = 52398.66715198\n",
            "Validation score: 0.751103\n",
            "Iteration 7314, loss = 52391.15055247\n",
            "Validation score: 0.751162\n",
            "Iteration 7315, loss = 52381.77289974\n",
            "Validation score: 0.751205\n",
            "Iteration 7316, loss = 52368.55284676\n",
            "Validation score: 0.751255\n",
            "Iteration 7317, loss = 52359.81632200\n",
            "Validation score: 0.751304\n",
            "Iteration 7318, loss = 52348.58256035\n",
            "Validation score: 0.751357\n",
            "Iteration 7319, loss = 52338.65039345\n",
            "Validation score: 0.751405\n",
            "Iteration 7320, loss = 52328.64517629\n",
            "Validation score: 0.751456\n",
            "Iteration 7321, loss = 52319.81678456\n",
            "Validation score: 0.751504\n",
            "Iteration 7322, loss = 52309.23091942\n",
            "Validation score: 0.751538\n",
            "Iteration 7323, loss = 52295.77512605\n",
            "Validation score: 0.751551\n",
            "Iteration 7324, loss = 52288.47712484\n",
            "Validation score: 0.751556\n",
            "Iteration 7325, loss = 52275.44067704\n",
            "Validation score: 0.751573\n",
            "Iteration 7326, loss = 52265.72522278\n",
            "Validation score: 0.751581\n",
            "Iteration 7327, loss = 52254.76506311\n",
            "Validation score: 0.751603\n",
            "Iteration 7328, loss = 52246.26232783\n",
            "Validation score: 0.751628\n",
            "Iteration 7329, loss = 52237.60978919\n",
            "Validation score: 0.751655\n",
            "Iteration 7330, loss = 52223.90308582\n",
            "Validation score: 0.751691\n",
            "Iteration 7331, loss = 52214.20090816\n",
            "Validation score: 0.751741\n",
            "Iteration 7332, loss = 52203.32301507\n",
            "Validation score: 0.751793\n",
            "Iteration 7333, loss = 52193.87370128\n",
            "Validation score: 0.751855\n",
            "Iteration 7334, loss = 52183.07514443\n",
            "Validation score: 0.751896\n",
            "Iteration 7335, loss = 52173.51662883\n",
            "Validation score: 0.751933\n",
            "Iteration 7336, loss = 52162.34943052\n",
            "Validation score: 0.751982\n",
            "Iteration 7337, loss = 52152.91815993\n",
            "Validation score: 0.752046\n",
            "Iteration 7338, loss = 52143.77854934\n",
            "Validation score: 0.752105\n",
            "Iteration 7339, loss = 52134.38621626\n",
            "Validation score: 0.752150\n",
            "Iteration 7340, loss = 52124.17325739\n",
            "Validation score: 0.752194\n",
            "Iteration 7341, loss = 52114.46442627\n",
            "Validation score: 0.752238\n",
            "Iteration 7342, loss = 52104.46313315\n",
            "Validation score: 0.752289\n",
            "Iteration 7343, loss = 52095.29760337\n",
            "Validation score: 0.752327\n",
            "Iteration 7344, loss = 52085.72538937\n",
            "Validation score: 0.752358\n",
            "Iteration 7345, loss = 52075.42426963\n",
            "Validation score: 0.752401\n",
            "Iteration 7346, loss = 52066.01277429\n",
            "Validation score: 0.752434\n",
            "Iteration 7347, loss = 52056.62559030\n",
            "Validation score: 0.752476\n",
            "Iteration 7348, loss = 52046.25257763\n",
            "Validation score: 0.752514\n",
            "Iteration 7349, loss = 52036.53323279\n",
            "Validation score: 0.752560\n",
            "Iteration 7350, loss = 52028.24871675\n",
            "Validation score: 0.752641\n",
            "Iteration 7351, loss = 52018.01407241\n",
            "Validation score: 0.752720\n",
            "Iteration 7352, loss = 52007.55236492\n",
            "Validation score: 0.752782\n",
            "Iteration 7353, loss = 51998.73764356\n",
            "Validation score: 0.752836\n",
            "Iteration 7354, loss = 51989.33908534\n",
            "Validation score: 0.752888\n",
            "Iteration 7355, loss = 51981.35914373\n",
            "Validation score: 0.752929\n",
            "Iteration 7356, loss = 51970.78511972\n",
            "Validation score: 0.752968\n",
            "Iteration 7357, loss = 51962.65670883\n",
            "Validation score: 0.752998\n",
            "Iteration 7358, loss = 51951.00976889\n",
            "Validation score: 0.753047\n",
            "Iteration 7359, loss = 51941.51013633\n",
            "Validation score: 0.753094\n",
            "Iteration 7360, loss = 51931.73599399\n",
            "Validation score: 0.753154\n",
            "Iteration 7361, loss = 51921.10519859\n",
            "Validation score: 0.753205\n",
            "Iteration 7362, loss = 51910.68337052\n",
            "Validation score: 0.753255\n",
            "Iteration 7363, loss = 51901.03828263\n",
            "Validation score: 0.753318\n",
            "Iteration 7364, loss = 51892.14625264\n",
            "Validation score: 0.753373\n",
            "Iteration 7365, loss = 51880.33968261\n",
            "Validation score: 0.753414\n",
            "Iteration 7366, loss = 51870.50910991\n",
            "Validation score: 0.753449\n",
            "Iteration 7367, loss = 51860.33514054\n",
            "Validation score: 0.753493\n",
            "Iteration 7368, loss = 51849.33601335\n",
            "Validation score: 0.753543\n",
            "Iteration 7369, loss = 51838.21536132\n",
            "Validation score: 0.753588\n",
            "Iteration 7370, loss = 51830.89159513\n",
            "Validation score: 0.753639\n",
            "Iteration 7371, loss = 51818.50452350\n",
            "Validation score: 0.753697\n",
            "Iteration 7372, loss = 51808.10026653\n",
            "Validation score: 0.753744\n",
            "Iteration 7373, loss = 51798.95448997\n",
            "Validation score: 0.753782\n",
            "Iteration 7374, loss = 51788.38889317\n",
            "Validation score: 0.753821\n",
            "Iteration 7375, loss = 51779.77683013\n",
            "Validation score: 0.753850\n",
            "Iteration 7376, loss = 51768.97966054\n",
            "Validation score: 0.753890\n",
            "Iteration 7377, loss = 51758.28278863\n",
            "Validation score: 0.753932\n",
            "Iteration 7378, loss = 51749.01208632\n",
            "Validation score: 0.753974\n",
            "Iteration 7379, loss = 51740.62833661\n",
            "Validation score: 0.753999\n",
            "Iteration 7380, loss = 51727.84923865\n",
            "Validation score: 0.754023\n",
            "Iteration 7381, loss = 51722.06779783\n",
            "Validation score: 0.754071\n",
            "Iteration 7382, loss = 51710.39996598\n",
            "Validation score: 0.754123\n",
            "Iteration 7383, loss = 51704.09966643\n",
            "Validation score: 0.754185\n",
            "Iteration 7384, loss = 51696.53202491\n",
            "Validation score: 0.754231\n",
            "Iteration 7385, loss = 51688.64207917\n",
            "Validation score: 0.754276\n",
            "Iteration 7386, loss = 51677.01490154\n",
            "Validation score: 0.754312\n",
            "Iteration 7387, loss = 51669.37962456\n",
            "Validation score: 0.754338\n",
            "Iteration 7388, loss = 51657.75358835\n",
            "Validation score: 0.754371\n",
            "Iteration 7389, loss = 51649.50928007\n",
            "Validation score: 0.754398\n",
            "Iteration 7390, loss = 51637.76172563\n",
            "Validation score: 0.754449\n",
            "Iteration 7391, loss = 51627.79744105\n",
            "Validation score: 0.754507\n",
            "Iteration 7392, loss = 51621.27406638\n",
            "Validation score: 0.754568\n",
            "Iteration 7393, loss = 51614.72749892\n",
            "Validation score: 0.754638\n",
            "Iteration 7394, loss = 51604.28942845\n",
            "Validation score: 0.754672\n",
            "Iteration 7395, loss = 51595.49720817\n",
            "Validation score: 0.754712\n",
            "Iteration 7396, loss = 51586.29749213\n",
            "Validation score: 0.754746\n",
            "Iteration 7397, loss = 51578.87869758\n",
            "Validation score: 0.754789\n",
            "Iteration 7398, loss = 51567.10999323\n",
            "Validation score: 0.754826\n",
            "Iteration 7399, loss = 51558.61193086\n",
            "Validation score: 0.754867\n",
            "Iteration 7400, loss = 51547.01619417\n",
            "Validation score: 0.754907\n",
            "Iteration 7401, loss = 51536.36637347\n",
            "Validation score: 0.754952\n",
            "Iteration 7402, loss = 51528.87155182\n",
            "Validation score: 0.755013\n",
            "Iteration 7403, loss = 51518.25436726\n",
            "Validation score: 0.755070\n",
            "Iteration 7404, loss = 51511.59959279\n",
            "Validation score: 0.755123\n",
            "Iteration 7405, loss = 51501.65507317\n",
            "Validation score: 0.755168\n",
            "Iteration 7406, loss = 51492.28144553\n",
            "Validation score: 0.755223\n",
            "Iteration 7407, loss = 51484.03304772\n",
            "Validation score: 0.755281\n",
            "Iteration 7408, loss = 51474.49695112\n",
            "Validation score: 0.755336\n",
            "Iteration 7409, loss = 51464.41713631\n",
            "Validation score: 0.755384\n",
            "Iteration 7410, loss = 51453.75096760\n",
            "Validation score: 0.755414\n",
            "Iteration 7411, loss = 51443.83921006\n",
            "Validation score: 0.755439\n",
            "Iteration 7412, loss = 51436.31720703\n",
            "Validation score: 0.755444\n",
            "Iteration 7413, loss = 51423.75975042\n",
            "Validation score: 0.755478\n",
            "Iteration 7414, loss = 51414.75491903\n",
            "Validation score: 0.755516\n",
            "Iteration 7415, loss = 51405.61621269\n",
            "Validation score: 0.755540\n",
            "Iteration 7416, loss = 51397.01476435\n",
            "Validation score: 0.755569\n",
            "Iteration 7417, loss = 51386.88304084\n",
            "Validation score: 0.755601\n",
            "Iteration 7418, loss = 51378.76719583\n",
            "Validation score: 0.755625\n",
            "Iteration 7419, loss = 51370.47848199\n",
            "Validation score: 0.755652\n",
            "Iteration 7420, loss = 51360.61621618\n",
            "Validation score: 0.755692\n",
            "Iteration 7421, loss = 51350.47695213\n",
            "Validation score: 0.755735\n",
            "Iteration 7422, loss = 51341.60993713\n",
            "Validation score: 0.755792\n",
            "Iteration 7423, loss = 51331.92508870\n",
            "Validation score: 0.755829\n",
            "Iteration 7424, loss = 51322.62278637\n",
            "Validation score: 0.755874\n",
            "Iteration 7425, loss = 51314.52268964\n",
            "Validation score: 0.755910\n",
            "Iteration 7426, loss = 51303.67650872\n",
            "Validation score: 0.755959\n",
            "Iteration 7427, loss = 51294.23396411\n",
            "Validation score: 0.756004\n",
            "Iteration 7428, loss = 51283.33576865\n",
            "Validation score: 0.756056\n",
            "Iteration 7429, loss = 51274.13316088\n",
            "Validation score: 0.756089\n",
            "Iteration 7430, loss = 51260.27492986\n",
            "Validation score: 0.756107\n",
            "Iteration 7431, loss = 51250.21206430\n",
            "Validation score: 0.756122\n",
            "Iteration 7432, loss = 51243.49553590\n",
            "Validation score: 0.756151\n",
            "Iteration 7433, loss = 51230.61186770\n",
            "Validation score: 0.756209\n",
            "Iteration 7434, loss = 51221.18742889\n",
            "Validation score: 0.756264\n",
            "Iteration 7435, loss = 51210.50454015\n",
            "Validation score: 0.756310\n",
            "Iteration 7436, loss = 51202.24635745\n",
            "Validation score: 0.756351\n",
            "Iteration 7437, loss = 51193.81528729\n",
            "Validation score: 0.756386\n",
            "Iteration 7438, loss = 51183.52615161\n",
            "Validation score: 0.756415\n",
            "Iteration 7439, loss = 51175.77187354\n",
            "Validation score: 0.756438\n",
            "Iteration 7440, loss = 51167.48566290\n",
            "Validation score: 0.756444\n",
            "Iteration 7441, loss = 51155.85580025\n",
            "Validation score: 0.756455\n",
            "Iteration 7442, loss = 51147.90568766\n",
            "Validation score: 0.756466\n",
            "Iteration 7443, loss = 51135.85055146\n",
            "Validation score: 0.756479\n",
            "Iteration 7444, loss = 51128.80853871\n",
            "Validation score: 0.756491\n",
            "Iteration 7445, loss = 51119.42275844\n",
            "Validation score: 0.756513\n",
            "Iteration 7446, loss = 51109.53035849\n",
            "Validation score: 0.756551\n",
            "Iteration 7447, loss = 51099.79041157\n",
            "Validation score: 0.756588\n",
            "Iteration 7448, loss = 51090.14533822\n",
            "Validation score: 0.756603\n",
            "Iteration 7449, loss = 51080.76161151\n",
            "Validation score: 0.756633\n",
            "Iteration 7450, loss = 51073.10479469\n",
            "Validation score: 0.756654\n",
            "Iteration 7451, loss = 51062.31255022\n",
            "Validation score: 0.756650\n",
            "Iteration 7452, loss = 51051.25417860\n",
            "Validation score: 0.756643\n",
            "Iteration 7453, loss = 51043.79001352\n",
            "Validation score: 0.756639\n",
            "Iteration 7454, loss = 51034.78036969\n",
            "Validation score: 0.756655\n",
            "Iteration 7455, loss = 51027.70533441\n",
            "Validation score: 0.756682\n",
            "Iteration 7456, loss = 51017.18574571\n",
            "Validation score: 0.756721\n",
            "Iteration 7457, loss = 51009.05111863\n",
            "Validation score: 0.756756\n",
            "Iteration 7458, loss = 50999.47876472\n",
            "Validation score: 0.756790\n",
            "Iteration 7459, loss = 50991.99675563\n",
            "Validation score: 0.756832\n",
            "Iteration 7460, loss = 50983.52365139\n",
            "Validation score: 0.756880\n",
            "Iteration 7461, loss = 50975.34722494\n",
            "Validation score: 0.756942\n",
            "Iteration 7462, loss = 50966.20985082\n",
            "Validation score: 0.756986\n",
            "Iteration 7463, loss = 50957.98583899\n",
            "Validation score: 0.757041\n",
            "Iteration 7464, loss = 50948.93997959\n",
            "Validation score: 0.757084\n",
            "Iteration 7465, loss = 50940.93861376\n",
            "Validation score: 0.757144\n",
            "Iteration 7466, loss = 50929.27894694\n",
            "Validation score: 0.757191\n",
            "Iteration 7467, loss = 50921.19092621\n",
            "Validation score: 0.757223\n",
            "Iteration 7468, loss = 50909.74035668\n",
            "Validation score: 0.757266\n",
            "Iteration 7469, loss = 50901.59101347\n",
            "Validation score: 0.757293\n",
            "Iteration 7470, loss = 50892.23167635\n",
            "Validation score: 0.757324\n",
            "Iteration 7471, loss = 50880.53692585\n",
            "Validation score: 0.757351\n",
            "Iteration 7472, loss = 50872.88950865\n",
            "Validation score: 0.757386\n",
            "Iteration 7473, loss = 50863.40011553\n",
            "Validation score: 0.757428\n",
            "Iteration 7474, loss = 50852.57745049\n",
            "Validation score: 0.757476\n",
            "Iteration 7475, loss = 50842.85240748\n",
            "Validation score: 0.757543\n",
            "Iteration 7476, loss = 50835.85487192\n",
            "Validation score: 0.757603\n",
            "Iteration 7477, loss = 50825.17005537\n",
            "Validation score: 0.757657\n",
            "Iteration 7478, loss = 50815.95722453\n",
            "Validation score: 0.757727\n",
            "Iteration 7479, loss = 50807.71032874\n",
            "Validation score: 0.757790\n",
            "Iteration 7480, loss = 50799.14603743\n",
            "Validation score: 0.757842\n",
            "Iteration 7481, loss = 50789.79994080\n",
            "Validation score: 0.757891\n",
            "Iteration 7482, loss = 50781.94901461\n",
            "Validation score: 0.757948\n",
            "Iteration 7483, loss = 50772.22849141\n",
            "Validation score: 0.758009\n",
            "Iteration 7484, loss = 50765.95377135\n",
            "Validation score: 0.758064\n",
            "Iteration 7485, loss = 50755.65681183\n",
            "Validation score: 0.758091\n",
            "Iteration 7486, loss = 50745.12965870\n",
            "Validation score: 0.758108\n",
            "Iteration 7487, loss = 50734.19736643\n",
            "Validation score: 0.758101\n",
            "Iteration 7488, loss = 50724.67718538\n",
            "Validation score: 0.758098\n",
            "Iteration 7489, loss = 50717.18769133\n",
            "Validation score: 0.758074\n",
            "Iteration 7490, loss = 50706.05441404\n",
            "Validation score: 0.758054\n",
            "Iteration 7491, loss = 50695.15585536\n",
            "Validation score: 0.758059\n",
            "Iteration 7492, loss = 50687.34177033\n",
            "Validation score: 0.758058\n",
            "Iteration 7493, loss = 50679.82286984\n",
            "Validation score: 0.758046\n",
            "Iteration 7494, loss = 50669.57578594\n",
            "Validation score: 0.758057\n",
            "Iteration 7495, loss = 50661.68820804\n",
            "Validation score: 0.758069\n",
            "Iteration 7496, loss = 50654.20498527\n",
            "Validation score: 0.758078\n",
            "Iteration 7497, loss = 50644.48267565\n",
            "Validation score: 0.758102\n",
            "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing Training Loss \n",
        "training_loss = nn.loss_curve_\n",
        "\n",
        "# Plotting Training Loss on each iteration\n",
        "plt.plot([(i+1) for i in range(len(training_loss))], training_loss)\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "\n",
        "# Calculating R2 Score for our predictions\n",
        "r2_score = r2_score(Y_test , Y_pred)\n",
        "\n",
        "print(\"=============================\")\n",
        "print(\"R2 Score -->\" + str(r2_score))\n",
        "print(\"=============================\")\n",
        "print(\"Training loss curve-->\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "kVpE0s-8QSz5",
        "outputId": "d80ae228-b2b5-4f93-dde2-461e9bc12285"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================\n",
            "R2 Score -->0.779450306789784\n",
            "=============================\n",
            "Training loss curve-->\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEQCAYAAAD2/KAsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVzU1f748dewj+wOMwOogCGuWa6AZItLmVoZV22zW2KKppV6w6Vbt7zmVdGuaWneb1fJfjfrlqShdV0qcCcG2zQxpQxywWEdkR2G+f1BjI6gjggOy/v5ePDQ+Zwzn8/bI/Ce8/mcRWEwGEwIIYQQN5mdrQMQQgjRNkkCEkIIYROSgIQQQtiEJCAhhBA2IQlICCGETUgCEkIIYROSgIQQQtiEJCAhhBA2IQmomUlPT7d1CC2StFvDSds1jLTbjZMEJIQQwiYkAQkhhLAJSUBCCCFsQhKQEEIIm5AEJIQQwiYkATVDFUbZIUMI0fpJAmpGTCYTO3Ps6RN/juOGSluHI4QQTUoSUDNxrsTIhMR8XjnuzNmSap7bX4CxWnpCQojWSxJQM3HgXDn/+73M/Do1p5JPfyu1YURCCNG0JAE1E3/qrGRUgIvFsRWHL1Btkl6QEKJ1kgTUTCgUChYN9MSOiwnnZ0MVSWfLbRiVEEI0HUlAzcgtHg7cqzZaHNuYXmKjaIQQomlJAmpm/uRbZfH688xSCsqrbRSNEEI0HUlAzUxfj2o6u9ubX1dUw6cnpRckhGh9JAE1MwoFTAhxtTj28a+SgIQQrY9NE9C5c+eYNm0awcHBaLVawsLC2L9/v7ncZDKxZMkSunfvjq+vL6NHj+bYsWMW5zAYDERHRxMQEEBAQADR0dEYDAaLOkePHmXUqFH4+vrSo0cPYmNjMV02uiwhIYGwsDA0Gg1hYWFs27bNotyaWBrL+FuUFq9Tcyo5WVh1hdpCCNEy2SwBGQwGRowYgclk4pNPPiElJYVly5ahVqvNdVatWsWaNWuIjY0lMTERtVpNZGQkFy5cMNeZPHkyhw8fJj4+nvj4eA4fPszUqVPN5YWFhURGRqLRaEhMTGTp0qW8/fbbrF692lxHp9MxadIkxo8fz759+xg/fjwTJ07k0KFD1xVLYwl0dyBC62RxTHpBQojWRmEwGGwy0WThwoUcOHCAnTt31ltuMpno3r07U6ZMISYmBoDS0lJCQkJ4/fXXiYqK4vjx44SFhbFjxw7Cw8MBSE5OZuTIkaSmphISEsL69etZsGABJ06cQKms6VksX76cuLg40tLSUCgUREVFUVBQwGeffWa+/pgxY/Dx8WH9+vVWxdJY0tPTCQkJ4f3jxcw8eLEn19ndnu/GalEoFI12rdaktt3E9ZO2axhptxtnsx7QF198Qf/+/YmKiqJLly4MHjyYd99913xrLDMzE71ez9ChQ83vUSqVREREkJKSAtT0XNzc3AgLCzPXCQ8Px9XV1aLOoEGDzMkHYNiwYWRlZZGZmQlAamqqxXVq69Sew5pYGtuYICVOl/zv/HbBSGpORZNcSwghbMHBVhfOyMhg/fr1TJ8+nVmzZnHkyBHmzZsHQHR0NHq9HsDillzt66ysLACys7NRqVQWvQKFQoGPjw/Z2dnmOv7+/nXOUVsWFBSEXq+v9zq157Amlvo0dM/42vcN9nYiMe/if9H/fZuFdxdZpPRKGtreQtquoaTdru5aPUSbJaDq6mr69u3La6+9BsDtt9/OyZMnWbduHdHR0bYKq1E1pHt+abf+GadSEhPzzWWJBU6svSUQJ3u5DXc5uR3ScNJ2DSPtduNsdgtOq9XSrVs3i2Ndu3bl9OnT5nKAnJwcizo5OTloNBoANBoNeXl5FiPaTCYTubm5FnXqO0dtWe21rnYda2JpCvd2dMHb+WKyKSg38eXpsqu8QwghWg6bJaDw8HB++eUXi2O//PILnTp1AiAwMBCtVktSUpK5vKysjOTkZPMzn9DQUIqKitDpdOY6Op2O4uJiizrJycmUlV38xZ2UlISfnx+BgYEADBw40OI6tXVqz2FNLE3ByV7Bnzq3szj2iUxKFUK0Evbz589fYIsLd+zYkdjYWOzs7PD19WXPnj0sWrSI2bNn079/fxQKBUajkZUrVxIcHIzRaOTll19Gr9ezcuVKnJ2d8fHx4dChQ8THx9O7d2/OnDnD7Nmz6devn3kodnBwMO+99x5HjhwhJCSE5ORkXn31VWbNmmVOHn5+fixevBgnJydUKhXvv/8+GzduZNWqVfj7+1sVS2PJz89HpVKZX3s7K/jPJevBZVyoYkp3N1wc5DbcpS5vN2E9abuGkXa7cTZ7BtSvXz82btzIwoULWb58OR07duSvf/0rkydPNteZOXMmpaWlzJkzB4PBQP/+/dm8eTPu7u7mOuvWrWPu3LmMHTsWgJEjR7Js2TJzuaenJ1u2bCEmJoYhQ4bg5eXFjBkzeO6558x1wsLCiIuLY9GiRSxevJjOnTsTFxfHgAEDriuWpjBQ7URnd3t+u1CzSGm5ERIySnm6m+s13imEEM2bzeYBifrV92BzyfeFxP5wccJrqNqJXQ+oL39rmyYPhBtO2q5hpN1unKwF1wI8Gmz5HEiXU8EPuTInSAjRskkCagFu8XBgiL/lc6Z1PxfbKBohhGgckoBaiCk9LJ/5xJ8sIb/MeIXaQgjR/EkCaiFGdHQhwO3iPkFlRixGxwkhREsjCaiFsLdTMLm7ZS9o3c/FGKtlDIkQomWSBNSCPBnSDpeLnSBOFRnZKSsjCCFaKElALUh7F3vG3WI5Iu6do0U2ikYIIW6MJKAW5vLBCPvPVfCtbNMghGiBJAG1MLernLjLz3JI9sojjb8rqxBCNDVJQC3QrN5uFq8/zywj/bzsEySEaFkkAbVAQ/yd6d3e0fzaBLz9kzwLEkK0LJKAWiCFQsHMy3pB//2lhKwSmZgqhGg5JAG1UA8HKQm8ZGJqRTW8Jc+ChBAtiCSgFsrBTsELl/WC3jtezDnpBQkhWghJQC3YkyGu+Le7+F9YZoS3fpJekBCiZZAE1II52yuY1dtyQ7z3fi4hu1R6QUKI5k8SUAv3VFdX/C7pBZUaTbx1REbECSGaP0lALZyLQ91e0Pqfi6UXJIRo9iQBtQJPd3XFV2nZC/rnj/IsSAjRvEkCagVcHBTMus2yFxR3vJiMC1U2ikgIIa5NElArEdXNlU6XzAuqrIZ/fFdow4iEEOLqJAG1Es72Cl7u62FxbNPJUn7Mk5WyhRDNkySgVmT8LUp6eTtYHFv4rfSChBDNk80S0JIlS/Dy8rL46tq1q7ncZDKxZMkSunfvjq+vL6NHj+bYsWMW5zAYDERHRxMQEEBAQADR0dEYDAaLOkePHmXUqFH4+vrSo0cPYmNjMZkst7FOSEggLCwMjUZDWFgY27Ztsyi3JpbmwN5OwYIBnhbHvj5Tzp6z5TaKSAghrsymPaCQkBCOHz9u/jp48KC5bNWqVaxZs4bY2FgSExNRq9VERkZy4cLF0V2TJ0/m8OHDxMfHEx8fz+HDh5k6daq5vLCwkMjISDQaDYmJiSxdupS3336b1atXm+vodDomTZrE+PHj2bdvH+PHj2fixIkcOnToumJpLoZ3cOYOXyeLYwu+PV8n6QohhK3ZNAE5ODig1WrNXz4+PkBNj2Pt2rXMmjWLMWPG0LNnT9auXUtRURHx8fEAHD9+nK+++oqVK1cSGhpKaGgob775Jjt37iQ9PR2ATZs2UVpaytq1a+nZsydjxoxh5syZvPPOO+ZfyGvXruXOO+8kJiaGbt26ERMTw+DBg1m7dq3VsTQnCoWCv1/WC/o+t5KEjDIbRSSEEPWzaQLKyMige/fu3HbbbUyaNImMjAwAMjMz0ev1DB061FxXqVQSERFBSkoKUNNzcXNzIywszFwnPDwcV1dXizqDBg1CqVSa6wwbNoysrCwyMzMBSE1NtbhObZ3ac1gTS3MzQO3EQ4EuFscWfHuecqP0goQQzYfDtatcnU6n4/z580RERODq6mr1+wYMGMA777xDSEgIubm5LF++nPvuu49vvvkGvV4PgFqttniPWq0mKysLgOzsbFQqFQqFwlyuUCjw8fEhOzvbXMff37/OOWrLgoKC0Ov19V6n9hzWxHIltT2x69XQ913qzyoFX2S6YKSmfTIuGFm4J4OJnVrv3KDGaLe2StquYaTdri4kJOSq5VYnoOXLl5OSkmJx2+nxxx9n586dAPj5+bF9+3YCAgKsOt+9995r8XrAgAH06dOHDz/8kIEDB1obVrN2rcavT3p6eoPeV+faQFSJgXU/F5uPbTjjzIywAPxd7a/8xhaqsdqtLZK2axhptxtn9S24+Ph4unXrZn69fft2duzYwcyZM1m3bh0VFRUsW7aswYG4ubnRvXt3Tp48iVarBSAnJ8eiTk5ODhqNBgCNRkNeXp7Fw3WTyURubq5FnfrOUVsGoNVqr3oda2Jprv7a1x1v54s9xOIqEwu+PW/DiIQQ4iKrE9DZs2ctsv3WrVsJDg7mtdde409/+hOTJ09mz549DQ6krKyM9PR0tFotgYGBaLVakpKSLMqTk5PNz3xCQ0MpKipCp9OZ6+h0OoqLiy3qJCcnU1Z28QF8UlISfn5+BAYGAjBw4ECL69TWqT2HNbE0V+1d7OtMTv3k11JS9DIsWwhhe1YnIIVCgdF4cYXlPXv2MGzYMPNrf3//Or2Eq3nllVfYv38/GRkZHDp0iKeffpqSkhIef/xxFAoFzz77LKtWrWLr1q2kpaUxffp0XF1dGTduHADdunVj+PDhzJ49G51Oh06nY/bs2YwYMcKcKMeNG4dSqWT69OmkpaWxdetWVq5cyfTp083PjqZNm8bevXt58803OXHiBCtWrGDfvn08++yz5n/3tWJpziZ2c60zOXVeynmqZVi2EMLGrH4G1KVLF7744gueeeYZvvrqK86dO2fxHOfMmTN4eXlZfeGzZ88yefJk8vLy8PHxYcCAAXz55ZfmZ0gzZ86ktLSUOXPmYDAY6N+/P5s3b8bd/eKim+vWrWPu3LmMHTsWgJEjR1rcBvT09GTLli3ExMQwZMgQvLy8mDFjBs8995y5TlhYGHFxcSxatIjFixfTuXNn4uLiGDBggLmONbE0Vw52CmLDvXhge6752A95lXyQXsJTXa0fNCKEEI1NYTAYrPoovGXLFp555hnc3d0pKSkhJCSEvXv34uBQk8NGjhyJu7s7n3zySZMG3No11YPNqKR8tmSUml+rnO1I/ZOG9i6tY0CCPBBuOGm7hpF2u3FW94AiIyPx9vZm165deHh4MHnyZHPyKSgoQKVS8eijjzZZoOLGLBzowY5TZZT+MRcor7yav39byKo7vG0cmRCirbqueUD33HMP99xzT53j3t7efPDBB40Vk2gCndwcePF2dxZdskXD+ydKeKJLO8K0zjaMTAjRVlk9CKG8vJyCggKLY3l5eaxYsYLXXnuN77//vtGDE43r+Vvd6Opp+ZljdrKBymoZkCCEuPmsTkAvvPACDz/8sPl1SUkJw4cP5/XXX+ett94yr2Igmi9newVvDLIcKJJWUMW/jhbZKCIhRFtmdQI6ePAgI0eONL+Oj48nIyOD+Ph4jh8/Trdu3XjjjTeaJEjReO7yc+bRYKXFsSU/XCBTtu8WQtxkViegnJwcOnToYH79v//9j9DQUIYNG4ZGo2HChAkcPny4SYIUjWvRQE88nS6ukFBSZWL2QYNs2SCEuKmsTkBubm7mzd6qqqo4ePCgxYAEpVLZLPfHEXWplfYsvGzLhsSz5fz319IrvEMIIRqf1Qmob9++/Oc//+HHH3/kjTfeoKioiPvvv99c/ttvvzX7tdHERX/u2q7OxnV/1RnIKTVe4R1CCNG4rE5Ar7zyCrm5uQwZMoTY2FjGjBlD3759zeWff/55s18bTVxkp1DwVoQ3l85DLSg3MS9FFisVQtwcVs8Duv3220lNTSUlJQUPDw8GDx5sLjMYDEyePJk77rijSYIUTSPY04H5fTxY8O3FuUGbfytlTFApY4KUV3mnEELcuOuaiKpSqRg1alSd415eXubFO0XL8tytbmz+rZTD+ZXmY7MPGhikdUKjbB3L9Aghmqfr3hF1165d7Nq1i99//x2AgIAA7r//foYPH97owYmm52Cn4J07vRmyLZvK6ppj+eXVzDxg4MNh7S12nBVCiMZk9TOgsrIyHn30UR577DE2bNhAWloaaWlpbNiwgUceeYRHH32U8nLZZ6YlurW9Iy9dtm/Q9lNlfPhLiY0iEkK0BVYnoCVLlrBr1y7mzp3LyZMn+emnn/jpp5/47bffmD9/Pl9++SVLly5tylhFE3rhVjcGqh0tjr2Ucp5TRTJBVQjRNKxOQJ9++ilPPvkk8+fPx8Pj4qdld3d35s6dy4QJE9i0aVOTBCmanoOdgrV3eqO0v3jLrbDSxIz9Btm8TgjRJK5rJYRLh11frk+fPte1I6pofrp4OrJggOWtuL1Z5fwrrdhGEQkhWjOrE1CHDh3Yu3fvFcv37t1rsVSPaJmm9HDlLj/L7RleO3SeH3IrbBSREKK1sjoBPfHEEyQkJPD8889z7NgxKisrqays5NixY7zwwgts27aNJ598siljFTeBnULBmsFeeFyyVlxlNUTtzqewotqGkQkhWhurh2H/5S9/ITMzkw8++ICNGzeah+eaTCZMJhN//vOfmTVrVpMFKm6eTm4OvH2HN08n5ZuP/XbByIvJBt69y1uGZgshGoXVCcjOzo63336badOmsWvXLk6dOgVAp06duO++++jVq1eTBSluvjFBSiZ1cyXu+MXnP5tOlnK3vzNPhrjaMDIhRGtx3RNRe/XqVW+y+fzzz/nss89Yt25dowQmbO8foZ58k11OWsHFodhzvznPQLUT3bwcr/JOIYS4NqufAV3Lzz//zObNmxvrdKIZUDooeO+e9rRzsNw7KGp3PqVVMjRbCHFjGi0Bidapm5cjy8It9w5KK6jiZZ2smi2EuDHNJgGtWLECLy8v5syZYz5mMplYsmQJ3bt3x9fXl9GjR3Ps2DGL9xkMBqKjowkICCAgIIDo6Gjzxnm1jh49yqhRo/D19aVHjx7ExsbW2f0zISGBsLAwNBoNYWFhbNu2zaLcmlhaqwld2jH+FsvVseOOF/NhuswPEkI0XLNIQKmpqWzYsKHOs6VVq1axZs0aYmNjSUxMRK1WExkZabHz6uTJkzl8+DDx8fHEx8dz+PBhpk6dai4vLCwkMjISjUZDYmIiS5cu5e2332b16tXmOjqdjkmTJjF+/Hj27dvH+PHjmThxIocOHbquWForhULBiggvbnG3XB17drJB5gcJIRrM5gno/PnzTJkyhdWrV+Pl5WU+bjKZWLt2LbNmzWLMmDH07NmTtWvXUlRURHx8PADHjx/nq6++YuXKlYSGhhIaGsqbb77Jzp07SU9PB2DTpk2Ulpaydu1aevbsyZgxY5g5cybvvPOOuRe0du1a7rzzTmJiYujWrRsxMTEMHjyYtWvXWh1La+fuaMd7Q9pbbGBXboQnE/PJLZNdVIUQ1++qo+DGjx9v9YkyMjIaFEDtL/W77rqL2NhY8/HMzEz0ej1Dhw41H1MqlURERJCSkkJUVBQ6nQ43NzeLnVjDw8NxdXUlJSWFkJAQdDodgwYNQqm8eAtp2LBh/OMf/yAzM5OgoCBSU1OJjo62iGvYsGG8++67VsfSFtyucmLVHd5M3VtgPna62MjEpHw+G+GDg53MDxJCWO+qCejnn3++rkmHHTt2vK6Lv//++5w8edL8i/5Ser0eALVabXFcrVaTlZUFQHZ2NiqVyiJGhUKBj48P2dnZ5jr+/v51zlFbFhQUhF6vr/c6teewJpb61PbCrldD33cz9AMe93fko7MXh2HvP1fB819m8pdbKq/8xpugObdbcydt1zDSblcXEhJy1fKrJqAjR440ajCXSk9PZ+HChezYsQNHx9Y5p+RajV+f9PT0Br3vZnor2MSpnbnsP3fx+c9HZx0JC1IzsZttJqm2hHZrrqTtGkba7cbZ7BmQTqcjLy+P8PBwVCoVKpWKAwcOsG7dOlQqFe3btweos8J2Tk4OGo0GAI1GQ15ensWINpPJRG5urkWd+s5RWwag1Wqveh2tVnvNWNoSR7ua+UEdXS0HJbyYbGD32TIbRSWEaGlsloBGjx7NwYMH2bdvn/mrb9++jB07ln379tGlSxe0Wi1JSUnm95SVlZGcnGx+5hMaGkpRURE6nc5cR6fTUVxcbFEnOTmZsrKLvxiTkpLw8/MjMDAQgIEDB1pcp7ZO7TkCAwOvGUtbo1ba88FQy0mqRhM8lZTPzwbb3ooTQrQM9vPnz19giwu7uLigVqstvjZt2kRAQAATJkxAoVBgNBpZuXIlwcHBGI1GXn75ZfR6PStXrsTZ2RkfHx8OHTpEfHw8vXv35syZM8yePZt+/fqZh2IHBwfz3nvvceTIEUJCQkhOTubVV19l1qxZ5uTh5+fH4sWLcXJyQqVS8f7777Nx40ZWrVqFv7+/VbE0lvz8fFQqVaOdryn5trOnm5cDW34rNR8rN8Ku02WMu0WJq+PN+3zTktqtuZG2axhptxt33WvB3UwzZ86ktLSUOXPmYDAY6N+/P5s3b8bd3d1cZ926dcydO5exY8cCMHLkSJYtW2Yu9/T0ZMuWLcTExDBkyBC8vLyYMWMGzz33nLlOWFgYcXFxLFq0iMWLF9O5c2fi4uIYMGDAdcXSFj0QqGThQA/+llpoPvZ7kZEnvs5j6/1qlA4yMk4IUT+FwWCQRb2akZb4YNNkMjH7oIENJ0osjj8Q4MKGIe1vyvDslthuzYW0XcNIu904m09EFS2fQqFg+SAv7vG3vBX5+e9lzDpoqLPskRBCgCQg0Ugc7RRsuKc93b0s7+p+kF7Ca4cKr/AuIURbZvUzoBkzZly1XKFQ4OLigr+/P4MHDyY0NPSGgxMti5ezHZ/e58OIL3I4XXxxeZ63fiqivbMds25r28/LhBCWrE5A+/bto7S0lNzcXADzum21K0/7+PhQXV1Nfn4+CoWCYcOG8f7779OuXbsmCFs0Vx1c7flshIr7/5dLblm1+fiCbwvxdrbjaRtNVBVCND9W34L75JNPcHJyYv78+fz222/mr5MnTzJv3jycnZ3ZuXMnGRkZzJkzh6+++op//OMfTRm7aKa6eDoSf68Kd0fLwQezkw0kZJRe4V1CiLbG6gQ0d+5cRowYwbx58yxWrfb29mb+/Pnce++9zJkzB09PT1566SXGjh1LQkJCkwQtmr8+Pk58NFyF8yWLJVSbYMqefFktQQgBXEcCOnToUJ39ei516623WqxIMGjQoDpL14i2ZbCvM+/d0x77SzpCFdUw4et8UrNlHyEh2jqrE5Cnpydff/31Fcu//PJLPDw8zK+Li4vb/CRNAaMClKwe7G1xrLjKxLgvc/kpX5bsEaItszoBPfXUU2zfvp0JEybw9ddfm58Bff311zzxxBPs2rWLp556ylx/165d9O7du0mCFi3L413asTjU0+LY+QoTf9qVy8nCKhtFJYSwNatHwc2fP5+ysjLeeecdtm/fblFmb2/PjBkzmD9/PlCzUOcTTzxx1Vt2om2Z3suN8xXVxP5wcQvz7NJqxuzMZccoNR0uW1lbCNH6XfdSPDk5OezZs4dTp04B0KlTJ+6+++46m7WJhmnNy3uYTCZe0p3nX2nFFse7ejrwv1E++Lg0PAm15nZratJ2DSPtduOuezFStVrNuHHjmiIW0copFAoWh3pSWGHiw18urht34nwVY3flsfV+HzydZHEOIdqK605AFy5c4NSpUxgM9a/xdccddzRKYKJ1slMoeOsOLworqvn894vDsX/Mq+TppHw236fC7jq2gRdCtFxWJ6D8/HzmzJnD1q1bMRprllkxmUwo/vhlUfv3/Pz8polUtBoOdgrW39Oex77KI+lsufn47rPlvHusmGk93WwYnRDiZrE6Ab3wwgvs2LGDqVOnMmjQIIvJqEJcL2d7BR8Mbc/DO3NJzbk4HPvvhwoZ3sGZLp6ONoxOCHEzWJ2AkpKSmD59OgsXLmzKeEQb4upox3v3tCfis2wKK2tu55YaTUzZW8DOUWqc7OVWnBCtmdVPfJVKJQEBAU0Zi2iDOro5sCTMco7Q97mVLPletnAQorWzOgE98sgjfP75500Zi2ijnujSjgcCXCyOrTxSxNdnZM04IVozq2/BjR49mv379/OnP/2JJ598ko4dO2JvX3feRv/+/Rs1QNH6Kf4YGfddbjZnS2q2cDABUbvz+foBNSHyPEiIVsnqBPTAAw+Y/7579+465TIKTtyI9i72rL2zZlBC7eD+wgoTj32Vx1cPaPB2lvlBQrQ2ViegNWvWNGUcQnC3vzN/H+DBq5ds4f1roZGnEvOIv88HZxmUIESrYnUCeuKJJ5oyDiEAeP5WN44ZqvjokpUS9p2rYNreAtbf4y2TVIVoRWx2X+Pf//43ERERdOrUiU6dOnHvvfeyc+dOc7nJZGLJkiV0794dX19fRo8ezbFjxyzOYTAYiI6OJiAggICAAKKjo81bhNc6evQoo0aNwtfXlx49ehAbG1tnBYeEhATCwsLQaDSEhYWxbds2i3JrYhGNQ6FQsDLCi3CNk8XxLRmlzEs5X+/qG0KIlumKPaDY2FgUCgUxMTHY2dkRGxt7zZMpFArmzp1r1YX9/f35+9//TnBwMNXV1Xz00UdMmDCB3bt3c+utt7Jq1SrWrFnDmjVrCAkJYdmyZURGRpKammreZ2jy5MmcPn2a+Ph4oGay7NSpU/n4448BKCwsJDIykoiICBITE0lPT2fGjBm0a9eO559/HgCdTsekSZN46aWXePDBB9m2bRsTJ05k586dDBgwAMCqWETjcbZXsHFYe+7/Xy7p5y9u1/DvY8WoXeyY28fjKu8WQrQUV1wN29vbG4VCwblz53BycsLb27u+apYnu8FBCEFBQbz22mtMnDiR7t27M2XKFGJiYgAoLS0lJCSE119/naioKI4fP05YWBg7duwgPDwcgOTkZEaOHElqaiohISGsX7+eBQsWcOLECZRKJQDLly8nLi6OtLQ0FAoFUVFRFA3bQ+IAACAASURBVBQU8Nlnn5njGDNmDD4+Pqxfvx6TyXTNWBqTrLB70e9FVYz4IoesP0bG1fpHqCczelku1yPt1nDSdg0j7XbjrngLrqCggPz8fJycnMyvr/XV0ORjNBr59NNPKS4uJjQ0lMzMTPR6PUOHDjXXUSqVREREkJKSAtT0XNzc3AgLCzPXCQ8Px9XV1aLOoEGDzMkHYNiwYWRlZZGZmQlAamqqxXVq69Sew5pYRNMIcHPg0/t88HSyfO7zsu48cT8XX+FdQoiWwqZjW48ePUqHDh3QaDTMnj2bDz74gF69eqHX6wHq7DGkVqvJzs4GIDs7G5VKZV4MFWp6YD4+PhZ16jtHbRmAXq+/6nWsiUU0nZ7ejnw8XEU7B8sk9JdkAx+mSxISoiW77u0YGlNISAj79u2jsLCQhIQEnn322Va12kJ6evpNfV9rpQKWd7dj9lFnKkwXE9Fz+wsoyNFzn7pmdXZpt4aTtmsYaberu9YtSqsTkMlkYsOGDfznP/8hIyOjzmgzqOmB5OXlWR2ck5MTt9xyCwB9+vThu+++45133jE/a8nJyaFTp07m+jk5OWg0GgA0Gg15eXl1toTIzc21qJOTk2NxzdrXtXW0Wm29dS4tv1YsV9KQ+8NyX7l+IYDat4wJiXlU/vFIqBoFr55wRuvrze3GM9JuDSTfcw0j7XbjrE5Ar776KmvWrKF379488sgjTbIdQ3V1NRUVFQQGBqLVaklKSqJfv34AlJWVkZycbF6NOzQ0lKKiInQ6nfk5kE6no7i42Pw6NDSUBQsWUFZWhotLzVpjSUlJ+Pn5ERgYCMDAgQNJSkrihRdeMMeRlJRkPoc1sYib475OLqy/uz1Ru/Mx/jF0xmiCKXsKeLmLPTHyu0CIFsXqBPTRRx/x0EMPsWHDhka58IIFC7jvvvvo0KEDRUVFxMfHs3//fj755BMUCgXPPvssK1asICQkhC5duvDGG2/g6upq3g68W7duDB8+nNmzZ7Ny5UoAZs+ezYgRI8yfSsaNG0dsbCzTp08nJiaGX375hZUrVzJ37lxzr2natGmMGjWKN998k9GjR/P555+zb98+duzYAWBVLOLmeShIyb/u9CZ6b4F5yR4TsOgXZ9xVRUyVzeyEaDGsTkBlZWXcc889jXZhvV5PdHQ02dnZeHh40KtXL+Lj4xk2bBgAM2fOpLS0lDlz5mAwGOjfvz+bN2+2mHezbt065s6dy9ixYwEYOXIky5YtM5d7enqyZcsWYmJiGDJkCF5eXsyYMYPnnnvOXCcsLIy4uDgWLVrE4sWL6dy5M3FxceY5QNbGIm6e8cHtsFNA9N4Cc08IYF7KeUqqTMy+Tf5fhGgJrjgP6HJPPPEEPj4+vPXWW00dU5sm95Wt90VmKVG786mwnCZEzO3uvNzX3WKEpLgy+Z5rGGm3G2f1MOx//vOfHDp0iDfeeEOGH4tmYXSgko+Gq1BetkjpGz9eIOab81RVy7I9QjRnVveAfH19MZlMVFZWAuDo6IidnWX+UigUnD17tvGjbEPkU9X1O3CunPG7cigxWiaiER2dWX9Pe9wcZSuHq5HvuYaRdrtxVj8DioyMlFsaolm6w9eZNbeWM+uYkvMVFz9P7TxdzujtuXw8XIVvu7qbJwohbMvqBLR27dqmjEOIG3KrezXbR6l55Ms8Thcbzcd/zKtk+Oc5bLpXRQ9v2VlViOZE7k2IVqOntyNfPqDmtvaWieZ0sZER/8thb1a5jSITQtTnij2gAwcOAHDHHXdYvL6W2vpC2IJfO3v+N8qHSbvz2XX6YsIprDAxdlcuqwd782hwOxtGKISodcUE9MADD1hsx1D7+kpql8S5ke0YhGgMbo52fDhMxZxvDLx3/OLOqpXVMHVvAZkXqphzuwzTFsLWrpiAancFrd2O4fJdQoVozhzsFKwY5EWQuwOvHSq0KFv8/QV+LzLyZoQXjnaShISwlSsmoMGDB1/1tRDNnUKhYGZvdzq62vPsvgKLCasfpJdwptjI+0Pa4+Ekj0KFsAX5yROt3thb2vHZCB+8LtvYLulsOff/L4ffi6qu8E4hRFO6rv2AysrK2LZtGz/88AOFhYVUV1uugaJQKFi9enWjBihEY4jwdebLB9SM25VHZtHFYdppBVXcszWH9Xd7M6SDiw0jFKLtsToBnT59mgcffJCMjAw8PT0pLCzE29sbg8FAdXU1KpUKV1fXpoxViBsS4unIVw+oeeyrPL7NrTQfzy+vZuyXebzSz4PZvd1kcIIQN4nVt+Bee+018vPz2bVrF99++y0mk4m4uDjOnj3L3/72N5RKJQkJCU0ZqxA3TK20Z9tIHx4MtOztVJtg4beFPJmYT+Hlq5sKIZqE1Qlo9+7dPPPMMwwcONBiDThnZ2f+8pe/EBERwUsvvdQkQQrRmNo52PH+kPb8rZ8Hl/d1vvi9jKHbcvjZUFnve4UQjcfqBFRcXExQUBBwcWj2hQsXzOWDBg2yerKqELZmp1Dw4u3ufHqfCm9nyzT0S2EVw7bl8NlvpTaKToi2weoE5Ofnx7lz5wBwdXXF29ubI0eOmMtPnTqFo6OstSValqEdXNj9oIY+Ksvv3eIqExN35/OKTrZ1EKKpWD0IISIigsTERObOnQvAQw89xOrVq3FwcKC6upp//etfjBgxoskCFaKpBLo7sGOUmphvDHyQXmJRtvpoET/kVRB3T3s0SllRW4jGZHUCmj59OklJSZSVleHi4sKCBQvIyMhg8eLFQM1E1aVLlzZZoEI0JRcHBW/f4cUAtRNzvzFYTFrdf66Ce7Zm8/4QFQM1TrYLUohWxuoE1KtXL3r16mV+7eXlxWeffYbBYMDe3h53d/cmCVCIm0WhUDCxmyu92zvyVGI+Z0ouzhc6W1LNqO05LA3zZFI3VxmqLUQjsOoZUElJCQ8++CAffPBBnTIvLy9JPqJV6a92YvdDau70teztVFbDi8nneWZPAYZyGaotxI2yKgG1a9eOH3/8EaPReO3KQrQCaqU9W0b48MKtbnXKNv9Wyh2fZcv+QkLcIKtHwUVERHDw4MGmjEWIZsXBTsHCgZ68P6Q9bg6Wt9zOlBgZsyOXV1PPU26UUXJCNITVCWjZsmV8++23/O1vfyMjI6POOnBCtFZjgpR8/aCa3pfttGoC3vqpiCFbs/k+t8I2wQnRgl01AX300UdkZmYCEBoayqlTp1izZg39+vVDo9Hg5+dn8eXv72/1hVesWMGQIUPo1KkTwcHBPProo6SlpVnUMZlMLFmyhO7du+Pr68vo0aM5duyYRR2DwUB0dDQBAQEEBAQQHR2NwWCwqHP06FFGjRqFr68vPXr0IDY2FpPJ8lNrQkICYWFhaDQawsLC6ux/ZE0sovXq5uXI1w+omXmrW53VE9IMVQz/PIe/HzpPWZX0hoSw1lVHwc2YMYP/+7//IzAwkMjIyEYd+bN//36eeeYZ+vXrh8lkYvHixTz88MOkpKTg7e0NwKpVq1izZg1r1qwhJCSEZcuWERkZSWpqqnngw+TJkzl9+jTx8fEAvPDCC0ydOpWPP/4YgMLCQiIjI83zmNLT05kxYwbt2rXj+eefB0Cn0zFp0iReeuklHnzwQbZt28bEiRPZuXMnAwYMsDoW0bo52Sv4+0BPhnd04dl9BZwuvvhM1GiCN48U8fnvZay+w4swrbMNIxWiZVAYDIYrfmTz9vbm3XffZfz48U0eSFFREQEBAWzcuJGRI0diMpno3r07U6ZMISYmBoDS0lJCQkJ4/fXXiYqK4vjx44SFhbFjxw7Cw8MBSE5OZuTIkaSmphISEsL69etZsGABJ06cQKlUArB8+XLi4uJIS0tDoVAQFRVFQUEBn332mTmeMWPG4OPjw/r1662KpbGkp6cTEhLSaOdrK252uxnKq5mXYuDjX+su16MApvV05ZV+Hrg6Nv8tt+R7rmGk3W5cs/npKCoqorq6Gi8vLwAyMzPR6/UMHTrUXEepVBIREUFKSgpQ03Nxc3MjLCzMXCc8PBxXV1eLOoMGDTInH4Bhw4aRlZVlvr2YmppqcZ3aOrXnsCYW0bZ4Odvxf3e15+PhKvzbWf4YmYC1acXckZDN7rNltglQiBbgmgnoZk24mz9/Pr179yY0NBQAvV4PgFqttqinVqvJzs4GIDs7G5VKZRGjQqHAx8fHok5956gtq73W1a5jTSyibRrRyYXkSC1Pd21XpyzjgpGHd+YRlZTPmWKZwiDE5a65EsKMGTPMz0quRaFQcPbs2esO4q9//SvffPMNO3bswN6+9ay3lZ6eflPf19bZst2e08BAJzsWpztxttzyc92WjFJ2/F7ClIBKHvevwqHZ3He4SL7nGkba7equdYvymgmof//+5m0YmsJLL73E5s2b2bZtm8V1tFotADk5OXTq1Ml8PCcnB41GA4BGoyEvLw+TyWTuBZlMJnJzcy3q5OTkWFyz9nVtHa1WW2+dS8uvFUt9GnJ/WO4rN0xzaLcQ4OE+1Sz8tpB/Hyvm0oerpdUK3spwYpehHcvDvbjTr/kMUmgObdcSSbvduGsmoKioqCYbhDBv3jy2bNnCtm3b6Nq1q0VZYGAgWq2WpKQk+vXrB0BZWRnJycksXLgQqBkaXlRUhE6nMz8H0ul0FBcXm1+HhoayYMEC8yKqAElJSfj5+REYGAjAwIEDSUpK4oUXXjBfPykpyXwOa2IRAsDN0Y5l4V48EtyOF5MN/JhnubHdz4YqHtyRy5ggFxYO8CTQ3erlGIVodWx2MyAmJoYPP/yQf//733h5eaHX69Hr9RQVFQE1t/OeffZZVq1axdatW0lLS2P69Om4uroybtw4ALp168bw4cOZPXs2Op0OnU7H7NmzGTFihPmTybhx41AqlUyfPp20tDS2bt3KypUrmT59urnXNG3aNPbu3cubb77JiRMnWLFiBfv27ePZZ5+1OhYhLjVA7UTiA2r+OcgTT6e6z1ETMsoI3aJn4bfnOS9bgIs2ymbDsGtHu11u3rx55q29TSYTS5cuZcOGDRgMBvr3788bb7xBz549zfUNBgNz585l+/btAIwcOZJly5ZZnP/o0aPExMTw3Xff4eXlRVRUFPPmzbMYvJCQkMCiRYvIyMigc+fOvPLKKzz00EPmcmtiaQzSrW+Y5txuuWVGXjtUyMbL9hqq5e2s4C+93Zncww2lw81fZbs5t11zJu1245rNPCBRQ76pG6YltFuKvpz5uvN8n1tZb7l/Ozvm9/XgiS7tcLC7eYmoJbRdcyTtduOueguuoKBAko8QjSRM68zXD6hZM9gLrbLuj97ZkmpeOGAgfEs2CRmldZaLEqK1aYYDQoVovewUCiaEuPLtWC2v9PPAw7FuT+eXwiqeTsrnnm05JGSUYqyWRCRaJ0lAQtiAm6MdMbe788M4Lc/f6oZzPdPffsyr5OmkfEK36Pl/J4pl2wfR6kgCEsKG2rvY8/pAT74b68tTXdtR36OfXwuNvHDAwO2bzvHWkQsUyqg50UpIAhKiGejgas9bd3iTEqnh4SBlvXXOlVbz6qFCbt10jte/PU92qSzvI1o2SUBCNCMhno5sGNKelEhNzWi4enpEhRUm/nm4iN6bzvFisoGMC1U3P1AhGoEkICGaoW5ejrxzpzc/jNMyvZcrrvVkonIjrP+5mH6f6nlmdz6H82RXVtGySAISohnr6ObA4lAvjozX8lJfd9o71/2RrTbBp7+VctfWHB7YnsPmkyVUyIAF0QJIAhKiBWjvYs+8Ph4cGa9laZgnHV3rXzV+/7kKJu0poOcn51hw6LzcnhPNmiQgIVoQV0c7pvV04/txWv51pzc9vOpfzDS3rJqVR4roE69n7K5cPs8spUrmE4lmRpbiFaIFcrRT8FiXdjwSrGTnqTLe+qmIZH39z4C+PlPO12fK8Wtnx1NdXXmqqysdrtCDEuJmkh6QEC2YnULByAAl20epSX5YQ3QPVzzqWX0bIKukmtgfLtB70zke/yqPHaekVyRsSxKQEK1ED29HloV7cewRX96+w4t+Po711qs2wfZTZTz2VT69N51jTYYjJwvlWZG4+SQBCdHKuDra8eeuriQ+qGH3g2qe7tqu3mHcUNMr2nDakX6f6nlgew4f/1pCaZX0isTNIQlIiFasj48Tq+7w5tijvvxzkCc9va/82Hf/uQqm7i2g28dZvJhs4IdcmVckmpYkICHaAA8nO57p7saBMRp2jfbhzyFX7hUVVphY/3Mx92zL4c6EbN5NK8JQLuvPicYnCUiINkShUBCqcebtwd4cf6zmWdFt7ldeU+5IfiVzU87T7eMspuzJZ8/ZcqplnyLRSGQYthBtlNsfz4rCFWepVgfxnxMl/PfXEnLL6vZ2yo2w6WQpm06WEuhmz/hb2jE+WEk3r/oHOghhDekBCSHo5uXIolBP0h7x5f8Nac99HZ3r3RoCILPIyBuHLxC2JZu7ErJ5+6cLZJXIytzi+kkPSAhh5mSv4KEgJQ8FKTlTbOTD9GI+SC8hs6j+BHM4v5LD+ZW8mlrInX7OjLtFyegAF1QuMtFVXJv0gIQQ9ergas+cPh58P05Lwggfxt+irHfnVgATsDernBcOGOj633OM2ZFL3M/FsmeRuCrpAQkhrspOoeBuf2fu9nfmjYpqtmWWsunXUvZmlVPfcASjCfZklbMnq5wXk2GQ1okxQUoeDFTiL0sAiUtIAhJCWM3TyY4nQ1x5MsSVrBIjn54sIf5kKT/kVdZb3wQc1FdwUF/BvJTzhKqdeCjIhYeClAS4ya+fts6mt+AOHDjAY489Ro8ePfDy8mLjxo0W5SaTiSVLltC9e3d8fX0ZPXo0x44ds6hjMBiIjo4mICCAgIAAoqOjMRgMFnWOHj3KqFGj8PX1pUePHsTGxmK6bChpQkICYWFhaDQawsLC2LZt23XHIkRb4tfOnududWf3Qxp0kRpe6ut+1YmuALqcCl5JLeS2TXoGJ2Sz6NtCUrMrZGh3G2XTBFRcXEzPnj1ZunQpSqWyTvmqVatYs2YNsbGxJCYmolariYyM5MKFC+Y6kydP5vDhw8THxxMfH8/hw4eZOnWqubywsJDIyEg0Gg2JiYksXbqUt99+m9WrV5vr6HQ6Jk2axPjx49m3bx/jx49n4sSJHDp06LpiEaKt6urlyLw+Hhx8WMuhP2l4tb8Ht6uuPkT7p/xK3jh8gXu/yKHrf88xfV8BCRmlFFbIpNe2QmEwGJrFR48OHTqwbNkyJkyYANT0OLp3786UKVOIiYkBoLS0lJCQEF5//XWioqI4fvw4YWFh7Nixg/DwcACSk5MZOXIkqamphISEsH79ehYsWMCJEyfMSW758uXExcWRlpaGQqEgKiqKgoICPvvsM3M8Y8aMwcfHh/Xr11sVS2NJT08nJCSk0c7XVki7NVxTtl3GhSq2ZZSSkFnKoZz6b9NdztEOIrTODOtQ89ypd3tH7BRXGBNuQ/I9d+Oa7Si4zMxM9Ho9Q4cONR9TKpVERESQkpIC1PRc3NzcCAsLM9cJDw/H1dXVos6gQYMseljDhg0jKyuLzMxMAFJTUy2uU1un9hzWxCKEqCvI3YHne7vz1QMafhqvZUmoJ4O0TlecYwRQWV0ziOHVQ4XcvTWHkI/OMWl3Pv/vRDG/F8mq3a1Js30KqNfrAVCr1RbH1Wo1WVlZAGRnZ6NSqVBc8ulIoVDg4+NDdna2uY6/v3+dc9SWBQUFodfr671O7TmsiUUIcXUd3Rx4tpcbz/ZyI6/MyFdnytnxexlfnymjsPLKN2LyyqvZ/Fspm38rBSDYw557/F24x9+ZO32d8XJutp+jxTU02wTUGqSnp9/U97V10m4NZ4u26wf06whz/eGHQjv25duzv8Ce30uvnlB+LTTya2Ex638uxg4TPd2rCfWqpp+Hkd4e1bS7iSO95Xvu6q51i7LZJiCtVgtATk4OnTp1Mh/PyclBo9EAoNFoyMvLw2QymXtBJpOJ3Nxcizo5OTkW5659XVtHq9XWW+fS8mvFUp+G3B+W+8oNI+3WcM2h7XoAj//x91/OV5J0tpzdZ8vZl1V+1d5RNQp+umDPTxfsicMRewXcrnIkQutMhK8Tg7TOeDdRD6k5tFtL12z7roGBgWi1WpKSkszHysrKSE5ONj/zCQ0NpaioCJ1OZ66j0+koLi62qJOcnExZWZm5TlJSEn5+fgQGBgIwcOBAi+vU1qk9hzWxCCEaRxdPR6b0cGPjMBUnn/Djy9Fq/trXnQitE1fYQcLMaILvcitZfbSIJ77Op/OHWURs0fNisoFPfi0h40JVnSkYwnbs58+fv8BWFy8qKuLnn39Gr9fzn//8h549e+Lh4UFFRQWenp4YjUZWrlxJcHAwRqORl19+Gb1ez8qVK3F2dsbHx4dDhw4RHx9P7969OXPmDLNnz6Zfv37modjBwcG89957HDlyhJCQEJKTk3n11VeZNWuWOXn4+fmxePFinJycUKlUvP/++2zcuJFVq1bh7++PQqG4ZiyNJT8/H5VK1Wjnayuk3RquObednUJBB1d77vB1ZkKIK9N7uRGuccbHxY6SShM59azcfbmcsmq+z61kW2YZ/0or5r3jxXyjr+BMsZFqwMfFHserjYq4gubcbi2FTYdh79u3jwcffLDO8ccff5y1a9diMplYunQpGzZswGAw0L9/f9544w169uxprmswGJg7dy7bt28HYOTIkSxbtgwvLy9znaNHjxITE8N3332Hl5cXUVFRzJs3z2LwQkJCAosWLSIjI4POnTvzyiuv8NBDD5nLrYmlMUi3vmGk3RquJbfduRIje7LKOXCunIPnKvil8PpHyTnaQe/2jvTzcaKPjyN9VU5083LA4RpJqSW3W3PRbOYBiRryTd0w0m4N15raLrvUSLK+oiYh6Ss4ml9Z73p119LOQcFt7R3p41OTmPr6OBLs4WAxH6k1tZutNNtBCEIIcb00SnvGBCkZE1Qz789QXs032eXosivQZVfwXW4lJVXXTkklVSa+ya7gm+wKoBgAD0cFvdo70svbkZ7ejngU26GtqMbDqdk+Sm/2JAEJIVotL2c77u+k5P5ONQmpqtrET/mVpOZUmJPSlfY6ulxhpYlkfQXJ+oo/jrjA4SwC3Ozp5V2TmHq1d6Cnd01v6Vq38IQkICFEG+Jgp6CPjxN9fJyY0qPmWHapke9yK/g+t5Ifcmt6SdYMbqj1e5GR34uMbD91caStsz109axJRF08HLjFw55gDweCPR1QOdtZPH9uyyQBCSHaNI3S3qKXZDKZOFNs5LvcSn7Iq0lM3+dWYKiw/mlSuRGO5FdyJL/u+nceTgq6eDgQ7OHALX/8WfvV1lZ1kAQkhBCXUCgUdHRzoKObAw8FXUxKmUVG0goqSSuo4mh+JT/oi8kss6P6Okc5FFaY+C63ku9y6yYnlbPdH4nJ3pyUbvmj5+Tu2PqSkyQgIYS4BoVCQZC7A0HuDowKqDmWnp5Hx85dOG6oJK2gkqMFVX/8WUl2acO2lMgrryYvpwJdTt0yrdLO3GPq7O5ARzd7OrrWfPm7Nmwuk61JAhJCiAZSOlx8pnSpnFIj6eer+LWwipOFNX/W/N1IqbFhM1/0pdXoSy8dBHGRAvBrZ0dHV8vEVPv3Tm4OeDkpmt2zJ0lAQgjRyNRKe9RKeyJ8LVdJqTaZyCqprpOYfj1fxW8XqmjoXnwm4GxJNWdL6u89Abg61Kwq4e9qj0Zph1ZZ86fa5Y8/lfb4uNihcrbDyf7mJCpJQEIIcZPULi3UwdWeu/wsk5Ox2sTpYqNlYvrjK/OCESumL11VcZWJE+erOHH+2qtFeDgp8HG2w8fFHpWLHTNudWOwb+MtOVZLEpAQQjQD9nYKAt0dCHR3YEgHy7LKahOniozmhHSqyMjp4ipOFxk5XWxE38BnTldSWGGisMLIyQs1c6Qe79KuUc9fSxKQEEI0c452Cm75Y0TcvfWUlxtNnC02cqrYyJliI6eLqjhdXJOcThfVHLdmBYgr8XFpmhF4koCEEKKFc7ZX0NnDgc4e9f9KN5lMGCpMnCqq+mMwg5Hs0mrOlRjJLasmp9RITlk1uWXV5JdX1xlaLglICCFEgygUCrydFXg7O12zrrHahKGiJhnVfnV0a5ptZiUBCSGEMLO3U6BysUflYk+3Jr5W65taK4QQokWQBCSEEMImJAEJIYSwCUlAQgghbEISkBBCCJtQGAyGG1zgQQghhLh+0gMSQghhE5KAhBBC2IQkICGEEDYhCUgIIYRNSAISQghhE5KAmol169Zx2223odVqufvuuzl48KCtQ7qpVqxYwZAhQ+jUqRPBwcE8+uijpKWlWdQxmUwsWbKE7t274+vry+jRozl27JhFHYPBQHR0NAEBAQQEBBAdHY3BYLCoc/ToUUaNGoWvry89evQgNjYWk6l1DAZdsWIFXl5ezJkzx3xM2u3Kzp07x7Rp0wgODkar1RIWFsb+/fvN5dJ2TUsSUDOwefNm5s+fz4svvsjevXsJDQ1l/PjxnDp1ytah3TT79+/nmWeeYefOnWzduhUHBwcefvhhCgoKzHVWrVrFmjVriI2NJTExEbVaTWRkJBcuXDDXmTx5MocPHyY+Pp74+HgOHz7M1KlTzeWFhYVERkai0WhITExk6dKlvP3226xevfqm/nubQmpqKhs2bKBXr14Wx6Xd6mcwGBgxYgQmk4lPPvmElJQUli1bhlqtNteRtmtaMg+oGRg2bBi9evXirbfeMh/r168fY8aM4bXXXrNhZLZTVFREQEAAGzduZOTIkZhMJrp3786UKVOIiYkBoLS0lJCQEF5//XWioqI4fvw4YWFh7Nixg/DwcACSk5MZOXIkqamphISEsH79ehYsWMCJEydQKpUALF++nLi4ONLS0lAoFDb7N9+I8+fPc/fdd/PWW28RGxtLz549Wb58ubTbVSxcuJADBw6wc+fOesul7Zqe9IBsrKKigh9++IGhQ4daQn42SQAADapJREFUHB86dCgpKSk2isr2ioqKqK6uxsvLC4DMzEz0er1FOymVSiIiIsztpNPpcHNzIywszFwnPDwcV1dXizqDBg0y/yKAmg8AWVlZZGZm3ox/WpOYNWsWY8aM4a677rI4Lu12ZV988QX9+/cnKiqKLl26MHjwYN59913zrTFpu6YnCcjG8vLyMBqNFt1+ALVaTXZ2to2isr358+fTu3dvQkNDAdDr9QBXbafs7GxUKpXFJ0qFQoGPj49FnfrOUVvWEr3//vucPHmSV155pU6ZtNuVZWRksH79eoKCgvj000+ZNm0af//73/n3v/8NSNvdDLIhnWh2/vrXv/LNN9+wY8cO7O2bZifG1iI9PZ2FCxeyY8cOHB0dbR1Oi1JdXU3fvn3Nt7lvv/12Tp48ybp164iOjrZxdG2D9IBsTKVSYW9vT05OjsXxnJwcNBqNjaKynZdeeolPP/2UrVu3EhQUZD6u1WoBrtpOGo2GvLw8i9FFJpOJ3Nxcizr1naO2rKXR6XTk5eURHh6OSqVCpVJx4MAB1q1bh0qlon379oC0W320Wi3dulnu+dm1a1dOnz5tLgdpu6YkCcjGnJyc6NOnD0lJSRbHk5KSLO4rtwXz5s0zJ5+uXbtalAUGBqLVai3aqaysjOTkZHM7hYaGUlRUhE6nM9fR6XQUFxdb1ElOTqasrMxcJykpCT8/PwIDA5vyn9ckRo8ezcGDB9m3b5/5q2/fvowdO5Z9+/bRpUsXabcrCA8P55dffrE49ssvv9CpUydAvuduBvv58+cvsHUQbZ27uztLlizB19cXFxcXli9fzsGDB1m9ejWenp62Du+miImJ4b///S8bNmygY8eOFBcXU1xcDNQkaYVCgdFoZOXKlQQHB2M0Gnn55ZfR6/WsXLkSZ2dnfHx8OHToEPHx8fTu3ZszZ84we/Zs+vXrZx4WGxwczHvvvceRI0cICQkhOTmZV199lVmzZrXIhO/i4oJarbb42rRpEwEBAUyYMEHa7So6duxIbGwsdnZ2+Pr6smfPHhYtWsTs2bPp37+/tN1NIMOwm4l169axatUq9Ho9Pf5/e/cfE3X9B3D8yQ9rxIYnBELgAQomiHrm/IPokpUJV2OVbpBMfsnIgigCPWBORFaKNwRWkkI/NI8LSnNROlLmLiioLSdzq4wBldBYS6CDP0zKk+8f7j51HmIQdl/q9djY+Lw/7/t8Xp/PTV6f9+f99v2OiGD37t3ExMQ4O6x/jG20240KCwspLi4Grr/aKC8v5/Dhw1gsFlatWkVFRQWRkZFKfYvFgl6vp7m5GQCdTofBYLA7/tdff83WrVs5d+4cKpWKjIwMCgsL/zXDYR977DFlGDbIfZvMqVOnKCsro6enh6CgILKystiyZYtyTXLvbi9JQEIIIZxC+oCEEEI4hSQgIYQQTiEJSAghhFNIAhJCCOEUkoCEEEI4hSQgIYQQTiEJSIgZ8umnn6JSqXj//fedHcpfduDAATQaDd7e3jzwwAPODmfa9uzZg0qlUiYQFbODJCAxq5hMJlQqFX5+fhMu2JeUlMSyZcucENns8/nnn1NcXMyqVavYv38/JSUlzg5J/MfIbNhiVvrtt9+orKykqqrK2aHMWralpysrK/8zUz6J/y/SAhKz0rJlyzCZTP+pZcttbHPk/V22GZkl+QhnkQQkZqX8/HwA9u3bN2m9ixcvolKpMJlMDvtUKhV79uxRtm39CF1dXTz99NOo1WoWLlxIWVkZ4+PjDAwMkJyczIIFCwgPD7dbQv3PrFYru3fvZsmSJQQEBLB+/Xp6e3sd6vX09JCenk5oaCjz589Hq9XS1NRkV8f2yrG1tRW9Xk94eDiBgYGTXrPVaqWiooKVK1fi5+dHVFQUJSUl/Prrr3bXXldXp/x+s3s03Xjb2trYtm0bCxcuJCgoiPT09AkXX2tqaiI2NhZ/f39CQ0PJzMyc8KGip6eHzMxMZXbv++67j6KiIod6o6OjPPvss6jVatRqNdnZ2Vy+fNmuTmtrKzqdjuDgYAICAtBoNGzbtm3Saxe3h7yCE7NSUFAQmzZtwmg0UlBQoEyhPxMyMzNZvHgxO3fu5PTp01RWVjJv3jzq6+u5//77KS0t5ejRo5SUlLBixQrWrFlj9/nq6mquXbvGc889h8Vioba2loSEBNrb25k3bx4AXV1drFu3jvnz5/PCCy/g6enJiRMnSEtLo7a2lqSkJLtjFhYWolKpKCgoYHR0dNL48/LyMBqNJCQkkJOTQ2dnJ6+88goXLlzgvffew8XFhdraWhobGzGbzdTW1gJMOjPzVOMtKirC09MTvV5Pf38/dXV1dHd3YzabueOOOwB499132bJlCxqNhpKSEoaGhqitreWLL76gra0NHx8fAC5cuEBcXByurq6kp6cTEhJCX18fx48fp7y83O68mzdvJiQkhJ07d3L+/HmOHDmCr68vu3btAuDbb78lMTGRyMhIioqKuOuuu/j+++85c+bMpPdU3B6SgMSslZ+fT319Pfv27aO6unrGjqvRaNi/fz8A6enpLF++nJKSErZv387WrVsB2LBhAxEREZhMJocEdOnSJb788ktlNmStVsvjjz9OTU2Nsmx2UVERAQEBmM1mPDw8AMjKyuLJJ59k165dJCYm2s2UbPuD7+4++T/Zr776CqPRSHJyMq+99ppSblt64NSpU8THx5OUlMTZs2cxm80OyWMiU40X4MSJE9x5550ALFmyhNzcXBobG0lNTeX3339nx44d3HvvvTQ3NyvHjI2NJSEhgaqqKl566SXg+lIdVquVtrY2u0UKd+zY4RDn8uXLqampUbaHh4cxGo1KAjKbzYyNjXHs2DElwQGUlpbe8h6ImSev4MSsZWsFmUwm+vr6Zuy4qampyu9ubm5oNBrGx8dJSUlRylUqFWFhYfzwww8On3/qqafspuJfs2YNERERfPzxxwD88ssvfPLJJzzxxBNcvnyZoaEh5efhhx9mYGDAYaG0tLS0WyYfgNOnTwOQk5NjV56dnY2bm5uyfyqmE29GRoaSfAA2btzI3LlzlXvQ2dnJzz//zObNm5XkA9eTtUajUeIcHBykvb2d5ORku+QDTLiUQVpamt12dHQ0w8PDSqvRy8sLgJMnT3Lt2rUp3wsxsyQBiVktPz8fFxeXW/YFTUVQUJDdtpeXF3PmzFGWaP5zucVicfj8okWLJiyzJcnvvvtOWWdm0aJFdj+2FtKNSzjf+Mf3Zvr7+3FxcSEsLMyufO7cufj7+08rUU8n3hvvgbu7O8HBwcr5bf084eHhDudbvHixUs+W4CMiIv5SrDd+d7YHAdv3tH79eqKjo3n++ecJCwsjPT2do0ePcvXq1b90fDGz5BWcmNWCgoJISUnhyJEjFBQUOOy/2YJfVqv1psd0c3NzKHN1nfhZbXx86stp2Z68s7OzWbdu3YR1/rzgGWDXSvinTSdeZ5nou4M/vicPDw9OnjxJe3s7LS0tnDlzhqysLGpqauxeBYp/hiQgMevl5+djNBqpqKhw2Gd7Ah4ZGbErv53Dtyca8dbb24tarQb+aM24u7sTGxs7o+desGAB4+Pj9PT0sHTpUqV8dHSUn376ibi4uCkfczrx9vb28tBDDynbV69e5eLFi8oqv7ZBI93d3Xb1bGW2exUaGgpcH4gwU1xdXdFqtWi1WsrKynjzzTcpKCjgo48+IjExccbOI25NXsGJWS8wMJDU1FQaGhocEouXlxc+Pj50dHTYlb/xxhu3LZ7Gxka7V3Otra3KSC4AX19ftFotb7/9NgMDAw6fHxwcnPa5bS2UAwcO2JUfPHgQq9U6rQQ0nXgPHTrE2NiYst3Q0MDIyIhyftsQ8cOHD3PlyhWlXkdHB52dnUo9Hx8fYmJieOeddxz626bT+hweHnYoW7FiBeD4kCJuP2kBiX+FF198EaPRyDfffOMwJDs1NZWqqipyc3NZuXIlHR0dDp3mM8nX15f4+Hg2bdrEyMgIBw8exN/f325gQGVlJXFxccTExJCWlkZoaCiXLl3i7NmzdHV10dnZOa1zR0VFkZKSgtFoZHR0lAcffJDz589TX1/P2rVrb/oK7VamE29CQgIbNmygr6+Puro6IiMj2bhxIwBz5syhrKyMZ555Bp1OR2JiojIM+5577iEvL085jsFgQKfTERsbS0ZGBiEhIfT393P8+HHOnTs3peswGAx89tlnxMXFoVarsVgsvPXWW3h6ek4rOYu/RxKQ+FewtYJef/11h316vZ7BwUGampr44IMPWLt2LceOHXPoqJ8peXl5dHd38+qrrzIyMkJ0dDQGgwFvb2+lTnh4OGazmb1799LY2MjQ0BB33303UVFRbN++/W+dv7q6muDgYOrr62lubsbPz4/c3FyKi4tv2id2K1ONt7y8nA8//JC9e/cyNjaGTqfDYDAo/wcIro8W9PDwoKqqitLSUjw8PHjkkUcoLS21GyK9dOlSWlpaePnllzl06BBXrlwhMDCQ+Pj4KV/Ho48+yo8//khDQwODg4N4e3uzevVq9Hq98tpP/HNcLBbL1NuxQggxAZPJRE5ODi0tLaxevdrZ4Yj/c9IHJIQQwikkAQkhhHAKSUBCCCGcQvqAhBBCOIW0gIQQQjiFJCAhhBBOIQlICCGEU0gCEkII4RSSgIQQQjiFJCAhhBBO8T8JbNyGRCOyBAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}